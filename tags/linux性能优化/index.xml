<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linux性能优化 on 迪克猪的博客</title>
    <link>https://zsy619.github.io/tags/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link>
    <description>Recent content in Linux性能优化 on 迪克猪的博客</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Thu, 16 Jul 2020 15:50:00 +0800</lastBuildDate>
    <atom:link href="https://zsy619.github.io/tags/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>01|如何学习Linux性能优化</title>
      <link>https://zsy619.github.io/post/01%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link>
      <pubDate>Wed, 27 May 2020 11:14:53 +0800</pubDate>
      <guid>https://zsy619.github.io/post/01%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid>
      <description>前凑 搭建github.io博客 学习 不需要了解每个组件的所有实现细节 理解他们最基本的工作原理和协助方式 性能指标 应用负载的两个指标：&#xA;吞吐 延时 性能分析：找出应用或系统的瓶颈，并想法去避免或缓解他们，从而更高效利用系统资源处理更多的请求。</description>
    </item>
    <item>
      <title>02|基础篇--到底应该怎么理解平均负载</title>
      <link>https://zsy619.github.io/post/02%E5%9F%BA%E7%A1%80%E7%AF%87%E5%88%B0%E5%BA%95%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD/</link>
      <pubDate>Wed, 27 May 2020 11:40:49 +0800</pubDate>
      <guid>https://zsy619.github.io/post/02%E5%9F%BA%E7%A1%80%E7%AF%87%E5%88%B0%E5%BA%95%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD/</guid>
      <description>什么是平均负载 平均负载(Load Average)：单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。 可运行状态的进程：正在使用cpu或等待使用cpu的进程，ps命令查看处于R状态（Running或Runnable）的进程。 不可中断的状态进程：处于内核态关键流程的状态，且这些流程不可打断，ps命令查看处于D状态（Uninterruptible Sleep，也称为Disk Sleep）的进程。 不可中断状态实际是系统对进程和硬件设备的一种保护机制。 $ uptime 14:36 up 5:23, 1 user, load averages: 2.</description>
    </item>
    <item>
      <title>03|基础篇经常说的CPU上下文切换是什么意思</title>
      <link>https://zsy619.github.io/post/03%E5%9F%BA%E7%A1%80%E7%AF%87%E7%BB%8F%E5%B8%B8%E8%AF%B4%E7%9A%84CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/</link>
      <pubDate>Wed, 27 May 2020 12:24:00 +0800</pubDate>
      <guid>https://zsy619.github.io/post/03%E5%9F%BA%E7%A1%80%E7%AF%87%E7%BB%8F%E5%B8%B8%E8%AF%B4%E7%9A%84CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/</guid>
      <description>CPU上下文切换就是罪魁祸首 任务运行前的准备工作 CPU都要知道任务从哪里加载、从哪里开始运行，需要系统事先设置好CPU寄存器和程序计数器（Program Counter，PC）&#xA;CPU寄存器：CPU内置容量小、速度极快的内存 程序计数器：用来存储CPU正在执行的指令位置、或将执行下一条指令的位置 这就是CPU上下文 CPU上下文切换：把前一个CPU上下文（cpu寄存器及程序计数器）保存起来，然后加载新的任务的上下文到这些寄存器及程序计数器，然后跳转到寄存器及程序计数器所指的位置，运行新的任务 进程、线程是最常见的任务 CPU上下文场景分类： 进程上下文切换 线程上下文切换 中断上下文切换 进程上下文切换 linux特权等级，把进程运行空间分为：内核空间、用户空间</description>
    </item>
    <item>
      <title>05|基础篇--某个应用的CPU使用率居然达到100%，我该怎么办？</title>
      <link>https://zsy619.github.io/post/05%E5%9F%BA%E7%A1%80%E7%AF%87%E6%9F%90%E4%B8%AA%E5%BA%94%E7%94%A8%E7%9A%84CPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%B1%85%E7%84%B6%E8%BE%BE%E5%88%B0100%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</link>
      <pubDate>Fri, 29 May 2020 12:45:21 +0800</pubDate>
      <guid>https://zsy619.github.io/post/05%E5%9F%BA%E7%A1%80%E7%AF%87%E6%9F%90%E4%B8%AA%E5%BA%94%E7%94%A8%E7%9A%84CPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%B1%85%E7%84%B6%E8%BE%BE%E5%88%B0100%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</guid>
      <description> cpu使用率 定义节拍率（内核中用HZ表示），触发时间中断，并使用全局变量Jiffies记录开机以来的节拍率 没发生一次时间中断，Jiffies就增加1 节拍率设置值100、250、1000等，查询/boot/config来查看 表示每秒触发250次中断&#xA;节拍率是内核选项，用户空间程序不能直接访问 用户节拍率USER_HZ默认是100 /proc虚拟文件系统 系统内部状态 /proc/stat提供cpu和任务系统信息 CPU使用率：就是空闲时间外的其他时间占总cpu时间的百分比 每个进程的运行情况：/proc/[pid]/stat 如何查看cpu使用率 top显示系统整体cpu与内存使用情况，以及各个进程资源使用情况 ps显示每个进程的使用情况 cpu使用过高 使用perf分析cpu性能 </description>
    </item>
    <item>
      <title>06|案例篇--系统的CPU使用率很高，但为啥却找不到高CPU的应用？</title>
      <link>https://zsy619.github.io/post/06%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E7%9A%84CPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%BE%88%E9%AB%98%E4%BD%86%E4%B8%BA%E5%95%A5%E5%8D%B4%E6%89%BE%E4%B8%8D%E5%88%B0%E9%AB%98CPU%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Sun, 31 May 2020 12:45:21 +0800</pubDate>
      <guid>https://zsy619.github.io/post/06%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E7%9A%84CPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%BE%88%E9%AB%98%E4%BD%86%E4%B8%BA%E5%95%A5%E5%8D%B4%E6%89%BE%E4%B8%8D%E5%88%B0%E9%AB%98CPU%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description>使用工具 使用top、vmstat、pidstat等&#xA;ap（apache bench）是一个常用的http性能测试工具&#xA;# 并发100个请求测试Nginx性能，总共测试1000个请求 $ ab -c 100 -n 1000 http://192.</description>
    </item>
    <item>
      <title>07|案例篇--系统中出现大量不可中断进程和僵尸进程怎么办？（上）</title>
      <link>https://zsy619.github.io/post/07%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%87%BA%E7%8E%B0%E5%A4%A7%E9%87%8F%E4%B8%8D%E5%8F%AF%E4%B8%AD%E6%96%AD%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8A/</link>
      <pubDate>Sun, 31 May 2020 17:16:28 +0800</pubDate>
      <guid>https://zsy619.github.io/post/07%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%87%BA%E7%8E%B0%E5%A4%A7%E9%87%8F%E4%B8%8D%E5%8F%AF%E4%B8%AD%E6%96%AD%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8A/</guid>
      <description> 进程状态 top 和 ps 是最常用的查看进程状态的工具 top命令： R 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行。 D 是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。 Z 是 Zombie 的缩写，如果你玩过“植物大战僵尸”这款游戏，应该知道它的意思。它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。 S 是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态。 I 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会。 进程组与会话 进程组：表示一组相互关联的进程，比如每个子进程都是父进程所在组的成员； 会话：指共享同一个控制终端的一个或多个进程组。 </description>
    </item>
    <item>
      <title>08|案例篇--系统中出现大量不可中断进程和僵尸进程怎么办？（下）</title>
      <link>https://zsy619.github.io/post/08%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%87%BA%E7%8E%B0%E5%A4%A7%E9%87%8F%E4%B8%8D%E5%8F%AF%E4%B8%AD%E6%96%AD%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8B/</link>
      <pubDate>Sun, 31 May 2020 17:31:56 +0800</pubDate>
      <guid>https://zsy619.github.io/post/08%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%87%BA%E7%8E%B0%E5%A4%A7%E9%87%8F%E4%B8%8D%E5%8F%AF%E4%B8%AD%E6%96%AD%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8B/</guid>
      <description>问题 通过分析 top 命令的输出，我们发现了两个问题：&#xA;第一，iowait 太高了，导致系统平均负载升高，并且已经达到了系统 CPU 的个数。 第二，僵尸进程在不断增多，看起来是应用程序没有正确清理子进程的资源。 iowait分析 dstat可以同时查看 CPU 和 I/O 这两种资源的使用情况 strace 正是最常用的跟踪进程系统调用的工具。 perf record -g perf report 僵尸进程 找出父进程，然后在父进程里解决。</description>
    </item>
    <item>
      <title>09|基础篇--怎么理解Linux软中断？</title>
      <link>https://zsy619.github.io/post/09%E5%9F%BA%E7%A1%80%E7%AF%87%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3Linux%E8%BD%AF%E4%B8%AD%E6%96%AD/</link>
      <pubDate>Sun, 31 May 2020 17:32:53 +0800</pubDate>
      <guid>https://zsy619.github.io/post/09%E5%9F%BA%E7%A1%80%E7%AF%87%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3Linux%E8%BD%AF%E4%B8%AD%E6%96%AD/</guid>
      <description>软中断（softirq） 软中断（softirq）CPU 使用率升高也是最常见的一种性能问题&#xA;中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。&#xA;为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行。&#xA;Linux 将中断处理过程分成了两个阶段，也就是上半部和下半部：&#xA;上半部用来快速处理中断，它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。 下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。 网卡接收到数据包后，会通过硬件中断的方式，通知内核有新的数据到了。</description>
    </item>
    <item>
      <title>10|案例篇--系统的软中断CPU使用率升高，我该怎么办？</title>
      <link>https://zsy619.github.io/post/10%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BD%AF%E4%B8%AD%E6%96%ADCPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%8D%87%E9%AB%98%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</link>
      <pubDate>Mon, 01 Jun 2020 11:49:03 +0800</pubDate>
      <guid>https://zsy619.github.io/post/10%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BD%AF%E4%B8%AD%E6%96%ADCPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%8D%87%E9%AB%98%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</guid>
      <description>中断处理程序 分上半部与下半部 上半部对应硬件中断，用来快速处理中断 下半部对应软件中断，用异步处理上半部未完成的工作 观察中断可通过/proc/softirqs sar命令 查看系统网络收发情况&#xA;# -n DEV 表示显示网络收发的报告，间隔1秒输出一组数据 $ sar -n DEV 1 15:03:46 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 15:03:47 eth0 12607.</description>
    </item>
    <item>
      <title>11|套路篇--如何迅速分析出系统CPU的瓶颈在哪里？</title>
      <link>https://zsy619.github.io/post/11%E5%A5%97%E8%B7%AF%E7%AF%87%E5%A6%82%E4%BD%95%E8%BF%85%E9%80%9F%E5%88%86%E6%9E%90%E5%87%BA%E7%B3%BB%E7%BB%9FCPU%E7%9A%84%E7%93%B6%E9%A2%88%E5%9C%A8%E5%93%AA%E9%87%8C/</link>
      <pubDate>Mon, 01 Jun 2020 18:49:15 +0800</pubDate>
      <guid>https://zsy619.github.io/post/11%E5%A5%97%E8%B7%AF%E7%AF%87%E5%A6%82%E4%BD%95%E8%BF%85%E9%80%9F%E5%88%86%E6%9E%90%E5%87%BA%E7%B3%BB%E7%BB%9FCPU%E7%9A%84%E7%93%B6%E9%A2%88%E5%9C%A8%E5%93%AA%E9%87%8C/</guid>
      <description>cup性能指标 首先联想到cpu使用率 根据cpu上运行任务不同，划分：&#xA;用户cpu 用户 CPU 使用率，包括用户态 CPU 使用率（user）和低优先级用户态 CPU 使用率（nice），表示 CPU 在用户态运行的时间百分比。用户 CPU 使用率高，通常说明有应用程序比较繁忙。 系统cpu 系统 CPU 使用率，表示 CPU 在内核态运行的时间百分比（不包括中断）。系统 CPU 使用率高，说明内核比较繁忙。 等待io/cpu 等待 I/O 的 CPU 使用率，通常也称为 iowait，表示等待 I/O 的时间百分比。iowait 高，通常说明系统与硬件设备的 I/O 交互时间比较长。 软中断 硬中断 软中断和硬中断的 CPU 使用率，分别表示内核调用软中断处理程序、硬中断处理程序的时间百分比。它们的使用率高，通常说明系统发生了大量的中断。 除了上面这些，还有在虚拟化环境中会用到的窃取 CPU 使用率（steal）和客户 CPU 使用率（guest），分别表示被其他虚拟机占用的 CPU 时间百分比，和运行客户虚拟机的 CPU 时间百分比。</description>
    </item>
    <item>
      <title>12|套路篇--CPU性能优化的几个思路</title>
      <link>https://zsy619.github.io/post/12%E5%A5%97%E8%B7%AF%E7%AF%87CPU-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Mon, 01 Jun 2020 19:24:51 +0800</pubDate>
      <guid>https://zsy619.github.io/post/12%E5%A5%97%E8%B7%AF%E7%AF%87CPU-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF/</guid>
      <description>性能优化方法论 三个问题：&#xA;首先，既然要做性能优化，那要怎么判断它是不是有效呢？特别是优化后，到底能提升多少性能呢？ 第二，性能问题通常不是独立的，如果有多个性能问题同时发生，你应该先优化哪一个呢？ 第三，提升性能的方法并不是唯一的，当有多种方法可以选择时，你会选用哪一种呢？是不是总选那个最大程度提升性能的方法就行了呢？ 性能评估可能有多重指标，性能问题可能会多个同时发生，而且，优化某一个指标的性能，可能又导致其他指标性能的下降。&#xA;怎么评估性能优化的效果 性能评估“三步走”：&#xA;确定性能的量化指标。 测试优化前的性能指标。 测试优化后的性能指标。 不要局限单一维度指标，至少要从应用程序和系统资源两个维度着手，分别选择不同的指标。</description>
    </item>
    <item>
      <title>13|答疑（一）无法模拟出RES中断的问题，怎么办？</title>
      <link>https://zsy619.github.io/post/13%E7%AD%94%E7%96%91%E4%B8%80%E6%97%A0%E6%B3%95%E6%A8%A1%E6%8B%9F%E5%87%BARES%E4%B8%AD%E6%96%AD%E7%9A%84%E9%97%AE%E9%A2%98%E6%80%8E%E4%B9%88%E5%8A%9E/</link>
      <pubDate>Tue, 02 Jun 2020 12:18:53 +0800</pubDate>
      <guid>https://zsy619.github.io/post/13%E7%AD%94%E7%96%91%E4%B8%80%E6%97%A0%E6%B3%95%E6%A8%A1%E6%8B%9F%E5%87%BARES%E4%B8%AD%E6%96%AD%E7%9A%84%E9%97%AE%E9%A2%98%E6%80%8E%E4%B9%88%E5%8A%9E/</guid>
      <description>问题 1：性能工具版本太低，导致指标不全 性能分析的学习，建议要用最新的性能工具来学。新工具有更全面的指标，更容易上手分析。这个绝对的优势，可以让你更直观地得到想要的数据，也不容易让你打退堂鼓。&#xA;最好试着去理解性能工具的原理，或者熟悉了使用方法后，再回过头重新学习原理。这样，即使是在无法安装新工具的环境中，你仍然可以从 proc 文件系统或者其他地方，获得同样的指标，进行有效的分析。&#xA;问题 2：使用 stress 命令，无法模拟 iowait 高的场景 可以运行下面的命令，来模拟 iowait 的问题：</description>
    </item>
    <item>
      <title>14|答疑（二）如何用perf工具分析Java程序？</title>
      <link>https://zsy619.github.io/post/14%E7%AD%94%E7%96%91%E4%BA%8C%E5%A6%82%E4%BD%95%E7%94%A8perf%E5%B7%A5%E5%85%B7%E5%88%86%E6%9E%90Java%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Tue, 02 Jun 2020 12:25:48 +0800</pubDate>
      <guid>https://zsy619.github.io/post/14%E7%AD%94%E7%96%91%E4%BA%8C%E5%A6%82%E4%BD%95%E7%94%A8perf%E5%B7%A5%E5%85%B7%E5%88%86%E6%9E%90Java%E7%A8%8B%E5%BA%8F/</guid>
      <description>问题 1： 使用 perf 工具时，看到的是 16 进制地址而不是函数名 只要你观察一下 perf 界面最下面的那一行，就会发现一个警告信息：</description>
    </item>
    <item>
      <title>15|基础篇--Linux内存是怎么工作的？</title>
      <link>https://zsy619.github.io/post/15%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E5%86%85%E5%AD%98%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84/</link>
      <pubDate>Sat, 06 Jun 2020 10:04:02 +0800</pubDate>
      <guid>https://zsy619.github.io/post/15%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E5%86%85%E5%AD%98%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84/</guid>
      <description>内存定义 内存主要用来存储系统和应用程序的指令、数据、缓存等。&#xA;内存映射 虚拟地址空间：是连续的，不同字长的处理器，地址空间范围不同 内核空间 用户空间 内存映射：就是将虚拟内存地址映射到物理内存地址 缺页异常：当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异&#xA;页：一个内存映射的最小单位也就是页，通常是 4 KB 大小。这样，每一次内存映射，都需要关联 4 KB 或者 4KB 整数倍的内存空间。</description>
    </item>
    <item>
      <title>16|基础篇怎么理解内存中的Buffer和Cache？</title>
      <link>https://zsy619.github.io/post/16%E5%9F%BA%E7%A1%80%E7%AF%87%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%AD%E7%9A%84Buffer%E5%92%8CCache/</link>
      <pubDate>Sat, 06 Jun 2020 16:38:42 +0800</pubDate>
      <guid>https://zsy619.github.io/post/16%E5%9F%BA%E7%A1%80%E7%AF%87%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%AD%E7%9A%84Buffer%E5%92%8CCache/</guid>
      <description>free数据来源 Buffers 是内核缓冲区用到的内存，对应 /proc/meminfo 中的Buffers值 Cache 是内核页缓存和Slab用到的内存，对应 /proc/meminfo 中Cached与SReclaimable之和 $ watch cat /proc/meminfo 【注】网上的结论可能是对的，但是很可能跟你的环境并不匹配。最简单来说，同一个指标的具体含义，就可能因为内核版本、性能工具版本的不同而有挺大差别。这也是为什么，我总在专栏中强调通用思路和方法，而不是让你死记结论。对于案例实践来说，机器环境就是我们的最大限制。</description>
    </item>
    <item>
      <title>17|案例篇--如何利用系统缓存优化程序的运行效率？</title>
      <link>https://zsy619.github.io/post/17%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%BF%90%E8%A1%8C%E6%95%88%E7%8E%87/</link>
      <pubDate>Tue, 09 Jun 2020 10:04:02 +0800</pubDate>
      <guid>https://zsy619.github.io/post/17%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%BF%90%E8%A1%8C%E6%95%88%E7%8E%87/</guid>
      <description>缓存命中率 缓存命中率，是指直接通过缓存获取数据的请求次数，占所有数据请求次数的百分比。 命中率越高，表示使用缓存带来的收益越高，应用程序的性能也就越好。 缓存是现在所有高并发系统必需的核心模块，主要作用就是把经常访问的数据（也就是热点数据），提前读入到内存中。 这样，下次访问时就可以直接从内存读取数据，而不需要经过硬盘，从而加快应用程序的响应速度。 这两个工具都是 bcc 软件包的一部分，它们基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，来跟踪内核中管理的缓存，并输出缓存的使用和命中情况。</description>
    </item>
    <item>
      <title>18|案例篇--内存泄漏了，我该如何定位和处理？</title>
      <link>https://zsy619.github.io/post/18%E6%A1%88%E4%BE%8B%E7%AF%87%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E4%BA%86%E6%88%91%E8%AF%A5%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E5%92%8C%E5%A4%84%E7%90%86/</link>
      <pubDate>Tue, 09 Jun 2020 10:07:13 +0800</pubDate>
      <guid>https://zsy619.github.io/post/18%E6%A1%88%E4%BE%8B%E7%AF%87%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E4%BA%86%E6%88%91%E8%AF%A5%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E5%92%8C%E5%A4%84%E7%90%86/</guid>
      <description>内存的分配和回收 事先并不知道数据大小，所以你就要用到标准库函数 malloc() ， 在程序中动态分配内存。这时候，系统就会从内存空间的堆中分配内存。&#xA;堆内存由应用程序自己来分配和管理。除非程序退出，这些堆内存并不会被系统自动释放，而是需要应用程序明确调用库函数 free() 来释放它们。如果应用程序没有正确释放堆内存，就会造成内存泄漏。&#xA;只读段，包括程序的代码和常量，由于是只读的，不会再去分配新的内存，所以也不会产生内存泄漏。 数据段，包括全局变量和静态变量，这些变量在定义时就已经确定了大小，所以也不会产生内存泄漏。 最后一个内存映射段，包括动态链接库和共享内存，其中共享内存由程序动态分配和管理。所以，如果程序在分配后忘了回收，就会导致跟堆内存类似的泄漏问题。 内存泄漏的危害非常大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用。内存泄漏不断累积，甚至会耗尽系统内存。</description>
    </item>
    <item>
      <title>19|案例篇--为什么系统的Swap变高了（上）</title>
      <link>https://zsy619.github.io/post/19%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E7%B3%BB%E7%BB%9F%E7%9A%84Swap%E5%8F%98%E9%AB%98%E4%BA%86%E4%B8%8A/</link>
      <pubDate>Tue, 09 Jun 2020 10:56:15 +0800</pubDate>
      <guid>https://zsy619.github.io/post/19%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E7%B3%BB%E7%BB%9F%E7%9A%84Swap%E5%8F%98%E9%AB%98%E4%BA%86%E4%B8%8A/</guid>
      <description>文件页（File-backed Page） 大部分文件页，都可以直接回收，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。&#xA;可以在应用程序中，通过系统调用 fsync ，把脏页同步到磁盘中； 也可以交给系统，由内核线程 pdflush 负责这些脏页的刷新。 Swap 原理 它包括换出和换入两个过程。</description>
    </item>
    <item>
      <title>20|案例篇--为什么系统的Swap变高了（下）</title>
      <link>https://zsy619.github.io/post/20%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E7%B3%BB%E7%BB%9F%E7%9A%84Swap%E5%8F%98%E9%AB%98%E4%BA%86%E4%B8%8B/</link>
      <pubDate>Tue, 09 Jun 2020 10:57:42 +0800</pubDate>
      <guid>https://zsy619.github.io/post/20%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E7%B3%BB%E7%BB%9F%E7%9A%84Swap%E5%8F%98%E9%AB%98%E4%BA%86%E4%B8%8B/</guid>
      <description>在内存资源紧张时，Linux 会通过 Swap ，把不常访问的匿名页换出到磁盘中，下次访问的时候再从磁盘换入到内存中来。你可以设置 /proc/sys/vm/min_free_kbytes，来调整系统定期回收内存的阈值；也可以设置 /proc/sys/vm/swappiness，来调整文件页和匿名页的回收倾向。&#xA;当 Swap 变高时，你可以用 sar、/proc/zoneinfo、/proc/pid/status 等方法，查看系统和进程的内存使用情况，进而找出 Swap 升高的根源和受影响的进程。</description>
    </item>
    <item>
      <title>21|套路篇--如何“快准狠”找到系统内存的问题？</title>
      <link>https://zsy619.github.io/post/21%E5%A5%97%E8%B7%AF%E7%AF%87%E5%A6%82%E4%BD%95%E5%BF%AB%E5%87%86%E7%8B%A0%E6%89%BE%E5%88%B0%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 09 Jun 2020 11:36:16 +0800</pubDate>
      <guid>https://zsy619.github.io/post/21%E5%A5%97%E8%B7%AF%E7%AF%87%E5%A6%82%E4%BD%95%E5%BF%AB%E5%87%86%E7%8B%A0%E6%89%BE%E5%88%B0%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      <description>内存性能指标 系统内存使用情况：已用内存、剩余内存、共享内存、可用内存、缓存和缓冲区的用量&#xA;已用内存和剩余内存很容易理解，就是已经使用和还未使用的内存。 共享内存是通过 tmpfs 实现的，所以它的大小也就是 tmpfs 使用的内存大小。tmpfs 其实也是一种特殊的缓存。 可用内存是新进程可以使用的最大内存，它包括剩余内存和可回收缓存。 缓存包括两部分，一部分是磁盘读取文件的页缓存，用来缓存从磁盘读取的数据，可以加快以后再次访问的速度。 另一部分，则是 Slab 分配器中的可回收内存。缓冲区是对原始磁盘块的临时存储，用来缓存将要写入磁盘的数据。这样，内核就可以把分散的写集中起来，统一优化磁盘写入。 进程内存使用情况：进程的虚拟内存、常驻内存、共享内存以及 Swap 内存</description>
    </item>
    <item>
      <title>22|答疑（三）文件系统与磁盘的区别是什么？</title>
      <link>https://zsy619.github.io/post/22%E7%AD%94%E7%96%91%E4%B8%89%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%A3%81%E7%9B%98%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88/</link>
      <pubDate>Tue, 09 Jun 2020 11:36:54 +0800</pubDate>
      <guid>https://zsy619.github.io/post/22%E7%AD%94%E7%96%91%E4%B8%89%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%A3%81%E7%9B%98%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88/</guid>
      <description>问题 1：内存回收与 OOM 怎么理解 LRU 内存回收？ 回收后的内存又到哪里去了？ OOM 是按照虚拟内存还是实际内存来打分？ 怎么估计应用程序的最小内存？ 一旦发现内存紧张，系统会通过三种方式回收内存。</description>
    </item>
    <item>
      <title>23|基础篇--Linux文件系统是怎么工作的？</title>
      <link>https://zsy619.github.io/post/23%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84/</link>
      <pubDate>Thu, 11 Jun 2020 09:56:56 +0800</pubDate>
      <guid>https://zsy619.github.io/post/23%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84/</guid>
      <description>索引节点和目录项 Linux 文件系统为每个文件都分配两个数据结构，索引节点（index node）和目录项（directory entry）。它们主要用来记录文件的元信息和目录结构。&#xA;索引节点，简称为 inode，用来记录文件的元数据，比如 inode 编号、文件大小、访问权限、修改日期、数据的位置等。索引节点和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中。所以记住，索引节点同样占用磁盘空间。 目录项，简称为 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的关联关系。多个关联的目录项，就构成了文件系统的目录结构。不过，不同于索引节点，目录项是由内核维护的一个内存数据结构，所以通常也被叫做目录项缓存。 索引节点是每个文件的唯一标志，而目录项维护的正是文件系统的树状结构。目录项和索引节点的关系是多对一，可简单理解为，一个文件可以有多个别名。 索引节点和目录项纪录了文件的元数据，以及文件间的目录关系 磁盘读写的最小单位是扇区，然而扇区只有 512B 大小 文件系统又把连续的扇区组成了逻辑块，然后每次都以逻辑块为最小单元，来管理数据。 常见的逻辑块大小为 4KB，也就是由连续的 8 个扇区组成。 第一，目录项本身就是一个内存缓存，而索引节点则是存储在磁盘中的数据。 第二，磁盘在执行文件系统格式化时，会被分成三个存储区域，超级块、索引节点区和数据块区。其中， 超级块，存储整个文件系统的状态。 索引节点区，用来存储索引节点。 数据块区，则用来存储文件数据。 虚拟文件系统 linux文件系统四要素：目录项、索引节点、逻辑块以及超级块</description>
    </item>
    <item>
      <title>24|基础篇--Linux磁盘I/O是怎么工作的（上）</title>
      <link>https://zsy619.github.io/post/24%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E7%A3%81%E7%9B%98IO%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%8A/</link>
      <pubDate>Thu, 11 Jun 2020 10:29:13 +0800</pubDate>
      <guid>https://zsy619.github.io/post/24%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E7%A3%81%E7%9B%98IO%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%8A/</guid>
      <description>磁盘 磁盘是可以持久化存储的设备，根据存储介质的不同，常见磁盘可以分为两类：机械磁盘和固态磁盘。&#xA;第一类，机械磁盘，也称为硬盘驱动器（Hard Disk Driver），通常缩写为 HDD。机械磁盘主要由盘片和读写磁头组成，数据就存储在盘片的环状磁道中。在读写数据前，需要移动读写磁头，定位到数据所在的磁道，然后才能访问数据。 第二类，固态磁盘（Solid State Disk），通常缩写为 SSD，由固态电子元器件组成。固态磁盘不需要磁道寻址，所以，不管是连续 I/O，还是随机 I/O 的性能，都比机械磁盘要好得多。 无论机械磁盘，还是固态磁盘，相同磁盘的随机 I/O 都要比连续 I/O 慢很多</description>
    </item>
    <item>
      <title>25|基础篇--Linux磁盘I/O是怎么工作的（下）</title>
      <link>https://zsy619.github.io/post/25%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E7%A3%81%E7%9B%98IO%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%8B/</link>
      <pubDate>Thu, 11 Jun 2020 10:47:19 +0800</pubDate>
      <guid>https://zsy619.github.io/post/25%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E7%A3%81%E7%9B%98IO%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%8B/</guid>
      <description>磁盘性能指标 使用率、饱和度、IOPS、吞吐量以及响应时间等。这五个指标，是衡量磁盘性能的基本指标。&#xA;使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈。 饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求。 IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。 吞吐量，是指每秒的 I/O 请求大小。 响应时间，是指 I/O 请求从发出到收到响应的间隔时间。 性能测试工具 fio 磁盘 I/O 观测 iostat 是最常用的磁盘 I/O 性能观测工具，它提供了每个磁盘的使用率、IOPS、吞吐量等各种常见的性能指标，这些指标实际上来自 /proc/diskstats。</description>
    </item>
    <item>
      <title>26|案例篇--如何找出狂打日志的“内鬼”？</title>
      <link>https://zsy619.github.io/post/26%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E6%89%BE%E5%87%BA%E7%8B%82%E6%89%93%E6%97%A5%E5%BF%97%E7%9A%84%E5%86%85%E9%AC%BC/</link>
      <pubDate>Wed, 17 Jun 2020 08:36:15 +0800</pubDate>
      <guid>https://zsy619.github.io/post/26%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E6%89%BE%E5%87%BA%E7%8B%82%E6%89%93%E6%97%A5%E5%BF%97%E7%9A%84%E5%86%85%E9%AC%BC/</guid>
      <description>文件系统、通用块层以及设备层，就构成了 Linux 的存储 I/O 栈。&#xA;为了优化文件访问的性能，采用页缓存、索引节点缓存、目录项缓存等多种缓存机制，减少对下层块设备的直接调用。&#xA;同样的，为了优化块设备的访问效率，使用缓冲区来缓存块设备的数据。&#xA;$ strace -p 18940 strace: Process 18940 attached .</description>
    </item>
    <item>
      <title>27|案例篇--为什么我的磁盘I/O延迟很高？</title>
      <link>https://zsy619.github.io/post/27%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E7%9A%84%E7%A3%81%E7%9B%98IO%E5%BB%B6%E8%BF%9F%E5%BE%88%E9%AB%98/</link>
      <pubDate>Wed, 17 Jun 2020 08:42:18 +0800</pubDate>
      <guid>https://zsy619.github.io/post/27%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E7%9A%84%E7%A3%81%E7%9B%98IO%E5%BB%B6%E8%BF%9F%E5%BE%88%E9%AB%98/</guid>
      <description>用 iostat ，确认是否有 I/O 性能瓶颈。再用 strace 和 lsof ，来定位应用程序以及它正在写入的日志文件路径。最后通过应用程序的接口调整日志级别，完美解决 I/O 问题。 $ top top - 14:27:02 up 10:30, 1 user, load average: 1.</description>
    </item>
    <item>
      <title>28|案例篇--一个SQL查询要15秒，这是怎么回事？</title>
      <link>https://zsy619.github.io/post/28%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%80%E4%B8%AASQL%E6%9F%A5%E8%AF%A2%E8%A6%8115%E7%A7%92%E8%BF%99%E6%98%AF%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B/</link>
      <pubDate>Wed, 17 Jun 2020 08:51:46 +0800</pubDate>
      <guid>https://zsy619.github.io/post/28%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%80%E4%B8%AASQL%E6%9F%A5%E8%AF%A2%E8%A6%8115%E7%A7%92%E8%BF%99%E6%98%AF%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B/</guid>
      <description>运行下面的 docker exec 命令，进入 MySQL 的命令行界面：&#xA;$ docker exec -i -t mysql mysql .</description>
    </item>
    <item>
      <title>29|案例篇--Redis响应严重延迟，如何解决？</title>
      <link>https://zsy619.github.io/post/29%E6%A1%88%E4%BE%8B%E7%AF%87Redis%E5%93%8D%E5%BA%94%E4%B8%A5%E9%87%8D%E5%BB%B6%E8%BF%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/</link>
      <pubDate>Wed, 17 Jun 2020 09:04:18 +0800</pubDate>
      <guid>https://zsy619.github.io/post/29%E6%A1%88%E4%BE%8B%E7%AF%87Redis%E5%93%8D%E5%BA%94%E4%B8%A5%E9%87%8D%E5%BB%B6%E8%BF%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/</guid>
      <description># -f表示跟踪子进程和子线程，-T表示显示系统调用的时长，-tt表示显示跟踪时间 $ strace -f -T -tt -p 9085 [pid 9085] 14:20:16.</description>
    </item>
    <item>
      <title>30|套路篇--如何迅速分析出系统I/O的瓶颈在哪里？</title>
      <link>https://zsy619.github.io/post/30%E5%A5%97%E8%B7%AF%E7%AF%87%E5%A6%82%E4%BD%95%E8%BF%85%E9%80%9F%E5%88%86%E6%9E%90%E5%87%BA%E7%B3%BB%E7%BB%9FIO%E7%9A%84%E7%93%B6%E9%A2%88%E5%9C%A8%E5%93%AA%E9%87%8C/</link>
      <pubDate>Wed, 17 Jun 2020 09:17:18 +0800</pubDate>
      <guid>https://zsy619.github.io/post/30%E5%A5%97%E8%B7%AF%E7%AF%87%E5%A6%82%E4%BD%95%E8%BF%85%E9%80%9F%E5%88%86%E6%9E%90%E5%87%BA%E7%B3%BB%E7%BB%9FIO%E7%9A%84%E7%93%B6%E9%A2%88%E5%9C%A8%E5%93%AA%E9%87%8C/</guid>
      <description>性能指标 文件系统 I/O 性能指标 首先，最容易想到的是存储空间的使用情况，包括容量、使用量以及剩余空间等。我们通常也称这些为磁盘空间的使用量，因为文件系统的数据最终还是存储在磁盘上。 容易忽略的是索引节点的使用情况，它也包括容量、使用量以及剩余量等三个指标。如果文件系统中存储过多的小文件，就可能碰到索引节点容量已满的问题。 其次，你应该想到的是前面多次提到过的缓存使用情况，包括页缓存、目录项缓存、索引节点缓存以及各个具体文件系统（如 ext4、XFS 等）的缓存。这些缓存会使用速度更快的内存，用来临时存储文件数据或者文件系统的元数据，从而可以减少访问慢速磁盘的次数。 磁盘 I/O 性能指标 使用率，是指磁盘忙处理 I/O 请求的百分比。过高的使用率（比如超过 60%）通常意味着磁盘 I/O 存在性能瓶颈。 IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。 吞吐量，是指每秒的 I/O 请求大小。 响应时间，是指从发出 I/O 请求到收到响应的间隔时间。 性能工具 第一，在文件系统的原理中，我介绍了查看文件系统容量的工具 df。它既可以查看文件系统数据的空间容量，也可以查看索引节点的容量。至于文件系统缓存，我们通过 /proc/meminfo、/proc/slabinfo 以及 slabtop 等各种来源，观察页缓存、目录项缓存、索引节点缓存以及具体文件系统的缓存情况。 第二，在磁盘 I/O 的原理中，我们分别用 iostat 和 pidstat 观察了磁盘和进程的 I/O 情况。它们都是最常用的 I/O 性能分析工具。通过 iostat ，我们可以得到磁盘的 I/O 使用率、吞吐量、响应时间以及 IOPS 等性能指标；而通过 pidstat ，则可以观察到进程的 I/O 吞吐量以及块设备 I/O 的延迟等。 第三，在狂打日志的案例中，我们先用 top 查看系统的 CPU 使用情况，发现 iowait 比较高；然后，又用 iostat 发现了磁盘的 I/O 使用率瓶颈，并用 pidstat 找出了大量 I/O 的进程；最后，通过 strace 和 lsof，我们找出了问题进程正在读写的文件，并最终锁定性能问题的来源——原来是进程在狂打日志。 第四，在磁盘 I/O 延迟的单词热度案例中，我们同样先用 top、iostat ，发现磁盘有 I/O 瓶颈，并用 pidstat 找出了大量 I/O 的进程。可接下来，想要照搬上次操作的我们失败了。在随后的 strace 命令中，我们居然没看到 write 系统调用。于是，我们换了一个思路，用新工具 filetop 和 opensnoop ，从内核中跟踪系统调用，最终找出瓶颈的来源。 最后，在 MySQL 和 Redis 的案例中，同样的思路，我们先用 top、iostat 以及 pidstat ，确定并找出 I/O 性能问题的瓶颈来源，它们正是 mysqld 和 redis-server。随后，我们又用 strace+lsof 找出了它们正在读写的文件。 性能指标和工具的联系 从 I/O 指标出发，你更容易把性能工具同系统工作原理关联起来，对性能问题有宏观的认识和把握。 而从性能工具出发，可以让你更快上手使用工具，迅速找出我们想观察的性能指标。特别是在工具有限的情况下，我们更要充分利用好手头的每一个工具，少量工具也要尽力挖掘出大量信息。 第一个维度，从文件系统和磁盘 I/O 的性能指标出发。换句话说，当你想查看某个性能指标时，要清楚知道，哪些工具可以做到。 第二个维度，从工具出发。也就是当你已经安装了某个工具后，要知道这个工具能提供哪些指标。 如何迅速分析 I/O 的性能瓶颈 想弄清楚性能指标的关联性，就要通晓每种性能指标的工作原理。</description>
    </item>
    <item>
      <title>31|套路篇--磁盘I/O性能优化的几个思路</title>
      <link>https://zsy619.github.io/post/31%E5%A5%97%E8%B7%AF%E7%AF%87%E7%A3%81%E7%9B%98IO%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Wed, 17 Jun 2020 09:25:59 +0800</pubDate>
      <guid>https://zsy619.github.io/post/31%E5%A5%97%E8%B7%AF%E7%AF%87%E7%A3%81%E7%9B%98IO%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF/</guid>
      <description> I/O 基准测试 I/O 性能优化 应用程序优化 第一，可以用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。 第二，可以借助缓存 I/O ，充分利用系统缓存，降低实际 I/O 的次数。 第三，可以在应用程序内部构建自己的缓存，或者用 Redis 这类外部缓存系统。这样，一方面，能在应用程序内部，控制缓存的数据和生命周期；另一方面，也能降低其他应用程序使用缓存对自身的影响。 第四，在需要频繁读写同一块磁盘空间时，可以用 mmap 代替 read/write，减少内存的拷贝次数。 第五，在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC。 第六，在多个应用程序共享相同磁盘时，为了保证 I/O 不被某个应用完全占用，推荐你使用 cgroups 的 I/O 子系统，来限制进程 / 进程组的 IOPS 以及吞吐量。 最后，在使用 CFQ 调度器时，可以用 ionice 来调整进程的 I/O 调度优先级，特别是提高核心应用的 I/O 优先级。ionice 支持三个优先级类：Idle、Best-effort 和 Realtime。其中， Best-effort 和 Realtime 还分别支持 0-7 的级别，数值越小，则表示优先级别越高。 文件系统优化 第一，你可以根据实际负载场景的不同，选择最适合的文件系统。比如 Ubuntu 默认使用 ext4 文件系统，而 CentOS 7 默认使用 xfs 文件系统。 第二，在选好文件系统后，还可以进一步优化文件系统的配置选项，包括文件系统的特性（如 ext_attr、dir_index）、日志模式（如 journal、ordered、writeback）、挂载选项（如 noatime）等等。 第三，可以优化文件系统的缓存。 最后，在不需要持久化时，你还可以用内存文件系统 tmpfs，以获得更好的 I/O 性能 。tmpfs 把数据直接保存在内存中，而不是磁盘中。比如 /dev/shm/ ，就是大多数 Linux 默认配置的一个内存文件系统，它的大小默认为总内存的一半。 磁盘优化 第一，最简单有效的优化方法，就是换用性能更好的磁盘，比如用 SSD 替代 HDD。 第二，我们可以使用 RAID ，把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列。这样做既可以提高数据的可靠性，又可以提升数据的访问性能。 第三，针对磁盘和应用程序 I/O 模式的特征，我们可以选择最适合的 I/O 调度算法。比方说，SSD 和虚拟机中的磁盘，通常用的是 noop 调度算法。而数据库应用，我更推荐使用 deadline 算法。 第四，我们可以对应用程序的数据，进行磁盘级别的隔离。比如，我们可以为日志、数据库等 I/O 压力比较重的应用，配置单独的磁盘。 第五，在顺序读比较多的场景中，我们可以增大磁盘的预读数据，比如，你可以通过下面两种方法，调整 /dev/sdb 的预读大小。 第六，我们可以优化内核块设备 I/O 的选项。比如，可以调整磁盘队列的长度 /sys/block/sdb/queue/nr_requests，适当增大队列长度，可以提升磁盘的吞吐量（当然也会导致 I/O 延迟增大）。 </description>
    </item>
    <item>
      <title>32|答疑（四）--阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系</title>
      <link>https://zsy619.github.io/post/32%E7%AD%94%E7%96%91%E5%9B%9B%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E-IO-%E4%B8%8E%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5-IO-%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB/</link>
      <pubDate>Wed, 17 Jun 2020 09:32:29 +0800</pubDate>
      <guid>https://zsy619.github.io/post/32%E7%AD%94%E7%96%91%E5%9B%9B%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E-IO-%E4%B8%8E%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5-IO-%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB/</guid>
      <description>问题 1：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系 所谓阻塞 I/O，是指应用程序在执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程，不能执行其他任务。 所谓非阻塞 I/O，是指应用程序在执行 I/O 操作后，不会阻塞当前的线程，可以继续执行其他的任务。 所谓同步 I/O，是指收到 I/O 请求后，系统不会立刻响应应用程序；等到处理完成，系统才会通过系统调用的方式，告诉应用程序 I/O 结果。 所谓异步 I/O，是指收到 I/O 请求后，系统会先告诉应用程序 I/O 请求已经收到，随后再去异步处理；等处理完成后，系统再通过事件通知的方式，告诉应用程序结果。 在 Linux I/O 调用中，</description>
    </item>
    <item>
      <title>33|关于 Linux 网络，你必须知道这些（上）</title>
      <link>https://zsy619.github.io/post/33%E5%85%B3%E4%BA%8E-Linux-%E7%BD%91%E7%BB%9C%E4%BD%A0%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E8%BF%99%E4%BA%9B%E4%B8%8A/</link>
      <pubDate>Sun, 31 May 2020 17:16:28 +0800</pubDate>
      <guid>https://zsy619.github.io/post/33%E5%85%B3%E4%BA%8E-Linux-%E7%BD%91%E7%BB%9C%E4%BD%A0%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E8%BF%99%E4%BA%9B%E4%B8%8A/</guid>
      <description>网络模型 开放式系统互联通信参考模型（Open System Interconnection Reference Model），简称为 OSI 网络模型。&#xA;OSI 模型把网络互联的框架分为应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层等七层，每个层负责不同的功能。其中，</description>
    </item>
    <item>
      <title>34|关于 Linux 网络，你必须知道这些（下）</title>
      <link>https://zsy619.github.io/post/34%E5%85%B3%E4%BA%8E-Linux-%E7%BD%91%E7%BB%9C%E4%BD%A0%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E8%BF%99%E4%BA%9B%E4%B8%8B/</link>
      <pubDate>Sun, 31 May 2020 17:16:28 +0800</pubDate>
      <guid>https://zsy619.github.io/post/34%E5%85%B3%E4%BA%8E-Linux-%E7%BD%91%E7%BB%9C%E4%BD%A0%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E8%BF%99%E4%BA%9B%E4%B8%8B/</guid>
      <description>性能指标 通常用带宽、吞吐量、延时、PPS（Packet Per Second）等指标衡量网络的性能。&#xA;带宽，表示链路的最大传输速率，单位通常为 b/s （比特 / 秒）。 吞吐量，表示单位时间内成功传输的数据量，单位通常为 b/s（比特 / 秒）或者 B/s（字节 / 秒）。吞吐量受带宽限制，而吞吐量 / 带宽，也就是该网络的使用率。 延时，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。在不同场景中，这一指标可能会有不同含义。比如，它可以表示，建立连接需要的时间（比如 TCP 握手延时），或一个数据包往返所需的时间（比如 RTT）。 PPS，是 Packet Per Second（包 / 秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力，比如硬件交换机，通常可以达到线性转发（即 PPS 可以达到或者接近理论最大值）。而基于 Linux 服务器的转发，则容易受网络包大小的影响。 除了这些指标，网络的可用性（网络能否正常通信）、并发连接数（TCP 连接数量）、丢包率（丢包百分比）、重传率（重新传输的网络包比例）等也是常用的性能指标。</description>
    </item>
    <item>
      <title>35|基础篇：C10K 和 C1000K 回顾</title>
      <link>https://zsy619.github.io/post/35%E5%9F%BA%E7%A1%80%E7%AF%87C10K-%E5%92%8C-C1000K-%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Sun, 31 May 2020 17:16:28 +0800</pubDate>
      <guid>https://zsy619.github.io/post/35%E5%9F%BA%E7%A1%80%E7%AF%87C10K-%E5%92%8C-C1000K-%E5%9B%9E%E9%A1%BE/</guid>
      <description>C10K 和 C1000K 的首字母 C 是 Client 的缩写。C10K 就是单机同时处理 1 万个请求（并发连接 1 万）的问题，而 C1000K 也就是单机支持处理 100 万个请求（并发连接 100 万）的问题。</description>
    </item>
    <item>
      <title>36|套路篇：怎么评估系统的网络性能？</title>
      <link>https://zsy619.github.io/post/36%E5%A5%97%E8%B7%AF%E7%AF%87%E6%80%8E%E4%B9%88%E8%AF%84%E4%BC%B0%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD/</link>
      <pubDate>Tue, 07 Jul 2020 11:13:12 +0800</pubDate>
      <guid>https://zsy619.github.io/post/36%E5%A5%97%E8%B7%AF%E7%AF%87%E6%80%8E%E4%B9%88%E8%AF%84%E4%BC%B0%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD/</guid>
      <description>要实现 C10M，就不是增加物理资源、调优内核和应用程序可以解决的问题了。这时内核中冗长的网络协议栈就成了最大的负担。&#xA;需要用 XDP 方式，在内核协议栈之前，先处理网络包。 或基于 DPDK ，直接跳过网络协议栈，在用户空间通过轮询的方式处理。 性能指标回顾 首先，带宽，表示链路的最大传输速率，单位是 b/s（比特 / 秒）。在你为服务器选购网卡时，带宽就是最核心的参考指标。常用的带宽有 1000M、10G、40G、100G 等。</description>
    </item>
    <item>
      <title>37|案例篇：DNS 解析时快时慢，我该怎么办？</title>
      <link>https://zsy619.github.io/post/37%E6%A1%88%E4%BE%8B%E7%AF%87DNS-%E8%A7%A3%E6%9E%90%E6%97%B6%E5%BF%AB%E6%97%B6%E6%85%A2%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</link>
      <pubDate>Tue, 07 Jul 2020 11:25:42 +0800</pubDate>
      <guid>https://zsy619.github.io/post/37%E6%A1%88%E4%BE%8B%E7%AF%87DNS-%E8%A7%A3%E6%9E%90%E6%97%B6%E5%BF%AB%E6%97%B6%E6%85%A2%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</guid>
      <description>Linux 网络基于 TCP/IP 协议栈构建，而在协议栈的不同层，我们所关注的网络性能也不尽相同。&#xA;在应用层，我们关注的是应用程序的并发连接数、每秒请求数、处理延迟、错误数等，可以使用 wrk、JMeter 等工具，模拟用户的负载，得到想要的测试结果。&#xA;而在传输层，我们关注的是 TCP、UDP 等传输层协议的工作状况，比如 TCP 连接数、 TCP 重传、TCP 错误数等。此时，你可以使用 iperf、netperf 等，来测试 TCP 或 UDP 的性能。</description>
    </item>
    <item>
      <title>38|案例篇：怎么使用 tcpdump 和 Wireshark 分析网络流量？</title>
      <link>https://zsy619.github.io/post/38%E6%A1%88%E4%BE%8B%E7%AF%87%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8-tcpdump-%E5%92%8C-Wireshark-%E5%88%86%E6%9E%90%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F/</link>
      <pubDate>Tue, 07 Jul 2020 15:38:35 +0800</pubDate>
      <guid>https://zsy619.github.io/post/38%E6%A1%88%E4%BE%8B%E7%AF%87%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8-tcpdump-%E5%92%8C-Wireshark-%E5%88%86%E6%9E%90%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F/</guid>
      <description>可以借助 nslookup 或者 dig 的调试功能，分析 DNS 的解析过程，再配合 ping 等工具调试 DNS 服务器的延迟，从而定位出性能瓶颈。通常，你可以用缓存、预取、HTTPDNS 等方法，优化 DNS 的性能。</description>
    </item>
    <item>
      <title>39|案例篇：怎么缓解 DDoS 攻击带来的性能下降问题？</title>
      <link>https://zsy619.github.io/post/39%E6%A1%88%E4%BE%8B%E7%AF%87%E6%80%8E%E4%B9%88%E7%BC%93%E8%A7%A3-DDoS-%E6%94%BB%E5%87%BB%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%80%A7%E8%83%BD%E4%B8%8B%E9%99%8D%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 07 Jul 2020 16:02:59 +0800</pubDate>
      <guid>https://zsy619.github.io/post/39%E6%A1%88%E4%BE%8B%E7%AF%87%E6%80%8E%E4%B9%88%E7%BC%93%E8%A7%A3-DDoS-%E6%94%BB%E5%87%BB%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%80%A7%E8%83%BD%E4%B8%8B%E9%99%8D%E9%97%AE%E9%A2%98/</guid>
      <description>DDoS 简介 DDoS 的前身是 DoS（Denail of Service），即拒绝服务攻击，指利用大量的合理请求，来占用过多的目标资源，从而使目标服务无法响应正常请求。&#xA;DDoS（Distributed Denial of Service） 则是在 DoS 的基础上，采用了分布式架构，利用多台主机同时攻击目标主机。这样，即使目标服务部署了网络防御设备，面对大量网络请求时，还是无力应对。</description>
    </item>
    <item>
      <title>40|案例篇：网络请求延迟变大了，我该怎么办？</title>
      <link>https://zsy619.github.io/post/40%E6%A1%88%E4%BE%8B%E7%AF%87%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F%E5%8F%98%E5%A4%A7%E4%BA%86%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</link>
      <pubDate>Tue, 07 Jul 2020 16:18:24 +0800</pubDate>
      <guid>https://zsy619.github.io/post/40%E6%A1%88%E4%BE%8B%E7%AF%87%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F%E5%8F%98%E5%A4%A7%E4%BA%86%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</guid>
      <description>除了 DDoS 会带来网络延迟增大外，我想，你肯定见到过不少其他原因导致的网络延迟，比如&#xA;网络传输慢，导致延迟； Linux 内核协议栈报文处理慢，导致延迟； 应用程序数据处理慢，导致延迟等等。 网络延迟 网络数据传输所用的时间。不过要注意，这个时间可能是单向的，指从源地址发送到目的地址的单程时间；也可能是双向的，即从源地址发送到目的地址，然后又从目的地址发回响应，这个往返全程所用的时间。&#xA;通常，我们更常用的是双向的往返通信延迟，比如 ping 测试的结果，就是往返延时 RTT（Round-Trip Time）。</description>
    </item>
    <item>
      <title>41|案例篇：如何优化 NAT 性能？（上）</title>
      <link>https://zsy619.github.io/post/41%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96-NAT-%E6%80%A7%E8%83%BD%E4%B8%8A/</link>
      <pubDate>Tue, 07 Jul 2020 16:26:49 +0800</pubDate>
      <guid>https://zsy619.github.io/post/41%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96-NAT-%E6%80%A7%E8%83%BD%E4%B8%8A/</guid>
      <description>另一个可能导致网络延迟的因素，即网络地址转换（Network Address Translation），缩写为 NAT。&#xA;NAT 原理 NAT 技术可以重写 IP 数据包的源 IP 或者目的 IP，被普遍地用来解决公网 IP 地址短缺的问题。它的主要原理就是，网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，自然也就为局域网中的机器提供了安全隔离。</description>
    </item>
    <item>
      <title>42|案例篇：如何优化 NAT 性能？（下）</title>
      <link>https://zsy619.github.io/post/42%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96-NAT-%E6%80%A7%E8%83%BD%E4%B8%8B/</link>
      <pubDate>Tue, 07 Jul 2020 16:40:20 +0800</pubDate>
      <guid>https://zsy619.github.io/post/42%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96-NAT-%E6%80%A7%E8%83%BD%E4%B8%8B/</guid>
      <description>NAT 技术能够重写 IP 数据包的源 IP 或目的 IP，所以普遍用来解决公网 IP 地址短缺的问题。它可以让网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，也为局域网中机器起到安全隔离的作用。</description>
    </item>
    <item>
      <title>43|套路篇：网络性能优化的几个思路（上）</title>
      <link>https://zsy619.github.io/post/43%E5%A5%97%E8%B7%AF%E7%AF%87%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%E4%B8%8A/</link>
      <pubDate>Tue, 07 Jul 2020 16:43:11 +0800</pubDate>
      <guid>https://zsy619.github.io/post/43%E5%A5%97%E8%B7%AF%E7%AF%87%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%E4%B8%8A/</guid>
      <description>NAT 基于 Linux 内核的连接跟踪机制，实现了 IP 地址及端口号重写的功能，主要被用来解决公网 IP 地址短缺的问题。&#xA;在分析 NAT 性能问题时，可以先从内核连接跟踪模块 conntrack 角度来分析，比如用 systemtap、perf、netstat 等工具，以及 proc 文件系统中的内核选项，来分析网络协议栈的行为；然后，通过内核选项调优、切换到无状态 NAT、使用 DPDK 等方式，进行实际优化。</description>
    </item>
    <item>
      <title>44|套路篇：网络性能优化的几个思路（下）</title>
      <link>https://zsy619.github.io/post/44%E5%A5%97%E8%B7%AF%E7%AF%87%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%E4%B8%8B/</link>
      <pubDate>Tue, 07 Jul 2020 16:57:32 +0800</pubDate>
      <guid>https://zsy619.github.io/post/44%E5%A5%97%E8%B7%AF%E7%AF%87%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%E4%B8%8B/</guid>
      <description>网络性能优化 传输层 TCP 提供了面向连接的可靠传输服务。要优化 TCP，我们首先要掌握 TCP 协议的基本原理，比如流量控制、慢启动、拥塞避免、延迟确认以及状态流图（如下图所示）等。&#xA;第一类，在请求数比较大的场景下，你可能会看到大量处于 TIME_WAIT 状态的连接，它们会占用大量内存和端口资源。这时，我们可以优化与 TIME_WAIT 状态相关的内核选项，比如采取下面几种措施。</description>
    </item>
    <item>
      <title>45|答疑（五）：网络收发过程中，缓冲区位置在哪里？</title>
      <link>https://zsy619.github.io/post/45%E7%AD%94%E7%96%91%E4%BA%94%E7%BD%91%E7%BB%9C%E6%94%B6%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%BC%93%E5%86%B2%E5%8C%BA%E4%BD%8D%E7%BD%AE%E5%9C%A8%E5%93%AA%E9%87%8C/</link>
      <pubDate>Tue, 07 Jul 2020 17:09:43 +0800</pubDate>
      <guid>https://zsy619.github.io/post/45%E7%AD%94%E7%96%91%E4%BA%94%E7%BD%91%E7%BB%9C%E6%94%B6%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%BC%93%E5%86%B2%E5%8C%BA%E4%BD%8D%E7%BD%AE%E5%9C%A8%E5%93%AA%E9%87%8C/</guid>
      <description>问题 1：网络收发过程中缓冲区的位置 第一点，是网络收发过程中，收发队列和缓冲区位置的疑问。&#xA;网卡收发网络包时，通过 DMA 方式交互的环形缓冲区； 网卡中断处理程序为网络帧分配的，内核数据结构 sk_buff 缓冲区； 应用程序通过套接字接口，与网络协议栈交互时的套接字缓冲区。 其中，环形缓冲区，由于需要 DMA 与网卡交互，理应属于网卡设备驱动的范围。</description>
    </item>
    <item>
      <title>46|案例篇：为什么应用容器化后，启动慢了很多？</title>
      <link>https://zsy619.github.io/post/46%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E5%90%8E%E5%90%AF%E5%8A%A8%E6%85%A2%E4%BA%86%E5%BE%88%E5%A4%9A/</link>
      <pubDate>Thu, 09 Jul 2020 15:18:53 +0800</pubDate>
      <guid>https://zsy619.github.io/post/46%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E5%90%8E%E5%90%AF%E5%8A%A8%E6%85%A2%E4%BA%86%E5%BE%88%E5%A4%9A/</guid>
      <description>随着 Kubernetes、Docker 等技术的普及，越来越多的企业，都已经走上了应用程序容器化的道路。我相信，你在了解学习这些技术的同时，一定也听说过不少，基于 Docker 的微服务架构带来的各种优势，比如：&#xA;使用 Docker ，把应用程序以及相关依赖打包到镜像中后，部署和升级更快捷； 把传统的单体应用拆分成多个更小的微服务应用后，每个微服务的功能都更简单，并且可以单独管理和维护； 每个微服务都可以根据需求横向扩展。即使发生故障，也只是局部服务不可用，而不像以前那样，导致整个服务不可用。 案例 docker 启动 Tomat 应用：</description>
    </item>
    <item>
      <title>47|案例篇：服务器总是时不时丢包，我该怎么办？（上）</title>
      <link>https://zsy619.github.io/post/47%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%BB%E6%98%AF%E6%97%B6%E4%B8%8D%E6%97%B6%E4%B8%A2%E5%8C%85%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8A/</link>
      <pubDate>Thu, 09 Jul 2020 15:34:15 +0800</pubDate>
      <guid>https://zsy619.github.io/post/47%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%BB%E6%98%AF%E6%97%B6%E4%B8%8D%E6%97%B6%E4%B8%A2%E5%8C%85%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8A/</guid>
      <description>执行 docker ps 命令，查询容器的状态：&#xA;$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dae0202cc27e feisky/nginx:drop &amp;#34;/start.</description>
    </item>
    <item>
      <title>48|案例篇：服务器总是时不时丢包，我该怎么办？（下）</title>
      <link>https://zsy619.github.io/post/48%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%BB%E6%98%AF%E6%97%B6%E4%B8%8D%E6%97%B6%E4%B8%A2%E5%8C%85%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8B/</link>
      <pubDate>Thu, 09 Jul 2020 15:51:03 +0800</pubDate>
      <guid>https://zsy619.github.io/post/48%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%BB%E6%98%AF%E6%97%B6%E4%B8%8D%E6%97%B6%E4%B8%A2%E5%8C%85%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8B/</guid>
      <description>iptables 更简单的方法，就是直接查询 DROP 和 REJECT 等规则的统计信息，看看是否为 0。如果统计值不是 0 ，再把相关的规则拎出来进行分析。</description>
    </item>
    <item>
      <title>49|案例篇：内核线程 CPU 利用率太高，我该怎么办？</title>
      <link>https://zsy619.github.io/post/49%E6%A1%88%E4%BE%8B%E7%AF%87%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B-CPU-%E5%88%A9%E7%94%A8%E7%8E%87%E5%A4%AA%E9%AB%98%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</link>
      <pubDate>Thu, 09 Jul 2020 16:05:27 +0800</pubDate>
      <guid>https://zsy619.github.io/post/49%E6%A1%88%E4%BE%8B%E7%AF%87%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B-CPU-%E5%88%A9%E7%94%A8%E7%8E%87%E5%A4%AA%E9%AB%98%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/</guid>
      <description>内核线程 在 Linux 中，用户态进程的“祖先”，都是 PID 号为 1 的 init 进程。比如，现在主流的 Linux 发行版中，init 都是 systemd 进程；而其他的用户态进程，会通过 systemd 来进行管理。</description>
    </item>
    <item>
      <title>50|案例篇：动态追踪怎么用？（上）</title>
      <link>https://zsy619.github.io/post/50%E6%A1%88%E4%BE%8B%E7%AF%87%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%E6%80%8E%E4%B9%88%E7%94%A8%E4%B8%8A/</link>
      <pubDate>Mon, 13 Jul 2020 08:35:13 +0800</pubDate>
      <guid>https://zsy619.github.io/post/50%E6%A1%88%E4%BE%8B%E7%AF%87%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%E6%80%8E%E4%B9%88%E7%94%A8%E4%B8%8A/</guid>
      <description>动态追踪技术，通过探针机制，来采集内核或者应用程序的运行信息，从而可以不用修改内核和应用程序的代码，就获得丰富的信息，帮你分析、定位想要排查的问题。&#xA;以往，在排查和调试性能问题时，我们往往需要先为应用程序设置一系列的断点（比如使用 GDB），然后以手动或者脚本（比如 GDB 的 Python 扩展）的方式，在这些断点处分析应用程序的状态。或者，增加一系列的日志，从日志中寻找线索。&#xA;相比以往的进程级跟踪方法（比如 ptrace），动态追踪往往只会带来很小的性能损耗（通常在 5% 或者更少）。</description>
    </item>
    <item>
      <title>51|案例篇：动态追踪怎么用？（下）</title>
      <link>https://zsy619.github.io/post/51%E6%A1%88%E4%BE%8B%E7%AF%87%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%E6%80%8E%E4%B9%88%E7%94%A8%E4%B8%8B/</link>
      <pubDate>Tue, 14 Jul 2020 17:52:46 +0800</pubDate>
      <guid>https://zsy619.github.io/post/51%E6%A1%88%E4%BE%8B%E7%AF%87%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%E6%80%8E%E4%B9%88%E7%94%A8%E4%B8%8B/</guid>
      <description>在 Linux 系统中，常见的动态追踪方法包括 ftrace、perf、eBPF 以及 SystemTap 等。上节课，我们具体学习了 ftrace 的使用方法。&#xA;perf 我们前面使用 perf record/top 时，都是先对事件进行采样，然后再根据采样数，评估各个函数的调用频率。实际上，perf 的功能远不止于此。比如，</description>
    </item>
    <item>
      <title>52|案例篇：服务吞吐量下降很厉害，怎么分析？</title>
      <link>https://zsy619.github.io/post/52%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%90%9E%E5%90%90%E9%87%8F%E4%B8%8B%E9%99%8D%E5%BE%88%E5%8E%89%E5%AE%B3%E6%80%8E%E4%B9%88%E5%88%86%E6%9E%90/</link>
      <pubDate>Tue, 14 Jul 2020 18:12:19 +0800</pubDate>
      <guid>https://zsy619.github.io/post/52%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%90%9E%E5%90%90%E9%87%8F%E4%B8%8B%E9%99%8D%E5%BE%88%E5%8E%89%E5%AE%B3%E6%80%8E%E4%B9%88%E5%88%86%E6%9E%90/</guid>
      <description>使用 perf 配合火焰图寻找热点函数，是一个比较通用的性能定位方法，在很多场景中都可以使用。 如果这仍满足不了你的要求，那么在新版的内核中，eBPF 和 BCC 是最灵活的动态追踪方法。 而在旧版本内核，特别是在 RHEL 系统中，由于 eBPF 支持受限，SystemTap 和 ftrace 往往是更好的选择。 连接数优化 要查看 TCP 连接数的汇总情况，首选工具自然是 ss 命令。</description>
    </item>
    <item>
      <title>53|套路篇：系统监控的综合思路</title>
      <link>https://zsy619.github.io/post/53%E5%A5%97%E8%B7%AF%E7%AF%87%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E7%9A%84%E7%BB%BC%E5%90%88%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Thu, 16 Jul 2020 14:12:53 +0800</pubDate>
      <guid>https://zsy619.github.io/post/53%E5%A5%97%E8%B7%AF%E7%AF%87%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E7%9A%84%E7%BB%BC%E5%90%88%E6%80%9D%E8%B7%AF/</guid>
      <description>要做好监控，最核心的就是全面的、可量化的指标，这包括系统和应用两个方面。&#xA;USE 法 为你介绍一种专门用于性能监控的 USE（Utilization Saturation and Errors）法。USE 法把系统资源的性能指标，简化成了三个类别，即使用率、饱和度以及错误数。&#xA;使用率，表示资源用于服务的时间或容量百分比。100% 的使用率，表示容量已经用尽或者全部时间都用于服务。 饱和度，表示资源的繁忙程度，通常与等待队列的长度相关。100% 的饱和度，表示资源无法接受更多的请求。错误数表示发生错误的事件个数。 错误数越多，表明系统的问题越严重。 这三个类别的指标，涵盖了系统资源的常见性能瓶颈，所以常被用来快速定位系统资源的性能瓶颈。这样，无论是对 CPU、内存、磁盘和文件系统、网络等硬件资源，还是对文件描述符数、连接数、连接跟踪数等软件资源，USE 方法都可以帮你快速定位出，是哪一种系统资源出现了性能瓶颈。</description>
    </item>
    <item>
      <title>54|套路篇：应用监控的一般思路</title>
      <link>https://zsy619.github.io/post/54%E5%A5%97%E8%B7%AF%E7%AF%87%E5%BA%94%E7%94%A8%E7%9B%91%E6%8E%A7%E7%9A%84%E4%B8%80%E8%88%AC%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Thu, 16 Jul 2020 14:25:58 +0800</pubDate>
      <guid>https://zsy619.github.io/post/54%E5%A5%97%E8%B7%AF%E7%AF%87%E5%BA%94%E7%94%A8%E7%9B%91%E6%8E%A7%E7%9A%84%E4%B8%80%E8%88%AC%E6%80%9D%E8%B7%AF/</guid>
      <description>指标监控 应用程序的核心指标，不再是资源的使用情况，而是请求数、错误率和响应时间。&#xA;第一个，是应用进程的资源使用情况，比如进程占用的 CPU、内存、磁盘 I/O、网络等。使用过多的系统资源，导致应用程序响应缓慢或者错误数升高，是一个最常见的性能问题。&#xA;第二个，是应用程序之间调用情况，比如调用频率、错误数、延时等。由于应用程序并不是孤立的，如果其依赖的其他应用出现了性能问题，应用自身性能也会受到影响。&#xA;第三个，是应用程序内部核心逻辑的运行情况，比如关键环节的耗时以及执行过程中的错误等。由于这是应用程序内部的状态，从外部通常无法直接获取到详细的性能数据。所以，应用程序在设计和开发时，就应该把这些指标提供出来，以便监控系统可以了解其内部运行状态。&#xA;有了应用程序之间的调用指标，你可以迅速分析出一个请求处理的调用链中，到底哪个组件才是导致性能问题的罪魁祸首； 而有了应用程序内部核心逻辑的运行性能，你就可以更进一步，直接进入应用程序的内部，定位到底是哪个处理环节的函数导致了性能问题。 基于这些思路，我相信你就可以构建出，描述应用程序运行状态的性能指标。再将这些指标纳入我们上一期提到的监控系统（比如 Prometheus + Grafana）中，就可以跟系统监控一样，一方面通过告警系统，把问题及时汇报给相关团队处理；另一方面，通过直观的图形界面，动态展示应用程序的整体性能。</description>
    </item>
    <item>
      <title>55|套路篇：分析性能问题的一般步骤</title>
      <link>https://zsy619.github.io/post/55%E5%A5%97%E8%B7%AF%E7%AF%87%E5%88%86%E6%9E%90%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E8%88%AC%E6%AD%A5%E9%AA%A4/</link>
      <pubDate>Thu, 16 Jul 2020 15:25:49 +0800</pubDate>
      <guid>https://zsy619.github.io/post/55%E5%A5%97%E8%B7%AF%E7%AF%87%E5%88%86%E6%9E%90%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E8%88%AC%E6%AD%A5%E9%AA%A4/</guid>
      <description>系统资源瓶颈 系统资源的瓶颈，可以通过 USE 法，即使用率、饱和度以及错误数这三类指标来衡量。系统的资源，可以分为硬件资源和软件资源两类。&#xA;如 CPU、内存、磁盘和文件系统以及网络等，都是最常见的硬件资源。 而文件描述符数、连接跟踪数、套接字缓冲区大小等，则是典型的软件资源。 CPU 性能分析 利用 top、vmstat、pidstat、strace 以及 perf 等几个最常见的工具，获取 CPU 性能指标后，再结合进程与 CPU 的工作原理，就可以迅速定位出 CPU 性能瓶颈的来源。</description>
    </item>
    <item>
      <title>56|套路篇：优化性能问题的一般方法</title>
      <link>https://zsy619.github.io/post/56%E5%A5%97%E8%B7%AF%E7%AF%87%E4%BC%98%E5%8C%96%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E8%88%AC%E6%96%B9%E6%B3%95/</link>
      <pubDate>Thu, 16 Jul 2020 15:34:48 +0800</pubDate>
      <guid>https://zsy619.github.io/post/56%E5%A5%97%E8%B7%AF%E7%AF%87%E4%BC%98%E5%8C%96%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E8%88%AC%E6%96%B9%E6%B3%95/</guid>
      <description>CPU 优化 CPU 性能优化的核心，在于排除所有不必要的工作、充分利用 CPU 缓存并减少进程调度对性能的影响。&#xA;第一种，把进程绑定到一个或者多个 CPU 上，充分利用 CPU 缓存的本地性，并减少进程间的相互影响。 第二种，为中断处理程序开启多 CPU 负载均衡，以便在发生大量中断时，可以充分利用多 CPU 的优势分摊负载。 第三种，使用 Cgroups 等方法，为进程设置资源限制，避免个别进程消耗过多的 CPU。同时，为核心应用程序设置更高的优先级，减少低优先级任务的影响。 内存优化 第一种，除非有必要，Swap 应该禁止掉。这样就可以避免 Swap 的额外 I/O ，带来内存访问变慢的问题。</description>
    </item>
    <item>
      <title>57|套路篇：Linux 性能工具速查</title>
      <link>https://zsy619.github.io/post/57%E5%A5%97%E8%B7%AF%E7%AF%87Linux-%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7%E9%80%9F%E6%9F%A5/</link>
      <pubDate>Thu, 16 Jul 2020 15:43:55 +0800</pubDate>
      <guid>https://zsy619.github.io/post/57%E5%A5%97%E8%B7%AF%E7%AF%87Linux-%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7%E9%80%9F%E6%9F%A5/</guid>
      <description>性能工具速查 info 可以理解为 man 的详细版本，提供了诸如节点跳转等更强大的功能。相对来说，man 的输出比较简洁，而 info 的输出更详细。所以，我们通常使用 man 来查询工具的使用方法，只有在 man 的输出不太好理解时，才会再去参考 info 文档。</description>
    </item>
    <item>
      <title>58|答疑（六）：容器冷启动如何性能分析？</title>
      <link>https://zsy619.github.io/post/58%E7%AD%94%E7%96%91%E5%85%AD%E5%AE%B9%E5%99%A8%E5%86%B7%E5%90%AF%E5%8A%A8%E5%A6%82%E4%BD%95%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 16 Jul 2020 15:50:00 +0800</pubDate>
      <guid>https://zsy619.github.io/post/58%E7%AD%94%E7%96%91%E5%85%AD%E5%AE%B9%E5%99%A8%E5%86%B7%E5%90%AF%E5%8A%A8%E5%A6%82%E4%BD%95%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/</guid>
      <description>问题 1：容器冷启动性能分析 容器为应用程序的管理带来了巨大的便捷，诸如 Serverless（只关注应用的运行，而无需关注服务器）、FaaS（Function as a Service）等新型的软件架构，也都基于容器技术来构建。不过，虽然容器启动已经很快了，但在启动新容器，也就是冷启动的时候，启动时间相对于应用程序的性能要求来说，还是过长了。&#xA;针对耗时最多的流程，我们可以通过应用程序监控或者动态追踪的方法，定位出耗时最多的字模块，这样也就找出了要优化的瓶颈点。&#xA;比如，镜像拉取流程，可以通过缓存热点镜像来减少镜像拉取时间；网络配置流程，可以通过网络资源预分配进行加速；而资源调度和容器启动，也可以通过复用预先创建好的容器来进行优化。</description>
    </item>
    <item>
      <title>第一周01-09阶段小结</title>
      <link>https://zsy619.github.io/post/%E7%AC%AC%E4%B8%80%E5%91%A801-09%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93/</link>
      <pubDate>Mon, 01 Jun 2020 10:26:55 +0800</pubDate>
      <guid>https://zsy619.github.io/post/%E7%AC%AC%E4%B8%80%E5%91%A801-09%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93/</guid>
      <description>学习思路 建立起整体性能的全局观&#xA;学习内容 平均负载 含义 1分钟、5分钟、15分钟时间段监控 平均负载的合理性判定 工具uptime使用 /proc/cupinfo查看cup相关信息 工具top使用 平均负载高于cpu数量70%就要进行排查了 工具uptime、stress、systat、mpstat、pidstat使用 cpu上下文切换 cpu寄存器 程序计数器PC cpu上下文与cpu上下文切换 进程上下文切换、进程上下文切换、中断上下文切换 内核空间 &amp;ndash; 内核态 用户空间 &amp;ndash; 用户态 工具vmstat、pidstat、sysbench、man、watch使用 自愿上下文切换 非自愿上下文切换 中断 进行中断会出现什么情况 /proc/interrupts观察中断情况 cpu使用率 节拍率HZ，使用/boot/config查看配置情况 USER_HZ，默认100 /proc/stat与/proc/[pid]/stat查看cpu使用率 工具top、ps、pidstat、perf top、perf recod、perf report、ab、pstree、execsnoop、ftrace使用 僵尸进程 进程状态区分（R\D\Z\S\I） 进程组、会话 iowait分析 工具ps aux、top、dstat、pidstat、strace、perf record、perf report、pstree使用 软中断 异步处理机制 上半部与下半部 外卖配送例子 /proc/softirqs /proc/interrupts 学习感悟 要从了解基本概念，从系统的原理着手出发，linux下的工具比较齐全，要充分了解各工具的作用及应用场景</description>
    </item>
    <item>
      <title>第二周10-14阶段小结</title>
      <link>https://zsy619.github.io/post/%E7%AC%AC%E4%BA%8C%E5%91%A810-14%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93/</link>
      <pubDate>Sat, 06 Jun 2020 10:02:39 +0800</pubDate>
      <guid>https://zsy619.github.io/post/%E7%AC%AC%E4%BA%8C%E5%91%A810-14%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93/</guid>
      <description> 学习核心 理解中断：特别是网络接收的软中断 上半部分 下半部分 平均负载 累积中断次数 cpu指标性能 cpu使用率 用户cpu使用率 系统cpu使用率 等待io的cpu使用率 软中断和硬中断的cpu使用率 窃取cpu使用率 客户cpu使用率 平均负载 进程上下文切换 cpu缓存命中率 工具 sar：添加 -n DEV 参数显示网络收发的报告 watch -d cat /proc/softirqs tcpdump：通过 -i eth0 选项指定网卡 eth0，并通过 tcp port 80 选项指定 TCP 协议的 80 端口 uptime、mpstat、pidstat vmstat：查看系统的上下文切换次数和中断次数 top、perf top、perf record、perf report 短时进程execsnoop dstat 把性能指标与工具联合起来 </description>
    </item>
    <item>
      <title>第三周15-22阶段小结</title>
      <link>https://zsy619.github.io/post/%E7%AC%AC%E4%B8%89%E5%91%A815-22%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93/</link>
      <pubDate>Thu, 11 Jun 2020 09:33:33 +0800</pubDate>
      <guid>https://zsy619.github.io/post/%E7%AC%AC%E4%B8%89%E5%91%A815-22%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93/</guid>
      <description>内存性能 linux内存工作原理 内存映射 内核空间 用户空间 虚拟内存地址 物理内存地址 内存映射 缺页异常 虚拟内存空间分布 内核空间 栈 文件映射 堆 数据段 只读段 内存分配与回收 内存查看工具free 内存buffer与cache Buffers 是内核缓冲区用到的内存，对应的是 /proc/meminfo 中的 Buffers 值。 Cache 是内核页缓存和 Slab 用到的内存，对应的是 /proc/meminfo 中的 Cached 与 SReclaimable 之和。 proc文件系统 内存泄露 只读段，包括程序的代码和常量，由于是只读的，不会再去分配新的内存，所以也不会产生内存泄漏。 数据段，包括全局变量和静态变量，这些变量在定义时就已经确定了大小，所以也不会产生内存泄漏。 最后一个内存映射段，包括动态链接库和共享内存，其中共享内存由程序动态分配和管理。所以，如果程序在分配后忘了回收，就会导致跟堆内存类似的泄漏问题。 内存泄漏的危害非常大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用。内存泄漏不断累积，甚至会耗尽系统内存。</description>
    </item>
  </channel>
</rss>
