[{"id":0,"href":"/golang/macos_go_etl_build/","title":"go-etl在macos下编译若干问题","parent":"golang","content":" 一、go-etl简介 1.1 go-etl是什么 go-etl是一个集数据源抽取，转化，加载的工具集，提供强大的数据同步能力。\n1.2 go-etl有什么功能 主流数据库的数据抽取以及数据加载的能力，在storage包中实现 类二维表的数据流的数据抽取以及数据加载的能力，在stream包中实现 类似datax的数据同步能力，在datax包中实现 1.3 go-etl的优势 本数据数据同步工具以下数据源的同步能力\n1.4 go-etl源码地址 https://github.com/Breeze0806/go-etl\n二、在macos环境下编译 2.1 下载源码 创建自己的工作版本，然后下载源码\ngit clone https://github.com/zsy619/go-etl.git 2.2 阅读readme.md 主要注意事项如下：\n只提供了linux与windows编译的脚本，macos下没有提供编译脚本 oracle主要依赖的类库： github.com/godror/godror 安装相关的oracle类库，请从官网下载并安装 本机安装目录：/Volumes/D/oracle/instantclient_19_16 排除对db2编译 启用cgo——CGO_ENABLED=1 这个工具现在就支持单表单任务数据同步，如要做定时同步，请使用crontab或者其他定时任务工具 2.3 macos下第一次编译 步骤一：添加缺少文件\ncmd/datax/tools/script_darwin.go storage/database/db2/decode_chinese_darwin.go 步骤二：根据release.bat构建自己的编译脚本\nexport IGNORE_PACKAGES=db2 set GO111MODULE=on go mod download go mod vendor go generate ./... cd cmd/datax go build -o datax-darwin cp -f datax-darwin ../../release/datax-darwin chmod -R 777 ../../release/datax-darwin rm -f datax-darwin cd ../.. go run tools/datax/release/main.go 步骤三：macos编译下提示错误：\n../../vendor/github.com/godror/godror/orahlp.go:563:19: undefined: VersionInfo 步骤四：经过N次尝试，发现godror类库在macos下无法编译，最终找到如下命令，需要安装gcc\nbrew install gcc gcc -v Apple clang version 15.0.0 (clang-1500.3.9.4) Target: x86_64-apple-darwin23.5.0 Thread model: posix 2.4 解决oracle类库 2.5 解决交叉编译生成windows应用问题 错误提示： gcc_libinit_windows.c:6:10: fatal error: \u0026lsquo;windows.h\u0026rsquo; file not found 解决方案：\n使用mingw-w64工具进行交叉编译 MinGW-w64不仅能编译为Win64程序，也能编译为Win32程序。 MinGW-w64同样是跨平台软件，可以运行在Windows、GNU/Linux、macOS中。 MinGW-w64官网：http://mingw-w64.org MacOS下安装mingw-w64 brew install mingw-w64 最终交叉编译命令 # CGO_ENABLED=1 CC=x86_64-w64-mingw32-gcc CXX=x86_64-w64-mingw32-g++ GOOS=windows GOARCH=amd64 go build -v -o datax.exe 验证生成的文件 file datax.exe datax.exe: PE32+ executable (console) x86-64, for MS Windows 说明生成成功~~~ 三、遗留问题 针对linux下交叉编译，还是有问题，暂未解决，后期补充。\nlinux_syscall.c:67:13: error: call to undeclared function \u0026#39;setresgid\u0026#39;; ISO C99 and later do not support implicit function declarations [-Wimplicit-function-declaration] linux_syscall.c:67:13: note: did you mean \u0026#39;setregid\u0026#39;? /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/unistd.h:593:6: note: \u0026#39;setregid\u0026#39; declared here linux_syscall.c:73:13: error: call to undeclared function \u0026#39;setresuid\u0026#39;; ISO C99 and later do not support implicit function declarations [-Wimplicit-function-declaration] linux_syscall.c:73:13: note: did you mean \u0026#39;setreuid\u0026#39;? /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/unistd.h:595:6: note: \u0026#39;setreuid\u0026#39; declared here 四、总结 在macos下编译go-etl，主要解决oracle类库以及交叉编译生成windows应用问题 在macox下交叉编译linux应用，还是有问题，暂未解决，后期补充。 最终交叉编译脚本如下： #!/bin/bash sh cover.sh export IGNORE_PACKAGES=db2 export CGO_ENABLED=1 export GO111MODULE=on go mod download go mod vendor go generate ./... cd cmd/datax # 【darwin/amd64】 echo \u0026#34;start build darwin/amd64 ...\u0026#34; CGO_ENABLED=1 GOOS=darwin GOARCH=amd64 go build -o datax-darwin cp -f datax-darwin ../../release/datax-darwin chmod -R 777 ../../release/datax-darwin rm -f datax-darwin # 【linux/amd64】 # echo \u0026#34;start build linux/amd64 ...\u0026#34; # CGO_ENABLED=1 GOOS=linux GOARCH=amd64 go build -o datax-linux # cp -f datax-linux ../../release/datax-linux # chmod -R 777 ../../release/datax-linux # rm -f datax-linux # 【windows/amd64】 echo \u0026#34;start build windows/amd64 ...\u0026#34; CGO_ENABLED=1 CC=x86_64-w64-mingw32-gcc CXX=x86_64-w64-mingw32-g++ GOOS=windows GOARCH=amd64 go build -v -o datax.exe cp -f datax.exe ../../release/datax.exe chmod -R 777 ../../release/datax.exe rm -f datax.exe cd ../.. go run tools/datax/release/main.go 详细代码查看 github地址：https://github.com/zsy619/go-etl ","description":"一、go-etl简介 1.1 go-etl是什么 go-etl是一个集数据源抽取，转化，加载的工具集，提供强大的数据同步能力。\n1.2 go-etl有什么功能 主流数据库的数据抽取以及数据加载的能力，在storage包中实现 类二维表的数据流的数据抽取以及数据加载的能力，在stream包中实现 类似datax的数据同步能力，在datax包中实现 1."},{"id":1,"href":"/cangjie/","title":"仓颉","parent":"首页","content":" 嘿仓颉 ","description":" 嘿仓颉 "},{"id":2,"href":"/ai/","title":"我的AI","parent":"首页","content":" AI工具箱 写作PPT 搜索工具 视频工具 音频工具 开发 Ollama部署 开源 MiniCPM-V 2.6单图多图视频处理 AI生成各种风格人类照片的工具PhotoMaker 利用企业数据定制人工智能的平台mindsdb 开源的AI换脸和增强工具facefusion 强大的对话式文本转语音模型ChatTTS 本地运行各种LLM的工具ollama 简化大模型API调用的工具LiteLLM 让静态图片开口说话hallo 阿里新开源的FunAudioLLM项目 提示词 伟人记录员Prompt 如何训练一个AI帮你写MV剧本 电影电视剧解说的剧本 ","description":"AI工具箱 写作PPT 搜索工具 视频工具 音频工具 开发 Ollama部署 开源 MiniCPM-V 2."},{"id":3,"href":"/cangjie/hei_cangjie/","title":"嘿仓颉","parent":"仓颉","content":"2024年6月21日，华为仓颉正式公开发布。作为一个从业者，仓颉是我第一次接触的第一个国产开发语言。\n内测申请 关注公众号：仓颉编程语言，回复：SDK，即可申请内测。特别提示：申请内测，请先到gitcode.com申请一个账号。\n步骤1：关注公众号 步骤2：回复：SDK 步骤3：点击内测地址，填写信息 注意事项：\n1、需要签名。\n2、请填写正确邮箱，申请通过之后，会发送SDK等相关资料到邮箱。\n步骤4：查看邮箱 环境准备 已macos环境为例。\n步骤1：安装仓颉vscode插件 步骤2：解压SDK 通过tar命令行进行解压： 步骤3：配置环境 嘿仓颉 vscode安装插件之后，可以command+shift+p，输入Hey，即可看到仓颉命令。 找到 选择 选择项目路径 然后创建项目，目录结构如下： 在命令行运行：cjpm run 至此，第一个仓颉项目完成，是不是很简单，大家赶快试试吧。\n仓颉语言有很多特性期待大家去探索。\n","description":"2024年6月21日，华为仓颉正式公开发布。作为一个从业者，仓颉是我第一次接触的第一个国产开发语言。\n内测申请 关注公众号：仓颉编程语言，回复：SDK，即可申请内测。特别提示：申请内测，请先到gitcode.com申请一个账号。\n步骤1：关注公众号 步骤2：回复：SDK 步骤3：点击内测地址，填写信息 注意事项：\n1、需要签名。\n2、请填写正确邮箱，申请通过之后，会发送SDK等相关资料到邮箱。\n步骤4：查看邮箱 环境准备 已macos环境为例。"},{"id":4,"href":"/post/01%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","title":"01|如何学习Linux性能优化","parent":"Linux性能优化","content":" 前凑 搭建github.io博客 学习 不需要了解每个组件的所有实现细节 理解他们最基本的工作原理和协助方式 性能指标 应用负载的两个指标：\n吞吐 延时 性能分析：找出应用或系统的瓶颈，并想法去避免或缓解他们，从而更高效利用系统资源处理更多的请求。\n性能分析六步法：\n选择指标评估应用系统程序与系统的的性能 为应用程序和系统设置性能目标 进行性能基准测试 性能分析定位瓶颈 优化应用程序和系统 性能监控和告警 专栏核心：性能分析和优化\n编程基础：\n了解linux常用命令的使用方法 知道怎么安装和管理软件包 知道怎么通过编程语言开发应用程序 学习重点 建立整体系统性能的全局观是核心\n理解最基本的几个系统知识原理 掌握必要的性能工具 通过实际的场景演练，贯穿不同的组件 性能领域大师布伦丹.格雷特(Brendan Gregg)，是动态追踪工具DTrace的作者\nlinux性能工具图谱：\n根据此图，可选择对应的性能分析工具\n性能分析思维导图 性能问题的本质是什么？ 系统资源已经达到瓶颈，但请求的处理却还不够快，无法支撑更多的请求。\n线程与进程的关系 线程是调度的基本单位，而进程是资源拥有的基本单位。 内核中的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。\n当进程只有一个线程时，可以认为进程就等于线程 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量，这些资源在线程上下文切换时是不需要修改的 线程也有自己的私有数据，比如栈和寄存器，这些在上下文切换时也是需要保存的 ","description":"前凑 搭建github.io博客 学习 不需要了解每个组件的所有实现细节 理解他们最基本的工作原理和协助方式 性能指标 应用负载的两个指标：\n吞吐 延时 性能分析：找出应用或系统的瓶颈，并想法去避免或缓解他们，从而更高效利用系统资源处理更多的请求。"},{"id":5,"href":"/golang/","title":"golang","parent":"首页","content":" go-etl在macos下编译若干问题 casbin测试包引用问题解决 Go1.15.2更新记录 (released 2020/09/09) go2go命令 Go交叉编译windows程序 Go学习网站汇总 官方golang泛型阅读笔记 ","description":" go-etl在macos下编译若干问题 casbin测试包引用问题解决 Go1.15.2更新记录 (released 2020/09/09) go2go命令 Go交叉编译windows程序 Go学习网站汇总 官方golang泛型阅读笔记 "},{"id":6,"href":"/post/02%E5%9F%BA%E7%A1%80%E7%AF%87%E5%88%B0%E5%BA%95%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD/","title":"02|基础篇--到底应该怎么理解平均负载","parent":"Linux性能优化","content":" 什么是平均负载 平均负载(Load Average)：单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。 可运行状态的进程：正在使用cpu或等待使用cpu的进程，ps命令查看处于R状态（Running或Runnable）的进程。 不可中断的状态进程：处于内核态关键流程的状态，且这些流程不可打断，ps命令查看处于D状态（Uninterruptible Sleep，也称为Disk Sleep）的进程。 不可中断状态实际是系统对进程和硬件设备的一种保护机制。 $ uptime 14:36 up 5:23, 1 user, load averages: 2.19 2.30 2.33 解释：\n14:36 //当前时间 up 5:23 //系统运行时间 1 user //正在登录用户数 2.19 //过去1分钟平均负载 2.30 //过去5分钟平均负载 2.33 //过去15分钟平均负载 $ man uptime UPTIME(1) BSD General Commands Manual UPTIME(1) NAME uptime -- show how long system has been running SYNOPSIS uptime DESCRIPTION The uptime utility displays the current time, the length of time the system has been up, the number of users, and the load average of the system over the last 1, 5, and 15 min- utes. SEE ALSO w(1) HISTORY The uptime command appeared in 3.0BSD. BSD April 18, 1994 BSD 平均负载为多少时合适 平均负载理想情况等于cpu个数 首先要知道系统有几个cpu，可以通过top命令或/proc/cpuinfo读取 [zsy@localhost ~]$ top [zsy@localhost ~]$ grep \u0026#39;model name\u0026#39; /proc/cpuinfo |wc -l 2 有了cpu个数，当平均负载比cpu个数大时，表示系统出现了过载。\n根据uptime三个负载值进行核对：\n如果1分钟、5分钟、15分钟平均负载值相差不大，或基本相同，表示负载稳定 如果1分钟负载值远小于15分钟负载值，说明最近1分钟负载在减少，而过去15分钟负载很大 反之，如果最近1分钟远大于15分钟负载，说明最近1分钟负载在增加，这种增加有可能是临死时性，有可能是持续性的，要持续观察 案例分析 在一个单cpu系统上负载1.73，0.60，7.89 过去1分钟内，系统有73%超载 而15分钟内，系统有689%超载 整体趋势来看，负载在降低 生成环境，负载多高时，需要进行关注？ 当平均负载超过cpu数量的70% 负载过高，会导致进行响应慢 70%并不是绝对的，要监控平均负载，根据更多的历史数据，判断负载变化趋势 htop工具： 平均负载与CPU使用率 cpu密集型进程，使用大量cpu会导致平均负载升高，此时两者是一致的 I/O密集型进程，等待IO也会是平均负载升高，但cpu使用率不一定高 大量等待cpu使用的也会造成平均负载升高，此时cpu使用率也比较高 分析工具：iostat、mpstat、pidstat\nstress是一个linux系统压力测试工具，而sysstat包含了常用的linux性能工具，用来监控和分析系统的性能 mpstat是一个常用的多核cpu性能分析工具，查看每个cpu的性能指标，及所有cpu的平均指标 pidstat是一个常用的进程性能分析工具，用来实时查看进程的cpu、内存、io以及上下文切换等性能指标 场景一：CPU密集型进程 第一个终端输入：\nzsy@ubuntu:~$ stress --cpu 1 --timeout 600 stress: info: [15764] dispatching hogs: 1 cpu, 0 io, 0 vm, 0 hdd 第二个终端输入：\n# -d 参数表示高亮显示变化的区域 $ watch -d uptime 第三个终端输入：\n# -P ALL表示监控所有的cpu，5表示每5秒输出一组变化 $ mpstat -P ALL 5 监控是哪个进程CPU使用为100%:\n# 间隔5秒后输出一组数据 $ pidstat -u 5 1 可以看出stess进程的cpu使用率为100%\n场景二：I/O密集型进程 第一个终端输入，模拟IO密集操作：\nzsy@ubuntu:~$ stress -i 1 --timeout 600 stress: info: [19057] dispatching hogs: 0 cpu, 1 io, 0 vm, 0 hdd 第二个终端监控平均负载：\nwatch -d uptime 第三个终端运行mpstat查看cpu变化情况：\nmpstat -P ALL 5 1 第四个终端监控哪个进程iowait高：\npidstat -u 5 1 场景三：大量进程的场景 第一个终端输入，模拟8个进程：\nzsy@ubuntu:~$ stress -c 8 --timeout 600 stress: info: [21546] dispatching hogs: 8 cpu, 0 io, 0 vm, 0 hdd 第二个终端输入，监控平均负载：\nwatch -d uptime 第三个终端，使用pidstat查看进程情况：\npidstat -u 5 1 小结 平均负载高有可能是CPU密集型进程导致的 平均负载高不一定是cpu使用率高，有可能是io更繁忙了 发现负载高，使用mpstat、pidstat工具进行分析 ","description":"什么是平均负载 平均负载(Load Average)：单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。 可运行状态的进程：正在使用cpu或等待使用cpu的进程，ps命令查看处于R状态（Running或Runnable）的进程。 不可中断的状态进程：处于内核态关键流程的状态，且这些流程不可打断，ps命令查看处于D状态（Uninterruptible Sleep，也称为Disk Sleep）的进程。 不可中断状态实际是系统对进程和硬件设备的一种保护机制。 $ uptime 14:36 up 5:23, 1 user, load averages: 2."},{"id":7,"href":"/flutter/","title":"flutter","parent":"首页","content":" 安装sudo gem install cocoapods ","description":" 安装sudo gem install cocoapods "},{"id":8,"href":"/post/03%E5%9F%BA%E7%A1%80%E7%AF%87%E7%BB%8F%E5%B8%B8%E8%AF%B4%E7%9A%84CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/","title":"03|基础篇经常说的CPU上下文切换是什么意思","parent":"Linux性能优化","content":" CPU上下文切换就是罪魁祸首 任务运行前的准备工作 CPU都要知道任务从哪里加载、从哪里开始运行，需要系统事先设置好CPU寄存器和程序计数器（Program Counter，PC）\nCPU寄存器：CPU内置容量小、速度极快的内存 程序计数器：用来存储CPU正在执行的指令位置、或将执行下一条指令的位置 这就是CPU上下文 CPU上下文切换：把前一个CPU上下文（cpu寄存器及程序计数器）保存起来，然后加载新的任务的上下文到这些寄存器及程序计数器，然后跳转到寄存器及程序计数器所指的位置，运行新的任务 进程、线程是最常见的任务 CPU上下文场景分类： 进程上下文切换 线程上下文切换 中断上下文切换 进程上下文切换 linux特权等级，把进程运行空间分为：内核空间、用户空间\n内核空间：具有最高权限，可以访问所有资源。 在此运行的进程叫进程的内核态。 用户空间：只访问受限资源，不能访问内存等硬件设备，必须通过系统调用陷入到内核中，才可以访问特权资源。 在次运行的进程叫进程的用户态。 从用户态到内核态，需要经过系统调用来完成。 一次系统调用，发生了两次CPU上下文切换 进程上下文切换与系统调用的区分：\n进程上下文切换是从一个进程切换到另外一个进程 系统调用是一直同一个进程在运行 系统调用过程称为特权模式切换，而不是上下文切换 进程切换只发生在内核态 保存上下文和恢复上下文并不是”免费“的 Linux通过TLB（Translation Lookaside Buffer）管理虚拟内存到物理内存的映射\n触发进程调用的场景：\n其一，为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。 其二，进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。 其三，当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。 其四，当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。 线程上下文切换 线程是调度的基本单位，而进程是资源拥有的基本单位\n进程与线程区别：\n当进程只有一个线程时，可以认为进程就等于线程。 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。 线程上下文切换场景：\n前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据 中断上下文切换 中断：cpu上下文切换；中断执行会打断进程的正常调度和执行\n对同一个CPU来说，中断处理比进程拥有更高的优先级\n","description":"CPU上下文切换就是罪魁祸首 任务运行前的准备工作 CPU都要知道任务从哪里加载、从哪里开始运行，需要系统事先设置好CPU寄存器和程序计数器（Program Counter，PC）\nCPU寄存器：CPU内置容量小、速度极快的内存 程序计数器：用来存储CPU正在执行的指令位置、或将执行下一条指令的位置 这就是CPU上下文 CPU上下文切换：把前一个CPU上下文（cpu寄存器及程序计数器）保存起来，然后加载新的任务的上下文到这些寄存器及程序计数器，然后跳转到寄存器及程序计数器所指的位置，运行新的任务 进程、线程是最常见的任务 CPU上下文场景分类： 进程上下文切换 线程上下文切换 中断上下文切换 进程上下文切换 linux特权等级，把进程运行空间分为：内核空间、用户空间"},{"id":9,"href":"/post/04%E5%9F%BA%E7%A1%80%E7%AF%87%E7%BB%8F%E5%B8%B8%E8%AF%B4%E7%9A%84CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D/","title":"04|基础篇--经常说的CPU上下文切换是什么意思","parent":"Linux性能优化","content":" 查看系统上下文切换情况 上下文切换，会把cpu时间消耗在寄存器、内核栈及虚拟内存等数据的保存和恢复上，缩短进程真正的运行时间，成为系统性能大幅下降的一个元凶。\n使用vmstat查看上下文切换情况，本工具主要分析系统的内存使用情况。例子每间隔5秒输出一组数据： cs（context switch）：每秒上下文切换的次数 in（interrupt）：每秒中断的次数 r（Running or Runnable）：就绪队列长度，也就是正在运行和等待cpu运行的进程 b（blocked）：处于不可中断睡眠状态的进程 vmstat给出系统整体的上下文切换情况，pidstat可以查看每个进程的详细情况 间隔5秒输出一组数据：\npidstat -w 5 cswch：每秒自愿上下文切换（voluntary context switches）次数 nvcswch：每秒非自愿上下文切换（non voluntary context switches）次数 使用sysbench模拟多线程调度切换情况 安装sysbench：\nsudo apt install sysbench 第一个终端模拟多线程调度：\n# 以10个线程运行5分钟的基准测试 $ sysbench --threads=10 --max-time=300 threads run 第二个终端监控上下文切换情况：\n# 每间隔1秒输出一组数据 $ vmstat 1 pidstat默认显示进程的指标数，加上-t显示线程的指标数\n如何知道中断发生的类型？/proc/interrupts\nwatch -d cat /proc/interrupts RES：重新调度中断，表示唤醒空闲状态cpu调度新的任务运行 IPI：处理器间中断，调度器分散任务到不同cpu的机制 ","description":"查看系统上下文切换情况 上下文切换，会把cpu时间消耗在寄存器、内核栈及虚拟内存等数据的保存和恢复上，缩短进程真正的运行时间，成为系统性能大幅下降的一个元凶。\n使用vmstat查看上下文切换情况，本工具主要分析系统的内存使用情况。例子每间隔5秒输出一组数据： cs（context switch）：每秒上下文切换的次数 in（interrupt）：每秒中断的次数 r（Running or Runnable）：就绪队列长度，也就是正在运行和等待cpu运行的进程 b（blocked）：处于不可中断睡眠状态的进程 vmstat给出系统整体的上下文切换情况，pidstat可以查看每个进程的详细情况 间隔5秒输出一组数据："},{"id":10,"href":"/ai/tools/","title":"AI工具箱","parent":"我的AI","content":" 写作PPT 搜索工具 视频工具 音频工具 ","description":" 写作PPT 搜索工具 视频工具 音频工具 "},{"id":11,"href":"/ai/%E5%BC%80%E5%8F%91/","title":"开发","parent":"我的AI","content":" Ollama部署 ","description":" Ollama部署 "},{"id":12,"href":"/ai/%E5%BC%80%E6%BA%90/","title":"开源","parent":"我的AI","content":" MiniCPM-V 2.6单图多图视频处理 AI生成各种风格人类照片的工具PhotoMaker 利用企业数据定制人工智能的平台mindsdb 开源的AI换脸和增强工具facefusion 强大的对话式文本转语音模型ChatTTS 本地运行各种LLM的工具ollama 简化大模型API调用的工具LiteLLM 让静态图片开口说话hallo 阿里新开源的FunAudioLLM项目 ","description":" MiniCPM-V 2.6单图多图视频处理 AI生成各种风格人类照片的工具PhotoMaker 利用企业数据定制人工智能的平台mindsdb 开源的AI换脸和增强工具facefusion 强大的对话式文本转语音模型ChatTTS 本地运行各种LLM的工具ollama 简化大模型API调用的工具LiteLLM 让静态图片开口说话hallo 阿里新开源的FunAudioLLM项目 "},{"id":13,"href":"/ai/prompt/","title":"提示词","parent":"我的AI","content":" 伟人记录员Prompt 如何训练一个AI帮你写MV剧本 电影电视剧解说的剧本 ","description":" 伟人记录员Prompt 如何训练一个AI帮你写MV剧本 电影电视剧解说的剧本 "},{"id":14,"href":"/post/05%E5%9F%BA%E7%A1%80%E7%AF%87%E6%9F%90%E4%B8%AA%E5%BA%94%E7%94%A8%E7%9A%84CPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%B1%85%E7%84%B6%E8%BE%BE%E5%88%B0100%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/","title":"05|基础篇--某个应用的CPU使用率居然达到100%，我该怎么办？","parent":"Linux性能优化","content":" cpu使用率 定义节拍率（内核中用HZ表示），触发时间中断，并使用全局变量Jiffies记录开机以来的节拍率 没发生一次时间中断，Jiffies就增加1 节拍率设置值100、250、1000等，查询/boot/config来查看 表示每秒触发250次中断\n节拍率是内核选项，用户空间程序不能直接访问 用户节拍率USER_HZ默认是100 /proc虚拟文件系统 系统内部状态 /proc/stat提供cpu和任务系统信息 CPU使用率：就是空闲时间外的其他时间占总cpu时间的百分比 每个进程的运行情况：/proc/[pid]/stat 如何查看cpu使用率 top显示系统整体cpu与内存使用情况，以及各个进程资源使用情况 ps显示每个进程的使用情况 cpu使用过高 使用perf分析cpu性能 ","description":" cpu使用率 定义节拍率（内核中用HZ表示），触发时间中断，并使用全局变量Jiffies记录开机以来的节拍率 没发生一次时间中断，Jiffies就增加1 节拍率设置值100、250、1000等，查询/boot/config来查看 表示每秒触发250次中断\n节拍率是内核选项，用户空间程序不能直接访问 用户节拍率USER_HZ默认是100 /proc虚拟文件系统 系统内部状态 /proc/stat提供cpu和任务系统信息 CPU使用率：就是空闲时间外的其他时间占总cpu时间的百分比 每个进程的运行情况：/proc/[pid]/stat 如何查看cpu使用率 top显示系统整体cpu与内存使用情况，以及各个进程资源使用情况 ps显示每个进程的使用情况 cpu使用过高 使用perf分析cpu性能 "},{"id":15,"href":"/post/06%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E7%9A%84CPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%BE%88%E9%AB%98%E4%BD%86%E4%B8%BA%E5%95%A5%E5%8D%B4%E6%89%BE%E4%B8%8D%E5%88%B0%E9%AB%98CPU%E7%9A%84%E5%BA%94%E7%94%A8/","title":"06|案例篇--系统的CPU使用率很高，但为啥却找不到高CPU的应用？","parent":"Linux性能优化","content":" 使用工具 使用top、vmstat、pidstat等\nap（apache bench）是一个常用的http性能测试工具\n# 并发100个请求测试Nginx性能，总共测试1000个请求 $ ab -c 100 -n 1000 http://192.168.0.10:10000/ This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1706008 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, ... Requests per second: 87.86 [#/sec] (mean) Time per request: 1138.229 [ms] (mean) ... 第一个原因，进程在不停地崩溃重启，比如因为段错误、配置错误等等，这时，进程在退出后可能又被监控系统自动重启了。\n第二个原因，这些进程都是短时进程，也就是在其他应用内部通过 exec 调用的外面命令。这些命令一般都只运行很短的时间就会结束，你很难用 top 这种间隔时间比较长的工具发现（上面的案例，我们碰巧发现了）。\n用 pstree 就可以用树状形式显示所有进程之间的关系： execsnoop execsnoop 就是一个专为短时进程设计的工具。它通过 ftrace 实时监控进程的 exec() 行为，并输出短时进程的基本信息，包括进程 PID、父进程 PID、命令行参数以及执行的结果。\nhgo # 按 Ctrl+C 结束 $ execsnoop PCOMM PID PPID RET ARGS sh 30394 30393 0 stress 30396 30394 0 /usr/local/bin/stress -t 1 -d 1 sh 30398 30393 0 stress 30399 30398 0 /usr/local/bin/stress -t 1 -d 1 sh 30402 30400 0 stress 30403 30402 0 /usr/local/bin/stress -t 1 -d 1 sh 30405 30393 0 stress 30407 30405 0 /usr/local/bin/stress -t 1 -d 1 ... 小结 第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。 第二，应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU。 ","description":"使用工具 使用top、vmstat、pidstat等\nap（apache bench）是一个常用的http性能测试工具\n# 并发100个请求测试Nginx性能，总共测试1000个请求 $ ab -c 100 -n 1000 http://192."},{"id":16,"href":"/post/07%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%87%BA%E7%8E%B0%E5%A4%A7%E9%87%8F%E4%B8%8D%E5%8F%AF%E4%B8%AD%E6%96%AD%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8A/","title":"07|案例篇--系统中出现大量不可中断进程和僵尸进程怎么办？（上）","parent":"Linux性能优化","content":" 进程状态 top 和 ps 是最常用的查看进程状态的工具 top命令： R 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行。 D 是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。 Z 是 Zombie 的缩写，如果你玩过“植物大战僵尸”这款游戏，应该知道它的意思。它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。 S 是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态。 I 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会。 进程组与会话 进程组：表示一组相互关联的进程，比如每个子进程都是父进程所在组的成员； 会话：指共享同一个控制终端的一个或多个进程组。 ","description":" 进程状态 top 和 ps 是最常用的查看进程状态的工具 top命令： R 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行。 D 是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。 Z 是 Zombie 的缩写，如果你玩过“植物大战僵尸”这款游戏，应该知道它的意思。它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。 S 是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态。 I 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会。 进程组与会话 进程组：表示一组相互关联的进程，比如每个子进程都是父进程所在组的成员； 会话：指共享同一个控制终端的一个或多个进程组。 "},{"id":17,"href":"/post/08%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%87%BA%E7%8E%B0%E5%A4%A7%E9%87%8F%E4%B8%8D%E5%8F%AF%E4%B8%AD%E6%96%AD%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8B/","title":"08|案例篇--系统中出现大量不可中断进程和僵尸进程怎么办？（下）","parent":"Linux性能优化","content":" 问题 通过分析 top 命令的输出，我们发现了两个问题：\n第一，iowait 太高了，导致系统平均负载升高，并且已经达到了系统 CPU 的个数。 第二，僵尸进程在不断增多，看起来是应用程序没有正确清理子进程的资源。 iowait分析 dstat可以同时查看 CPU 和 I/O 这两种资源的使用情况 strace 正是最常用的跟踪进程系统调用的工具。 perf record -g perf report 僵尸进程 找出父进程，然后在父进程里解决。\n# -a 表示输出命令行选项 # p表PID # s表示指定进程的父进程 $ pstree -aps 125 小结 iowait 高不一定代表 I/O 有性能瓶颈。当系统中只有 I/O 类型的进程在运行时，iowait 也会很高，但实际上，磁盘的读写远没有达到性能瓶颈的程度。\n碰到 iowait 升高时，需要先用 dstat、pidstat 等工具，确认是不是磁盘 I/O 的问题，然后再找是哪些进程导致了 I/O。\n","description":"问题 通过分析 top 命令的输出，我们发现了两个问题：\n第一，iowait 太高了，导致系统平均负载升高，并且已经达到了系统 CPU 的个数。 第二，僵尸进程在不断增多，看起来是应用程序没有正确清理子进程的资源。 iowait分析 dstat可以同时查看 CPU 和 I/O 这两种资源的使用情况 strace 正是最常用的跟踪进程系统调用的工具。 perf record -g perf report 僵尸进程 找出父进程，然后在父进程里解决。"},{"id":18,"href":"/post/09%E5%9F%BA%E7%A1%80%E7%AF%87%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3Linux%E8%BD%AF%E4%B8%AD%E6%96%AD/","title":"09|基础篇--怎么理解Linux软中断？","parent":"Linux性能优化","content":" 软中断（softirq） 软中断（softirq）CPU 使用率升高也是最常见的一种性能问题\n中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。\n为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行。\nLinux 将中断处理过程分成了两个阶段，也就是上半部和下半部：\n上半部用来快速处理中断，它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。 下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。 网卡接收到数据包后，会通过硬件中断的方式，通知内核有新的数据到了。\n这两个阶段你也可以这样理解：\n上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行； 而下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。 查看软中断和内核线程 /proc/softirqs 提供了软中断的运行情况； /proc/interrupts 提供了硬中断的运行情况。 在查看 /proc/softirqs 文件内容时，你要特别注意以下这两点。\n第一，要注意软中断的类型，也就是这个界面中第一列的内容。从第一列你可以看到，软中断包括了 10 个类别，分别对应不同的工作类型。比如 NET_RX 表示网络接收中断，而 NET_TX 表示网络发送中断。 第二，要注意同一种软中断在不同 CPU 上的分布情况，也就是同一行的内容。正常情况下，同一种中断在不同 CPU 上的累积次数应该差不多。比如这个界面中，NET_RX 在 CPU0 和 CPU1 上的中断次数基本是同一个数量级，相差不大。 ","description":"软中断（softirq） 软中断（softirq）CPU 使用率升高也是最常见的一种性能问题\n中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。\n为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行。\nLinux 将中断处理过程分成了两个阶段，也就是上半部和下半部：\n上半部用来快速处理中断，它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。 下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。 网卡接收到数据包后，会通过硬件中断的方式，通知内核有新的数据到了。"},{"id":19,"href":"/post/10%E6%A1%88%E4%BE%8B%E7%AF%87%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BD%AF%E4%B8%AD%E6%96%ADCPU%E4%BD%BF%E7%94%A8%E7%8E%87%E5%8D%87%E9%AB%98%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/","title":"10|案例篇--系统的软中断CPU使用率升高，我该怎么办？","parent":"Linux性能优化","content":" 中断处理程序 分上半部与下半部 上半部对应硬件中断，用来快速处理中断 下半部对应软件中断，用异步处理上半部未完成的工作 观察中断可通过/proc/softirqs sar命令 查看系统网络收发情况\n# -n DEV 表示显示网络收发的报告，间隔1秒输出一组数据 $ sar -n DEV 1 15:03:46 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 15:03:47 eth0 12607.00 6304.00 664.86 358.11 0.00 0.00 0.00 0.01 15:03:47 docker0 6302.00 12604.00 270.79 664.66 0.00 0.00 0.00 0.00 15:03:47 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 15:03:47 veth9f6bbcd 6302.00 12604.00 356.95 664.66 0.00 0.00 0.00 0.05 列表从左到右依次：\n第一列：表示报告的时间。 第二列：IFACE 表示网卡。 第三、四列：rxpck/s 和 txpck/s 分别表示每秒接收、发送的网络帧数，也就是 PPS。 第五、六列：rxkB/s 和 txkB/s 分别表示每秒接收、发送的千字节数，也就是 BPS。 tcpdump命令 # -i eth0 只抓取eth0网卡，-n不解析协议名和主机名 # tcp port 80表示只抓取tcp协议并且端口号为80的网络帧 $ tcpdump -i eth0 -n tcp port 80 15:11:32.678966 IP 192.168.0.2.18238 \u0026gt; 192.168.0.30.80: Flags [S], seq 458303614, win 512, length 0 ... 解决 SYN FLOOD 问题最简单的解决方法，就是从交换机或者硬件防火墙中封掉来源 IP，这样 SYN FLOOD 网络帧就不会发送到服务器中。\n","description":"中断处理程序 分上半部与下半部 上半部对应硬件中断，用来快速处理中断 下半部对应软件中断，用异步处理上半部未完成的工作 观察中断可通过/proc/softirqs sar命令 查看系统网络收发情况\n# -n DEV 表示显示网络收发的报告，间隔1秒输出一组数据 $ sar -n DEV 1 15:03:46 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 15:03:47 eth0 12607."},{"id":20,"href":"/post/11%E5%A5%97%E8%B7%AF%E7%AF%87%E5%A6%82%E4%BD%95%E8%BF%85%E9%80%9F%E5%88%86%E6%9E%90%E5%87%BA%E7%B3%BB%E7%BB%9FCPU%E7%9A%84%E7%93%B6%E9%A2%88%E5%9C%A8%E5%93%AA%E9%87%8C/","title":"11|套路篇--如何迅速分析出系统CPU的瓶颈在哪里？","parent":"Linux性能优化","content":" cup性能指标 首先联想到cpu使用率 根据cpu上运行任务不同，划分：\n用户cpu 用户 CPU 使用率，包括用户态 CPU 使用率（user）和低优先级用户态 CPU 使用率（nice），表示 CPU 在用户态运行的时间百分比。用户 CPU 使用率高，通常说明有应用程序比较繁忙。 系统cpu 系统 CPU 使用率，表示 CPU 在内核态运行的时间百分比（不包括中断）。系统 CPU 使用率高，说明内核比较繁忙。 等待io/cpu 等待 I/O 的 CPU 使用率，通常也称为 iowait，表示等待 I/O 的时间百分比。iowait 高，通常说明系统与硬件设备的 I/O 交互时间比较长。 软中断 硬中断 软中断和硬中断的 CPU 使用率，分别表示内核调用软中断处理程序、硬中断处理程序的时间百分比。它们的使用率高，通常说明系统发生了大量的中断。 除了上面这些，还有在虚拟化环境中会用到的窃取 CPU 使用率（steal）和客户 CPU 使用率（guest），分别表示被其他虚拟机占用的 CPU 时间百分比，和运行客户虚拟机的 CPU 时间百分比。\n平均负载（Load Average） 理想情况下，平均负载等于逻辑 CPU 个数，这表示每个 CPU 都恰好被充分利用。如果平均负载大于逻辑 CPU 个数，就表示负载比较重了。\n进程上下文切换 无法获取资源而导致的自愿上下文切换 被系统强制调度导致的非自愿上下文切换 上下文切换，本身是保证 Linux 正常运行的一项核心功能。但过多的上下文切换，会将原本运行进程的 CPU 时间，消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，缩短进程真正运行的时间，成为性能瓶颈。\nCPU 缓存的命中率 产生原因：\n由于 CPU 发展的速度远快于内存的发展，CPU 的处理速度就比内存的访问速度快得多。这样，CPU 在访问内存的时候，免不了要等待内存的响应。为了协调这两者巨大的性能差距，CPU 缓存（通常是多级缓存）就出现了。\n性能工具 想弄清楚性能指标的关联性，就要通晓每种性能指标的工作原理。为了缩小排查范围，我通常会先运行几个支持指标较多的工具，如 top、vmstat 和 pidstat 。\n","description":"cup性能指标 首先联想到cpu使用率 根据cpu上运行任务不同，划分：\n用户cpu 用户 CPU 使用率，包括用户态 CPU 使用率（user）和低优先级用户态 CPU 使用率（nice），表示 CPU 在用户态运行的时间百分比。用户 CPU 使用率高，通常说明有应用程序比较繁忙。 系统cpu 系统 CPU 使用率，表示 CPU 在内核态运行的时间百分比（不包括中断）。系统 CPU 使用率高，说明内核比较繁忙。 等待io/cpu 等待 I/O 的 CPU 使用率，通常也称为 iowait，表示等待 I/O 的时间百分比。iowait 高，通常说明系统与硬件设备的 I/O 交互时间比较长。 软中断 硬中断 软中断和硬中断的 CPU 使用率，分别表示内核调用软中断处理程序、硬中断处理程序的时间百分比。它们的使用率高，通常说明系统发生了大量的中断。 除了上面这些，还有在虚拟化环境中会用到的窃取 CPU 使用率（steal）和客户 CPU 使用率（guest），分别表示被其他虚拟机占用的 CPU 时间百分比，和运行客户虚拟机的 CPU 时间百分比。"},{"id":21,"href":"/post/12%E5%A5%97%E8%B7%AF%E7%AF%87CPU-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF/","title":"12|套路篇--CPU性能优化的几个思路","parent":"Linux性能优化","content":" 性能优化方法论 三个问题：\n首先，既然要做性能优化，那要怎么判断它是不是有效呢？特别是优化后，到底能提升多少性能呢？ 第二，性能问题通常不是独立的，如果有多个性能问题同时发生，你应该先优化哪一个呢？ 第三，提升性能的方法并不是唯一的，当有多种方法可以选择时，你会选用哪一种呢？是不是总选那个最大程度提升性能的方法就行了呢？ 性能评估可能有多重指标，性能问题可能会多个同时发生，而且，优化某一个指标的性能，可能又导致其他指标性能的下降。\n怎么评估性能优化的效果 性能评估“三步走”：\n确定性能的量化指标。 测试优化前的性能指标。 测试优化后的性能指标。 不要局限单一维度指标，至少要从应用程序和系统资源两个维度着手，分别选择不同的指标。\n例：web应用程序：\n应用程序的维度 \u0026ndash; 吞吐量与请求延迟 系统资源的维度 \u0026ndash; cpu使用率 为什么选择这两个维度：\n好的应用程序是性能优化的最终目的和结果，系统优化总是为应用程序服务的。所以，必须要使用应用程序的指标，来评估性能优化的整体效果。 系统资源的使用情况是影响应用程序性能的根源。所以，需要用系统资源的指标，来观察和分析瓶颈的来源。 工具ab、vmstat、pidstat使用\n性能测试注意事项：\n第一，要避免性能测试工具干扰应用程序的性能。通常，对 Web 应用来说，性能测试工具跟目标应用程序要在不同的机器上运行。 第二，避免外部环境的变化影响性能指标的评估。这要求优化前、后的应用程序，都运行在相同配置的机器上，并且它们的外部依赖也要完全一致。 多个性能问题同时存在，要怎么选择？ 性能问题不是独立存在的\n并不是所有的性能问题都值得优化\n例子：\n第一，如果发现是系统资源达到了瓶颈，比如CPU使用率达到了100%，那么首先优化的一定是系统资源使用问题。完成系统资源瓶颈的优化后，才要考虑其他问题。 第二，针对不同类型的指标，首先去优化那些由瓶颈导致的，性能指标变化幅度最大的问题。比如产生瓶颈后，用户CPU使用率升高了10%，而系统CPU使用率却升高了50%，这个时候就应该首先优化系统CPU的使用。 有多种优化方法时，要如何选择? 一般情况下，我们当然想选能最大提升性能的方法，这其实也是性能优化的目标。\n性能优化并非没有成本。（性能优化通常会带来复杂度的提升，降低程序的可维护性，还可能在优化一个指标时，引发其他指标的异常。也就是说，很可能你优化了一个指标，另一个指标的性能却变差了。）\ncpu优化 应用程序优化 编译器优化：很多编译器都会提供优化选项，适当开启它们，在编译阶段你就可以获得编译器的帮助，来提升性能。比如， gcc 就提供了优化选项 -O2，开启后会自动对应用程序的代码进行优化。 算法优化：使用复杂度更低的算法，可以显著加快处理速度。比如，在数据比较大的情况下，可以用 O(nlogn) 的排序算法（如快排、归并排序等），代替 O(n^2) 的排序算法（如冒泡、插入排序等）。 异步处理：使用异步处理，可以避免程序因为等待某个资源而一直阻塞，从而提升程序的并发处理能力。比如，把轮询替换为事件通知，就可以避免轮询耗费 CPU 的问题。 多线程代替多进程：前面讲过，相对于进程的上下文切换，线程的上下文切换并不切换进程地址空间，因此可以降低上下文切换的成本。 善用缓存：经常访问的数据或者计算过程中的步骤，可以放到内存中缓存起来，这样在下次用时就能直接从内存中获取，加快程序的处理速度。 系统优化 CPU 绑定：把进程绑定到一个或者多个 CPU 上，可以提高 CPU 缓存的命中率，减少跨 CPU 调度带来的上下文切换问题。 CPU 独占：跟 CPU 绑定类似，进一步将 CPU 分组，并通过 CPU 亲和性机制为其分配进程。这样，这些 CPU 就由指定的进程独占，换句话说，不允许其他进程再来使用这些 CPU。 优先级调整：使用 nice 调整进程的优先级，正值调低优先级，负值调高优先级。优先级的数值含义前面我们提到过，忘了的话及时复习一下。在这里，适当降低非核心应用的优先级，增高核心应用的优先级，可以确保核心应用得到优先处理。 NUMA（Non-Uniform Memory Access）优化：支持 NUMA 的处理器会被划分为多个 node，每个 node 都有自己的本地内存空间。NUMA 优化，其实就是让 CPU 尽可能只访问本地内存。 中断负载均衡：无论是软中断还是硬中断，它们的中断处理程序都可能会耗费大量的 CPU。开启 irqbalance 服务或者配置 smp_affinity，就可以把中断处理过程自动负载均衡到多个 CPU 上。 避免过早优化 性能优化最好是逐步完善，动态进行，不追求一步到位，而要首先保证能满足当前的性能要求。当发现性能不满足要求或者出现性能瓶颈时，再根据性能评估的结果，选择最重要的性能问题进行优化。\n","description":"性能优化方法论 三个问题：\n首先，既然要做性能优化，那要怎么判断它是不是有效呢？特别是优化后，到底能提升多少性能呢？ 第二，性能问题通常不是独立的，如果有多个性能问题同时发生，你应该先优化哪一个呢？ 第三，提升性能的方法并不是唯一的，当有多种方法可以选择时，你会选用哪一种呢？是不是总选那个最大程度提升性能的方法就行了呢？ 性能评估可能有多重指标，性能问题可能会多个同时发生，而且，优化某一个指标的性能，可能又导致其他指标性能的下降。\n怎么评估性能优化的效果 性能评估“三步走”：\n确定性能的量化指标。 测试优化前的性能指标。 测试优化后的性能指标。 不要局限单一维度指标，至少要从应用程序和系统资源两个维度着手，分别选择不同的指标。"},{"id":22,"href":"/post/13%E7%AD%94%E7%96%91%E4%B8%80%E6%97%A0%E6%B3%95%E6%A8%A1%E6%8B%9F%E5%87%BARES%E4%B8%AD%E6%96%AD%E7%9A%84%E9%97%AE%E9%A2%98%E6%80%8E%E4%B9%88%E5%8A%9E/","title":"13|答疑（一）无法模拟出RES中断的问题，怎么办？","parent":"Linux性能优化","content":" 问题 1：性能工具版本太低，导致指标不全 性能分析的学习，建议要用最新的性能工具来学。新工具有更全面的指标，更容易上手分析。这个绝对的优势，可以让你更直观地得到想要的数据，也不容易让你打退堂鼓。\n最好试着去理解性能工具的原理，或者熟悉了使用方法后，再回过头重新学习原理。这样，即使是在无法安装新工具的环境中，你仍然可以从 proc 文件系统或者其他地方，获得同样的指标，进行有效的分析。\n问题 2：使用 stress 命令，无法模拟 iowait 高的场景 可以运行下面的命令，来模拟 iowait 的问题：\n# -i的含义还是调用sync，而—hdd则表示读写临时文件 $ stress-ng -i 1 --hdd 1 --timeout 600 问题 3：无法模拟出 RES 中断的问题 分析：重调度中断是调度器用来分散任务到不同 CPU 的机制，也就是可以唤醒空闲状态的 CPU ，来调度新任务运行，而这通常借助处理器间中断（Inter-Processor Interrupts，IPI）来实现。\n：：：：这个中断在单核（只有一个逻辑 CPU）的机器上当然就没有意义了，因为压根儿就不会发生重调度的情况。\n拿 pidstat 中的 %wait 跟 top 中的 iowait% （缩写为 wa）对比，其实这是没有意义的，因为它们是完全不相关的两个指标。\npidstat 中， %wait 表示进程等待 CPU 的时间百分比。 top 中 ，iowait% 则表示等待 I/O 的 CPU 时间百分比。 差异化：：：不同版本的 sysbench 运行参数也不是完全一样的\nUbuntu 18.04 $ sysbench \u0026ndash;threads=10 \u0026ndash;max-time=300 threads run Ubuntu 16.04 $ sysbench \u0026ndash;num-threads=10 \u0026ndash;max-time=300 \u0026ndash;test=threads run 问题 4：无法模拟出 I/O 性能瓶颈，以及 I/O 压力过大的问题 问题 5：性能工具（如 vmstat）输出中，第一行数据跟其他行差别巨大 ：：：在碰到直观上解释不了的现象时，要第一时间去查命令手册。如 man vmstat\nThe first report produced gives averages since the last reboot. Additional reports give information on a sam‐ pling period of length delay. The process and memory reports are instantaneous in either case. 也就是说，第一行数据是系统启动以来的平均值，其他行才是你在运行 vmstat 命令时，设置的间隔时间的平均值。另外，进程和内存的报告内容都是即时数值。\n","description":"问题 1：性能工具版本太低，导致指标不全 性能分析的学习，建议要用最新的性能工具来学。新工具有更全面的指标，更容易上手分析。这个绝对的优势，可以让你更直观地得到想要的数据，也不容易让你打退堂鼓。\n最好试着去理解性能工具的原理，或者熟悉了使用方法后，再回过头重新学习原理。这样，即使是在无法安装新工具的环境中，你仍然可以从 proc 文件系统或者其他地方，获得同样的指标，进行有效的分析。\n问题 2：使用 stress 命令，无法模拟 iowait 高的场景 可以运行下面的命令，来模拟 iowait 的问题："},{"id":23,"href":"/post/14%E7%AD%94%E7%96%91%E4%BA%8C%E5%A6%82%E4%BD%95%E7%94%A8perf%E5%B7%A5%E5%85%B7%E5%88%86%E6%9E%90Java%E7%A8%8B%E5%BA%8F/","title":"14|答疑（二）如何用perf工具分析Java程序？","parent":"Linux性能优化","content":" 问题 1： 使用 perf 工具时，看到的是 16 进制地址而不是函数名 只要你观察一下 perf 界面最下面的那一行，就会发现一个警告信息：\nFailed to open /opt/bitnami/php/lib/php/extensions/opcache.so, continuing without symbols 这说明，perf 找不到待分析进程依赖的库。当然，实际上这个案例中有很多依赖库都找不到，只不过，perf 工具本身只在最后一行显示警告信息，所以你只能看到这一条警告。\n这个问题，其实也是在分析 Docker 容器应用时，我们经常碰到的一个问题，因为容器应用依赖的库都在镜像里面。\n四个解决方法:\n第一个方法，在容器外面构建相同路径的依赖库。这种方法从原理上可行，但是我并不推荐，一方面是因为找出这些依赖库比较麻烦，更重要的是，构建这些路径，会污染容器主机的环境。 第二个方法，在容器内部运行 perf。不过，这需要容器运行在特权模式下，但实际的应用程序往往只以普通容器的方式运行。所以，容器内部一般没有权限执行 perf 分析。 第三个方法，指定符号路径为容器文件系统的路径。 $ mkdir /tmp/foo $ PID=$(docker inspect --format {{.State.Pid}} phpfpm) $ bindfs /proc/$PID/root /tmp/foo $ perf report --symfs /tmp/foo # 使用完成后不要忘记解除绑定 $ umount /tmp/foo/ 第四个方法，在容器外面把分析纪录保存下来，再去容器里查看结果。这样，库和符号的路径也就都对了。 问题 2：如何用 perf 工具分析 Java 程序 问题 3：为什么 perf 的报告中，很多符号都不显示调用栈 问题 4：怎么理解 perf report 报告 工具性能了解：\nperf 这种动态追踪工具，会给系统带来一定的性能损失。 vmstat、pidstat 这些直接读取 proc 文件系统来获取指标的工具，不会带来性能损失。 问题 5：性能优化书籍和参考资料推荐 《性能之巅：洞悉系统、企业与云计算》\nhttp://www.brendangregg.com/ 特别关注：http://www.brendangregg.com/linuxperf.html\nLinux 性能工具图谱 性能分析参考资料 性能优化的演讲视频 抓住主线不动摇，先从最基本的原理开始，掌握性能分析的思路，然后再逐步深入，探究细节，不要试图一口吃成个大胖子。 ","description":"问题 1： 使用 perf 工具时，看到的是 16 进制地址而不是函数名 只要你观察一下 perf 界面最下面的那一行，就会发现一个警告信息："},{"id":24,"href":"/post/15%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E5%86%85%E5%AD%98%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84/","title":"15|基础篇--Linux内存是怎么工作的？","parent":"Linux性能优化","content":" 内存定义 内存主要用来存储系统和应用程序的指令、数据、缓存等。\n内存映射 虚拟地址空间：是连续的，不同字长的处理器，地址空间范围不同 内核空间 用户空间 内存映射：就是将虚拟内存地址映射到物理内存地址 缺页异常：当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异\n页：一个内存映射的最小单位也就是页，通常是 4 KB 大小。这样，每一次内存映射，都需要关联 4 KB 或者 4KB 整数倍的内存空间。\n多页分级和大页\n页的大小只有 4 KB ，导致的另一个问题就是，整个页表会变得非常大。比方说，仅 32 位系统就需要 100 多万个页表项（4GB/4KB），才可以实现整个地址空间的映射。为了解决页表项过多的问题，Linux 提供了两种机制，也就是多级页表和大页（HugePage）。 多页分级 就是把内存分成区块来管理，将原来的映射关系改成区块索引和区块内的偏移。 由于虚拟内存空间通常只用了很少一部分，那么，多级页表就只保存这些使用中的区块，这样就可以大大地减少页表的项数。 Linux 用的正是四级页表来管理内存页 大页 就是比普通页更大的内存块，常见的大小有 2MB 和 1GB。 大页通常用在使用大量内存的进程上，比如 Oracle、DPDK 等。 虚拟内存空间分布 只读段，包括代码和常量等。 数据段，包括全局变量等。 堆，包括动态分配的内存，从低地址开始向上增长。 文件映射段，包括动态库、共享内存等，从高地址开始向下增长。 栈，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。 内存分配与回收 linux使用伙伴系统来管理内存分配\n发现内存紧张：\n回收缓存 回收不常访问的内存 使用交换分区（swap） swap就是把其中一块磁盘当内存使用 换出：把进程暂时不用的数据存储到磁盘中 换入：当进程访问这些内存时，再从磁盘读取这些数据到内存中 由于磁盘读写的速度远比内存慢，Swap 会导致严重的内存性能问题。 杀死进程 oom（out of memory）问题，内核的一种保护机制 一个进程消耗的内存越大，oom_score 就越大 一个进程运行占用的 CPU 越多，oom_score 就越小 进程的 oom_score 越大，代表消耗的内存越多，也就越容易被 OOM 杀死，从而可以更好保护系统 oom_adj 的范围是 [-17, 15]，数值越大，表示进程越容易被 OOM 杀死；数值越小，表示进程越不容易被 OOM 杀死，其中 -17 表示禁止 OOM。 如何查看内存使用情况 free ## 这两行分别是物理内存 Mem 和交换分区 Swap 的使用情况 zsy@ubuntu:~$ free total used free shared buff/cache available Mem: 2028784 953944 434752 1972 640088 911864 Swap: 2097148 0 2097148 第一列，total 是总内存大小； 第二列，used 是已使用内存的大小，包含了共享内存； 第三列，free 是未使用内存的大小； 第四列，shared 是共享内存的大小； 第五列，buff/cache 是缓存和缓冲区的大小； 最后一列，available 是新进程可用内存的大小。 小结 当进程通过 malloc() 申请内存后，内存并不会立即分配，而是在首次访问时，才通过缺页异常陷入内核中分配内存。\n由于进程的虚拟地址空间比物理内存大很多，Linux 还提供了一系列的机制，应对内存不足的问题，比如缓存的回收、交换分区 Swap 以及 OOM 等。\n了解系统或者进程的内存使用情况时，可以用 free 和 top 、ps 等性能工具。\n","description":"内存定义 内存主要用来存储系统和应用程序的指令、数据、缓存等。\n内存映射 虚拟地址空间：是连续的，不同字长的处理器，地址空间范围不同 内核空间 用户空间 内存映射：就是将虚拟内存地址映射到物理内存地址 缺页异常：当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异\n页：一个内存映射的最小单位也就是页，通常是 4 KB 大小。这样，每一次内存映射，都需要关联 4 KB 或者 4KB 整数倍的内存空间。"},{"id":25,"href":"/post/16%E5%9F%BA%E7%A1%80%E7%AF%87%E6%80%8E%E4%B9%88%E7%90%86%E8%A7%A3%E5%86%85%E5%AD%98%E4%B8%AD%E7%9A%84Buffer%E5%92%8CCache/","title":"16|基础篇怎么理解内存中的Buffer和Cache？","parent":"Linux性能优化","content":" free数据来源 Buffers 是内核缓冲区用到的内存，对应 /proc/meminfo 中的Buffers值 Cache 是内核页缓存和Slab用到的内存，对应 /proc/meminfo 中Cached与SReclaimable之和 $ watch cat /proc/meminfo 【注】网上的结论可能是对的，但是很可能跟你的环境并不匹配。最简单来说，同一个指标的具体含义，就可能因为内核版本、性能工具版本的不同而有挺大差别。这也是为什么，我总在专栏中强调通用思路和方法，而不是让你死记结论。对于案例实践来说，机器环境就是我们的最大限制。\nproc文件系统 /proc是linux特殊的文件系统，是用户跟内核交互的接口 内核的运行状态 配置选项 查询进程的运行状态 统计数据 修改内核配置 也是很多性能工具的最终数据来源 free就是通过读取/proc/meminfo，得到内存的使用情况 Buffers 是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等。 Cached 是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。 SReclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。 示例 清理系统缓存：\n$ echo 3 \u0026gt; /proc/sys/vm/drop_caches 磁盘与文件写入 使用vmstat命令\n【关注重点】内存部分的 buff 和 cache ，以及 io 部分的 bi 和 bo\nbuff 和 cache 就是 Buffers 和 Cache，单位是 KB bi 和 bo 则分别表示块设备读取和写入的大小，单位为块 / 秒。因为 Linux 中块的大小是 1KB，所以这个单位也就等价于 KB/s 场景 1：磁盘和文件写案例 步骤一：运行dd命令向磁盘分区/dev/sdb1写入2G数据\nzsy@ubuntu:~$ sudo dd if=/dev/urandom of=/dev/sdb1 bs=1M count=2048 dd: error writing \u0026#39;/dev/sdb1\u0026#39;: No space left on device 964+0 records in 963+0 records out 1009917952 bytes (1.0 GB, 963 MiB) copied, 5.31438 s, 190 MB/s 步骤二：观察内存与io变化\n场景 2：磁盘和文件读案例 步骤一：读取数据写入空设备\nzsy@ubuntu:~$ dd if=/tmp/file of=/dev/null 0+1 records in 0+1 records out 54 bytes copied, 0.000117266 s, 460 kB/s 步骤二：观察内存和 I/O 的变化情况\nzsy@ubuntu:~$ vmstat 1 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 315136 97304 20068 985864 1 165 178 182 249 524 2 2 96 0 0 3 0 315136 97004 20076 985864 0 0 0 12 1056 2413 4 2 94 0 0 0 0 315136 95728 20076 985912 0 0 0 0 1590 3150 11 3 85 0 0 0 0 315136 96508 20076 985912 0 0 0 0 550 1042 2 2 96 0 0 0 0 315136 96248 20076 985912 0 0 0 0 618 1075 1 2 97 0 0 0 0 315136 96516 20080 985908 4 0 16 0 1308 2007 2 1 97 0 0 0 0 315136 130836 20088 985756 8 0 900 48 863 1750 2 2 96 1 0 0 0 315136 130096 20088 985756 0 0 0 0 659 1225 1 2 97 0 0 0 0 315136 131104 20088 985756 0 0 0 8 801 1488 2 2 96 0 0 0 0 315136 131088 20088 985756 0 0 0 0 848 1676 2 1 97 0 0 ^Z [6]+ Stopped vmstat 1 读磁盘时（也就是 bi 大于 0 时），Buffer 和 Cache 都在增长，但显然 Buffer 的增长快很多。这说明读磁盘时，数据缓存到了 Buffer 中。\nBuffer 既可以用作“将要写入磁盘数据的缓存”，也可以用作“从磁盘读取数据的缓存”。 Cache 既可以用作“从文件读取数据的页缓存”，也可以用作“写文件的页缓存”。 小结 从写的角度来说，不仅可以优化磁盘和文件的写入，对应用程序也有好处，应用程序可以在数据真正落盘前，就返回去做其他工作。 从读的角度来说，既可以加速读取那些需要频繁访问的数据，也降低了频繁 I/O 对磁盘的压力。 ","description":"free数据来源 Buffers 是内核缓冲区用到的内存，对应 /proc/meminfo 中的Buffers值 Cache 是内核页缓存和Slab用到的内存，对应 /proc/meminfo 中Cached与SReclaimable之和 $ watch cat /proc/meminfo 【注】网上的结论可能是对的，但是很可能跟你的环境并不匹配。最简单来说，同一个指标的具体含义，就可能因为内核版本、性能工具版本的不同而有挺大差别。这也是为什么，我总在专栏中强调通用思路和方法，而不是让你死记结论。对于案例实践来说，机器环境就是我们的最大限制。"},{"id":26,"href":"/post/17%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%BF%90%E8%A1%8C%E6%95%88%E7%8E%87/","title":"17|案例篇--如何利用系统缓存优化程序的运行效率？","parent":"Linux性能优化","content":" 缓存命中率 缓存命中率，是指直接通过缓存获取数据的请求次数，占所有数据请求次数的百分比。 命中率越高，表示使用缓存带来的收益越高，应用程序的性能也就越好。 缓存是现在所有高并发系统必需的核心模块，主要作用就是把经常访问的数据（也就是热点数据），提前读入到内存中。 这样，下次访问时就可以直接从内存读取数据，而不需要经过硬盘，从而加快应用程序的响应速度。 这两个工具都是 bcc 软件包的一部分，它们基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，来跟踪内核中管理的缓存，并输出缓存的使用和命中情况。\ncachestat 提供了整个操作系统缓存的读写命中情况。 cachetop 提供了每个进程的缓存命中情况。 安装命令： sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD echo \u0026#34;deb https://repo.iovisor.org/apt/xenial xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/iovisor.list sudo apt-get update sudo apt-get install -y bcc-tools libbcc-examples linux-headers-$(uname -r) (提示：工具未能安装成功)\n指定文件的缓存大小 工具pcstat安装使用\n$ pcstat /bin/ls +---------+----------------+------------+-----------+---------+ | Name | Size (bytes) | Pages | Cached | Percent | |---------+----------------+------------+-----------+---------| | /bin/ls | 133792 | 33 | 0 | 000.000 | +---------+----------------+------------+-----------+---------+ 总结 Buffers 和 Cache 可以极大提升系统的 I/O 性能。通常，我们用缓存命中率，来衡量缓存的使用效率。命中率越高，表示缓存被利用得越充分，应用程序的性能也就越好。\n可以用 cachestat 和 cachetop 这两个工具，观察系统和进程的缓存命中情况。\ncachestat 提供了整个系统缓存的读写命中情况。 cachetop 提供了每个进程的缓存命中情况。 ","description":"缓存命中率 缓存命中率，是指直接通过缓存获取数据的请求次数，占所有数据请求次数的百分比。 命中率越高，表示使用缓存带来的收益越高，应用程序的性能也就越好。 缓存是现在所有高并发系统必需的核心模块，主要作用就是把经常访问的数据（也就是热点数据），提前读入到内存中。 这样，下次访问时就可以直接从内存读取数据，而不需要经过硬盘，从而加快应用程序的响应速度。 这两个工具都是 bcc 软件包的一部分，它们基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，来跟踪内核中管理的缓存，并输出缓存的使用和命中情况。"},{"id":27,"href":"/post/18%E6%A1%88%E4%BE%8B%E7%AF%87%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E4%BA%86%E6%88%91%E8%AF%A5%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E5%92%8C%E5%A4%84%E7%90%86/","title":"18|案例篇--内存泄漏了，我该如何定位和处理？","parent":"Linux性能优化","content":" 内存的分配和回收 事先并不知道数据大小，所以你就要用到标准库函数 malloc() ， 在程序中动态分配内存。这时候，系统就会从内存空间的堆中分配内存。\n堆内存由应用程序自己来分配和管理。除非程序退出，这些堆内存并不会被系统自动释放，而是需要应用程序明确调用库函数 free() 来释放它们。如果应用程序没有正确释放堆内存，就会造成内存泄漏。\n只读段，包括程序的代码和常量，由于是只读的，不会再去分配新的内存，所以也不会产生内存泄漏。 数据段，包括全局变量和静态变量，这些变量在定义时就已经确定了大小，所以也不会产生内存泄漏。 最后一个内存映射段，包括动态链接库和共享内存，其中共享内存由程序动态分配和管理。所以，如果程序在分配后忘了回收，就会导致跟堆内存类似的泄漏问题。 内存泄漏的危害非常大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用。内存泄漏不断累积，甚至会耗尽系统内存。\n系统最终可以通过 OOM （Out of Memory）机制杀死进程，但进程在 OOM 前，可能已经引发了一连串的反应，导致严重的性能问题。\n小结 malloc() 和 free() 通常并不是成对出现，而是需要你，在每个异常处理路径和成功路径上都释放内存 。 在多线程程序中，一个线程中分配的内存，可能会在另一个线程中访问和释放。 更复杂的是，在第三方的库函数中，隐式分配的内存可能需要应用程序显式释放。 为了避免内存泄漏，最重要的一点就是养成良好的编程习惯，比如分配内存后，一定要先写好内存释放的代码，再去开发其他逻辑。\n","description":"内存的分配和回收 事先并不知道数据大小，所以你就要用到标准库函数 malloc() ， 在程序中动态分配内存。这时候，系统就会从内存空间的堆中分配内存。\n堆内存由应用程序自己来分配和管理。除非程序退出，这些堆内存并不会被系统自动释放，而是需要应用程序明确调用库函数 free() 来释放它们。如果应用程序没有正确释放堆内存，就会造成内存泄漏。\n只读段，包括程序的代码和常量，由于是只读的，不会再去分配新的内存，所以也不会产生内存泄漏。 数据段，包括全局变量和静态变量，这些变量在定义时就已经确定了大小，所以也不会产生内存泄漏。 最后一个内存映射段，包括动态链接库和共享内存，其中共享内存由程序动态分配和管理。所以，如果程序在分配后忘了回收，就会导致跟堆内存类似的泄漏问题。 内存泄漏的危害非常大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用。内存泄漏不断累积，甚至会耗尽系统内存。"},{"id":28,"href":"/post/19%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E7%B3%BB%E7%BB%9F%E7%9A%84Swap%E5%8F%98%E9%AB%98%E4%BA%86%E4%B8%8A/","title":"19|案例篇--为什么系统的Swap变高了（上）","parent":"Linux性能优化","content":" 文件页（File-backed Page） 大部分文件页，都可以直接回收，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。\n可以在应用程序中，通过系统调用 fsync ，把脏页同步到磁盘中； 也可以交给系统，由内核线程 pdflush 负责这些脏页的刷新。 Swap 原理 它包括换出和换入两个过程。\n所谓换出，就是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存。 而换入，则是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来。 Swap 其实是把系统的可用内存变大了。这样，即使服务器的内存不足，也可以运行大内存的应用程序。 直接内存回收 定期回收内存，也就是 kswapd0 三个内存阈值（watermark，也称为水位 页最小阈值（pages_min） 页低阈值（pages_low） 页高阈值（pages_high） 剩余内存，则使用 pages_free 表示 kswapd0 定期扫描内存的使用情况，并根据剩余内存落在这三个阈值的空间位置，进行内存的回收操作。\n剩余内存小于页最小阈值，说明进程可用内存都耗尽了，只有内核才可以分配内存。 剩余内存落在页最小阈值和页低阈值中间，说明内存压力比较大，剩余内存不多了。这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值为止。 剩余内存落在页低阈值和页高阈值中间，说明内存有一定压力，但还可以满足新内存请求。 剩余内存大于页高阈值，说明剩余内存比较多，没有内存压力。 一旦剩余内存小于页低阈值，就会触发内存的回收 页低阈值，其实可以通过内核选项 /proc/sys/vm/min_free_kbytes 来间接设置 min_free_kbytes 设置了页最小阈值，而其他两个阈值，都是根据页最小阈值计算生成的，计算方法如下 ： pages_low = pages_min*5/4 pages_high = pages_min*3/2 NUMA 与 Swap 很多情况下，你\\明明发现了 Swap 升高，可是在分析系统的内存使用时，却很可能发现，系统剩余内存还多着呢。为什么剩余内存很多的情况下，也会发生 Swap 呢？:::::::正是处理器的 NUMA （Non-Uniform Memory Access）架构导致的。\n在 NUMA 架构下，多个处理器被划分到不同 Node 上，且每个 Node 都拥有自己的本地内存空间。\n工具numactl：查看处理器在 Node 的分布情况，以及每个 Node 的内存使用情况\nzsy@ubuntu:~$ numactl --hardware available: 1 nodes (0) node 0 cpus: 0 1 node 0 size: 1981 MB node 0 free: 190 MB node distances: node 0 0: 10 提到的三个内存阈值（页最小阈值、页低阈值和页高阈值），都可以通过内存域在 proc 文件系统中的接口 /proc/zoneinfo 来查看：\nzsy@ubuntu:~$ cat /proc/zoneinfo Node 0, zone DMA per-node stats nr_inactive_anon 173802 nr_active_anon 133182 nr_inactive_file 32771 nr_active_file 56062 nr_unevictable 0 nr_slab_reclaimable 17327 nr_slab_unreclaimable 29472 nr_isolated_anon 0 nr_isolated_file 0 workingset_nodes 2058 workingset_refault 155937 workingset_activate 33796 workingset_restore 15995 workingset_nodereclaim 945 nr_anon_pages 164627 nr_mapped 31095 nr_file_pages 232300 nr_dirty 14 nr_writeback 0 nr_writeback_temp 0 nr_shmem 141403 nr_shmem_hugepages 0 nr_shmem_pmdmapped 0 nr_file_hugepages 0 nr_file_pmdmapped 0 nr_anon_transparent_hugepages 0 nr_unstable 0 nr_vmscan_write 243216 nr_vmscan_immediate_reclaim 732 nr_dirtied 413853 nr_written 596735 nr_kernel_misc_reclaimable 0 pages free 2018 min 90 low 112 high 134 spanned 4095 present 3998 managed 3977 protection: (0, 1910, 1910, 1910, 1910) nr_free_pages 2018 nr_zone_inactive_anon 1943 nr_zone_active_anon 0 nr_zone_inactive_file 0 nr_zone_active_file 0 nr_zone_unevictable 0 nr_zone_write_pending 0 nr_mlock 0 nr_page_table_pages 0 nr_kernel_stack 0 nr_bounce 0 nr_zspages 0 nr_free_cma 0 numa_hit 5877 numa_miss 0 numa_foreign 0 numa_interleave 0 numa_local 5877 numa_other 0 pagesets cpu: 0 count: 0 high: 0 batch: 1 vm stats threshold: 4 cpu: 1 count: 0 high: 0 batch: 1 vm stats threshold: 4 node_unreclaimable: 0 start_pfn: 1 Node 0, zone DMA32 pages free 44994 min 11173 low 13966 high 16759 spanned 520172 present 520172 managed 503219 protection: (0, 0, 0, 0, 0) nr_free_pages 44994 nr_zone_inactive_anon 171859 nr_zone_active_anon 133182 nr_zone_inactive_file 32771 nr_zone_active_file 56062 nr_zone_unevictable 0 nr_zone_write_pending 14 nr_mlock 0 nr_page_table_pages 4398 nr_kernel_stack 10464 nr_bounce 0 nr_zspages 0 nr_free_cma 0 numa_hit 11427432 numa_miss 0 numa_foreign 0 numa_interleave 39965 numa_local 11427432 numa_other 0 pagesets cpu: 0 count: 148 high: 378 batch: 63 vm stats threshold: 20 cpu: 1 count: 338 high: 378 batch: 63 vm stats threshold: 20 node_unreclaimable: 0 start_pfn: 4096 Node 0, zone Normal pages free 0 min 0 low 0 high 0 spanned 0 present 0 managed 0 protection: (0, 0, 0, 0, 0) Node 0, zone Movable pages free 0 min 0 low 0 high 0 spanned 0 present 0 managed 0 protection: (0, 0, 0, 0, 0) Node 0, zone Device pages free 0 min 0 low 0 high 0 spanned 0 present 0 managed 0 protection: (0, 0, 0, 0, 0) pages 处的 min、low、high，就是上面提到的三个内存阈值，而 free 是剩余内存页数，它跟后面的 nr_free_pages 相同。 nr_zone_active_anon 和 nr_zone_inactive_anon，分别是活跃和非活跃的匿名页数。 nr_zone_active_file 和 nr_zone_inactive_file，分别是活跃和非活跃的文件页数。 某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。具体选哪种模式，你可以通过 /proc/sys/vm/zone_reclaim_mode 来调整。它支持以下几个选项：\n默认的 0 ，也表示既可以从其他 Node 寻找空闲内存，也可以从本地回收内存。 1、2、4 都表示只回收本地内存，2 表示可以回写脏数据回收内存，4 表示可以用 Swap 方式回收内存。 swappiness 对文件页的回收，当然就是直接回收缓存，或者把脏页写回磁盘后再回收。 而对匿名页的回收，其实就是通过 Swap 机制，把它们写入磁盘后再释放内存。 Linux 提供了一个 /proc/sys/vm/swappiness 选项，用来调整使用 Swap 的积极程度。\nswappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页。\n","description":"文件页（File-backed Page） 大部分文件页，都可以直接回收，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。\n可以在应用程序中，通过系统调用 fsync ，把脏页同步到磁盘中； 也可以交给系统，由内核线程 pdflush 负责这些脏页的刷新。 Swap 原理 它包括换出和换入两个过程。"},{"id":29,"href":"/post/20%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E7%B3%BB%E7%BB%9F%E7%9A%84Swap%E5%8F%98%E9%AB%98%E4%BA%86%E4%B8%8B/","title":"20|案例篇--为什么系统的Swap变高了（下）","parent":"Linux性能优化","content":"在内存资源紧张时，Linux 会通过 Swap ，把不常访问的匿名页换出到磁盘中，下次访问的时候再从磁盘换入到内存中来。你可以设置 /proc/sys/vm/min_free_kbytes，来调整系统定期回收内存的阈值；也可以设置 /proc/sys/vm/swappiness，来调整文件页和匿名页的回收倾向。\n当 Swap 变高时，你可以用 sar、/proc/zoneinfo、/proc/pid/status 等方法，查看系统和进程的内存使用情况，进而找出 Swap 升高的根源和受影响的进程。\n反过来说，通常，降低 Swap 的使用，可以提高系统的整体性能。要怎么做呢？这里，总结了几种常见的降低方法。\n禁止 Swap，现在服务器的内存足够大，所以除非有必要，禁用 Swap 就可以了。随着云计算的普及，大部分云平台中的虚拟机都默认禁止 Swap。 如果实在需要用到 Swap，可以尝试降低 swappiness 的值，减少内存回收时 Swap 的使用倾向。 响应延迟敏感的应用，如果它们可能在开启 Swap 的服务器中运行，你还可以用库函数 mlock() 或者 mlockall() 锁定内存，阻止它们的内存换出。 ","description":"在内存资源紧张时，Linux 会通过 Swap ，把不常访问的匿名页换出到磁盘中，下次访问的时候再从磁盘换入到内存中来。你可以设置 /proc/sys/vm/min_free_kbytes，来调整系统定期回收内存的阈值；也可以设置 /proc/sys/vm/swappiness，来调整文件页和匿名页的回收倾向。\n当 Swap 变高时，你可以用 sar、/proc/zoneinfo、/proc/pid/status 等方法，查看系统和进程的内存使用情况，进而找出 Swap 升高的根源和受影响的进程。"},{"id":30,"href":"/post/21%E5%A5%97%E8%B7%AF%E7%AF%87%E5%A6%82%E4%BD%95%E5%BF%AB%E5%87%86%E7%8B%A0%E6%89%BE%E5%88%B0%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%9A%84%E9%97%AE%E9%A2%98/","title":"21|套路篇--如何“快准狠”找到系统内存的问题？","parent":"Linux性能优化","content":" 内存性能指标 系统内存使用情况：已用内存、剩余内存、共享内存、可用内存、缓存和缓冲区的用量\n已用内存和剩余内存很容易理解，就是已经使用和还未使用的内存。 共享内存是通过 tmpfs 实现的，所以它的大小也就是 tmpfs 使用的内存大小。tmpfs 其实也是一种特殊的缓存。 可用内存是新进程可以使用的最大内存，它包括剩余内存和可回收缓存。 缓存包括两部分，一部分是磁盘读取文件的页缓存，用来缓存从磁盘读取的数据，可以加快以后再次访问的速度。 另一部分，则是 Slab 分配器中的可回收内存。缓冲区是对原始磁盘块的临时存储，用来缓存将要写入磁盘的数据。这样，内核就可以把分散的写集中起来，统一优化磁盘写入。 进程内存使用情况：进程的虚拟内存、常驻内存、共享内存以及 Swap 内存\n虚拟内存，包括了进程代码段、数据段、共享内存、已经申请的堆内存和已经换出的内存等。这里要注意，已经申请的内存，即使还没有分配物理内存，也算作虚拟内存。 常驻内存是进程实际使用的物理内存，不过，它不包括 Swap 和共享内存。 常驻内存一般会换算成占系统总内存的百分比，也就是进程的内存使用率。 共享内存，既包括与其他进程共同使用的真实的共享内存，还包括了加载的动态链接库以及程序的代码段等。 Swap 内存，是指通过 Swap 换出到磁盘的内存。 缺页异常：\n可以直接从物理内存中分配时，被称为次缺页异常。 需要磁盘 I/O 介入（比如 Swap）时，被称为主缺页异常。 Swap 的使用情况：Swap 的已用空间、剩余空间、换入速度和换出速度\n已用空间和剩余空间很好理解，就是字面上的意思，已经使用和没有使用的内存空间。 换入和换出速度，则表示每秒钟换入和换出内存的大小。 内存性能工具 通过 proc 文件系统，找到了内存指标的来源；并通过 vmstat，动态观察了内存的变化情况。与 free 相比，vmstat 除了可以动态查看内存变化，还可以区分缓存和缓冲区、Swap 换入和换出的内存大小。\n性能指标和工具的联系 从内存指标出发，更容易把工具和内存的工作原理关联起来。 从性能工具出发，可以更快地利用工具，找出我们想观察的性能指标。特别是在工具有限的情况下，我们更得充分利用手头的每一个工具，挖掘出更多的问题。 如何迅速分析内存的性能瓶颈 为了迅速定位内存问题，我通常会先运行几个覆盖面比较大的性能工具，比如 free、top、vmstat、pidstat 等。\n具体的分析思路主要有这几步。\n先用 free 和 top，查看系统整体的内存使用情况。 再用 vmstat 和 pidstat，查看一段时间的趋势，从而判断出内存问题的类型。 最后进行详细分析，比如内存分配分析、缓存 / 缓冲区分析、具体进程的内存使用分析等。 ","description":"内存性能指标 系统内存使用情况：已用内存、剩余内存、共享内存、可用内存、缓存和缓冲区的用量\n已用内存和剩余内存很容易理解，就是已经使用和还未使用的内存。 共享内存是通过 tmpfs 实现的，所以它的大小也就是 tmpfs 使用的内存大小。tmpfs 其实也是一种特殊的缓存。 可用内存是新进程可以使用的最大内存，它包括剩余内存和可回收缓存。 缓存包括两部分，一部分是磁盘读取文件的页缓存，用来缓存从磁盘读取的数据，可以加快以后再次访问的速度。 另一部分，则是 Slab 分配器中的可回收内存。缓冲区是对原始磁盘块的临时存储，用来缓存将要写入磁盘的数据。这样，内核就可以把分散的写集中起来，统一优化磁盘写入。 进程内存使用情况：进程的虚拟内存、常驻内存、共享内存以及 Swap 内存"},{"id":31,"href":"/post/22%E7%AD%94%E7%96%91%E4%B8%89%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%A3%81%E7%9B%98%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88/","title":"22|答疑（三）文件系统与磁盘的区别是什么？","parent":"Linux性能优化","content":" 问题 1：内存回收与 OOM 怎么理解 LRU 内存回收？ 回收后的内存又到哪里去了？ OOM 是按照虚拟内存还是实际内存来打分？ 怎么估计应用程序的最小内存？ 一旦发现内存紧张，系统会通过三种方式回收内存。\n这三种方式分别是 ：\n基于 LRU（Least Recently Used）算法，回收缓存； 基于 Swap 机制，回收不常访问的匿名页； 基于 OOM（Out of Memory）机制，杀掉占用大量内存的进程。前两种方式，缓存回收和 Swap 回收，实际上都是基于 LRU 算法，也就是优先回收不常访问的内存。 LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：\nactive 记录活跃的内存页； inactive 记录非活跃的内存页。 问题 2: 文件系统与磁盘的区别 读写文件最终也是读写磁盘，到底要怎么区分，是读写文件还是读写磁盘呢？ 读写磁盘难道可以不经过文件系统吗？ 磁盘是一个存储设备（确切地说是块设备），可以被划分为不同的磁盘分区。而在磁盘或者磁盘分区上，还可以再创建文件系统，并挂载到系统的某个目录中。这样，系统就可以通过这个挂载目录，来读写文件。\nLinux 中一切皆文件。换句话说，你可以通过相同的文件接口，来访问磁盘和文件（比如 open、read、write、close 等）。我们通常说的“文件”，其实是指普通文件。而磁盘或者分区，则是指块设备文件。\n问题 3: 如何统计所有进程的物理内存使用量 问题 4: CentOS 系统中如何安装 bcc-tools 问题 5: 内存泄漏案例的优化方法 在内存泄漏案例的最后，我们通过增加 free() 调用，释放了函数 fibonacci() 分配的内存，修复了内存泄漏的问题。就这个案例而言，还有没有其他更好的修复方法呢？\n","description":"问题 1：内存回收与 OOM 怎么理解 LRU 内存回收？ 回收后的内存又到哪里去了？ OOM 是按照虚拟内存还是实际内存来打分？ 怎么估计应用程序的最小内存？ 一旦发现内存紧张，系统会通过三种方式回收内存。"},{"id":32,"href":"/post/23%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84/","title":"23|基础篇--Linux文件系统是怎么工作的？","parent":"Linux性能优化","content":" 索引节点和目录项 Linux 文件系统为每个文件都分配两个数据结构，索引节点（index node）和目录项（directory entry）。它们主要用来记录文件的元信息和目录结构。\n索引节点，简称为 inode，用来记录文件的元数据，比如 inode 编号、文件大小、访问权限、修改日期、数据的位置等。索引节点和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中。所以记住，索引节点同样占用磁盘空间。 目录项，简称为 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的关联关系。多个关联的目录项，就构成了文件系统的目录结构。不过，不同于索引节点，目录项是由内核维护的一个内存数据结构，所以通常也被叫做目录项缓存。 索引节点是每个文件的唯一标志，而目录项维护的正是文件系统的树状结构。目录项和索引节点的关系是多对一，可简单理解为，一个文件可以有多个别名。 索引节点和目录项纪录了文件的元数据，以及文件间的目录关系 磁盘读写的最小单位是扇区，然而扇区只有 512B 大小 文件系统又把连续的扇区组成了逻辑块，然后每次都以逻辑块为最小单元，来管理数据。 常见的逻辑块大小为 4KB，也就是由连续的 8 个扇区组成。 第一，目录项本身就是一个内存缓存，而索引节点则是存储在磁盘中的数据。 第二，磁盘在执行文件系统格式化时，会被分成三个存储区域，超级块、索引节点区和数据块区。其中， 超级块，存储整个文件系统的状态。 索引节点区，用来存储索引节点。 数据块区，则用来存储文件数据。 虚拟文件系统 linux文件系统四要素：目录项、索引节点、逻辑块以及超级块\n虚拟文件系统 VFS（Virtual File System）：Linux 内核在用户进程和文件系统的中间，引入了一个抽象层\n文件系统 I/O cat命令示例：\n首先调用 open() ，打开一个文件 然后调用 read() ，读取文件的内容 最后再调用 write() ，把文件内容输出到控制台的标准输出中 文件读写方式的各种差异，导致 I/O 的分类多种多样：\n缓冲与非缓冲 I/O 直接与非直接 I/O 阻塞与非阻塞 I/O 同步与异步 I/O 根据是否利用标准库缓存，可以把文件 I/O 分为缓冲 I/O 与非缓冲 I/O\n缓冲 I/O，是指利用标准库缓存来加速文件的访问，而标准库内部再通过系统调度访问文件。 非缓冲 I/O，是指直接通过系统调用来访问文件，不再经过标准库缓存。 根据是否利用操作系统的页缓存，可以把文件 I/O 分为直接 I/O 与非直接 I/O\n直接 I/O，是指跳过操作系统的页缓存，直接跟文件系统交互来访问文件。 非直接 I/O 正好相反，文件读写时，先要经过系统的页缓存，然后再由内核或额外的系统调用，真正写入磁盘。 根据应用程序是否阻塞自身运行，可以把文件 I/O 分为阻塞 I/O 和非阻塞 I/O\n所谓阻塞 I/O，是指应用程序执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程，自然就不能执行其他任务。 所谓非阻塞 I/O，是指应用程序执行 I/O 操作后，不会阻塞当前的线程，可以继续执行其他的任务，随后再通过轮询或者事件通知的形式，获取调用的结果。 根据是否等待响应结果，可以把文件 I/O 分为同步和异步 I/O\n所谓同步 I/O，是指应用程序执行 I/O 操作后，要一直等到整个 I/O 完成后，才能获得 I/O 响应。 所谓异步 I/O，是指应用程序执行 I/O 操作后，不用等待完成和完成后的响应，而是继续执行就可以。等到这次 I/O 完成后，响应会用事件通知的方式，告诉应用程序。 性能观测 容量 缓存 工具：/proc/slabinfo、slabtop\n","description":"索引节点和目录项 Linux 文件系统为每个文件都分配两个数据结构，索引节点（index node）和目录项（directory entry）。它们主要用来记录文件的元信息和目录结构。\n索引节点，简称为 inode，用来记录文件的元数据，比如 inode 编号、文件大小、访问权限、修改日期、数据的位置等。索引节点和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中。所以记住，索引节点同样占用磁盘空间。 目录项，简称为 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的关联关系。多个关联的目录项，就构成了文件系统的目录结构。不过，不同于索引节点，目录项是由内核维护的一个内存数据结构，所以通常也被叫做目录项缓存。 索引节点是每个文件的唯一标志，而目录项维护的正是文件系统的树状结构。目录项和索引节点的关系是多对一，可简单理解为，一个文件可以有多个别名。 索引节点和目录项纪录了文件的元数据，以及文件间的目录关系 磁盘读写的最小单位是扇区，然而扇区只有 512B 大小 文件系统又把连续的扇区组成了逻辑块，然后每次都以逻辑块为最小单元，来管理数据。 常见的逻辑块大小为 4KB，也就是由连续的 8 个扇区组成。 第一，目录项本身就是一个内存缓存，而索引节点则是存储在磁盘中的数据。 第二，磁盘在执行文件系统格式化时，会被分成三个存储区域，超级块、索引节点区和数据块区。其中， 超级块，存储整个文件系统的状态。 索引节点区，用来存储索引节点。 数据块区，则用来存储文件数据。 虚拟文件系统 linux文件系统四要素：目录项、索引节点、逻辑块以及超级块"},{"id":33,"href":"/post/24%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E7%A3%81%E7%9B%98IO%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%8A/","title":"24|基础篇--Linux磁盘I/O是怎么工作的（上）","parent":"Linux性能优化","content":" 磁盘 磁盘是可以持久化存储的设备，根据存储介质的不同，常见磁盘可以分为两类：机械磁盘和固态磁盘。\n第一类，机械磁盘，也称为硬盘驱动器（Hard Disk Driver），通常缩写为 HDD。机械磁盘主要由盘片和读写磁头组成，数据就存储在盘片的环状磁道中。在读写数据前，需要移动读写磁头，定位到数据所在的磁道，然后才能访问数据。 第二类，固态磁盘（Solid State Disk），通常缩写为 SSD，由固态电子元器件组成。固态磁盘不需要磁道寻址，所以，不管是连续 I/O，还是随机 I/O 的性能，都比机械磁盘要好得多。 无论机械磁盘，还是固态磁盘，相同磁盘的随机 I/O 都要比连续 I/O 慢很多\n对机械磁盘来说，我们刚刚提到过的，由于随机 I/O 需要更多的磁头寻道和盘片旋转，它的性能自然要比连续 I/O 慢。 而对固态磁盘来说，虽然它的随机性能比机械硬盘好很多，但同样存在“先擦除再写入”的限制。随机读写会导致大量的垃圾回收，所以相对应的，随机 I/O 的性能比起连续 I/O 来，也还是差了很多。 机械磁盘的最小读写单位是扇区，一般大小为 512 字节。 而固态磁盘的最小读写单位是页，通常大小是 4KB、8KB 等。 磁盘按照接口来分类\nIDE（Integrated Drive Electronics） SCSI（Small Computer System Interface） SAS（Serial Attached SCSI） SATA（Serial ATA） FC（Fibre Channel） 不同的接口，往往分配不同的设备名称 磁盘整列：是把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列，也就是 RAID（Redundant Array of Independent Disks），从而可以提高数据访问的性能，并且增强数据存储的可靠性。\n根据容量、性能和可靠性需求的不同，RAID 一般可以划分为多个级别，如 RAID0、RAID1、RAID5、RAID10 等。\nRAID0 有最优的读写性能，但不提供数据冗余的功能。 而其他级别的 RAID，在提供数据冗余的基础上，对读写性能也有一定程度的优化。 【磁盘实际上是作为一个块设备来管理的】\n通用块层 通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层。它主要有两个功能 。\n第一个功能跟虚拟文件系统的功能类似。向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序。 第二个功能，通用块层还会给文件系统和应用程序发来的 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。 Linux 内核支持四种 I/O 调度算法，分别是 NONE、NOOP、CFQ 以及 DeadLine。\n第一种 NONE ，更确切来说，并不能算 I/O 调度算法。因为它完全不使用任何 I/O 调度器，对文件系统和应用程序的 I/O 其实不做任何处理，常用在虚拟机中（此时磁盘 I/O 调度完全由物理机负责）。\n第二种 NOOP ，是最简单的一种 I/O 调度算法。它实际上是一个先入先出的队列，只做一些最基本的请求合并，常用于 SSD 磁盘。\n第三种 CFQ（Completely Fair Scheduler），也被称为完全公平调度器，是现在很多发行版的默认 I/O 调度器，它为每个进程维护了一个 I/O 调度队列，并按照时间片来均匀分布每个进程的 I/O 请求。\n最后一种 DeadLine 调度算法，分别为读、写请求创建了不同的 I/O 队列，可以提高机械磁盘的吞吐量，并确保达到最终期限（deadline）的请求被优先处理。DeadLine 调度算法，多用在 I/O 压力比较重的场景，比如数据库等。\nI/O 栈 把 Linux 存储系统的 I/O 栈，由上到下分为三个层次，分别是文件系统层、通用块层和设备层。\n文件系统层，包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过通用块层，来存储和管理磁盘数据。 通用块层，包括块设备 I/O 队列和 I/O 调度器。它会对文件系统的 I/O 请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层。 设备层，包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作。 存储系统的 I/O ，通常是整个系统中最慢的一环。所以， Linux 通过多种缓存机制来优化 I/O 效率。\n","description":"磁盘 磁盘是可以持久化存储的设备，根据存储介质的不同，常见磁盘可以分为两类：机械磁盘和固态磁盘。\n第一类，机械磁盘，也称为硬盘驱动器（Hard Disk Driver），通常缩写为 HDD。机械磁盘主要由盘片和读写磁头组成，数据就存储在盘片的环状磁道中。在读写数据前，需要移动读写磁头，定位到数据所在的磁道，然后才能访问数据。 第二类，固态磁盘（Solid State Disk），通常缩写为 SSD，由固态电子元器件组成。固态磁盘不需要磁道寻址，所以，不管是连续 I/O，还是随机 I/O 的性能，都比机械磁盘要好得多。 无论机械磁盘，还是固态磁盘，相同磁盘的随机 I/O 都要比连续 I/O 慢很多"},{"id":34,"href":"/post/25%E5%9F%BA%E7%A1%80%E7%AF%87Linux%E7%A3%81%E7%9B%98IO%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%E4%B8%8B/","title":"25|基础篇--Linux磁盘I/O是怎么工作的（下）","parent":"Linux性能优化","content":" 磁盘性能指标 使用率、饱和度、IOPS、吞吐量以及响应时间等。这五个指标，是衡量磁盘性能的基本指标。\n使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈。 饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求。 IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。 吞吐量，是指每秒的 I/O 请求大小。 响应时间，是指 I/O 请求从发出到收到响应的间隔时间。 性能测试工具 fio 磁盘 I/O 观测 iostat 是最常用的磁盘 I/O 性能观测工具，它提供了每个磁盘的使用率、IOPS、吞吐量等各种常见的性能指标，这些指标实际上来自 /proc/diskstats。\n关注项：\n%util ，就是我们前面提到的磁盘 I/O 使用率； r/s+ w/s ，就是 IOPS； rkB/s+wkB/s ，就是吞吐量； r_await+w_await ，就是响应时间。 进程 I/O 观测 要观察进程的 I/O 情况，你还可以使用 pidstat 和 iotop 这两个工具。\n","description":"磁盘性能指标 使用率、饱和度、IOPS、吞吐量以及响应时间等。这五个指标，是衡量磁盘性能的基本指标。\n使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈。 饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求。 IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。 吞吐量，是指每秒的 I/O 请求大小。 响应时间，是指 I/O 请求从发出到收到响应的间隔时间。 性能测试工具 fio 磁盘 I/O 观测 iostat 是最常用的磁盘 I/O 性能观测工具，它提供了每个磁盘的使用率、IOPS、吞吐量等各种常见的性能指标，这些指标实际上来自 /proc/diskstats。"},{"id":35,"href":"/post/26%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E6%89%BE%E5%87%BA%E7%8B%82%E6%89%93%E6%97%A5%E5%BF%97%E7%9A%84%E5%86%85%E9%AC%BC/","title":"26|案例篇--如何找出狂打日志的“内鬼”？","parent":"Linux性能优化","content":" 文件系统、通用块层以及设备层，就构成了 Linux 的存储 I/O 栈。\n为了优化文件访问的性能，采用页缓存、索引节点缓存、目录项缓存等多种缓存机制，减少对下层块设备的直接调用。\n同样的，为了优化块设备的访问效率，使用缓冲区来缓存块设备的数据。\n$ strace -p 18940 strace: Process 18940 attached ... mmap(NULL, 314576896, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f0f7aee9000 mmap(NULL, 314576896, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f0f682e8000 write(3, \u0026#34;2018-12-05 15:23:01,709 - __main\u0026#34;..., 314572844 ) = 314572844 munmap(0x7f0f682e8000, 314576896) = 0 write(3, \u0026#34;\\n\u0026#34;, 1) = 1 munmap(0x7f0f7aee9000, 314576896) = 0 close(3) = 0 stat(\u0026#34;/tmp/logtest.txt.1\u0026#34;, {st_mode=S_IFREG|0644, st_size=943718535, ...}) = 0 $ lsof -p 18940 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME python 18940 root cwd DIR 0,50 4096 1549389 / python 18940 root rtd DIR 0,50 4096 1549389 / … python 18940 root 2u CHR 136,0 0t0 3 /dev/pts/0 python 18940 root 3w REG 8,1 117944320 303 /tmp/logtest.txt 日志，是了解应用程序内部运行情况，最常用、也最有效的工具。无论是操作系统，还是应用程序，都会记录大量的运行日志，以便事后查看历史记录。这些日志一般按照不同级别来开启，比如，开发环境通常打开调试级别的日志，而线上环境则只记录警告和错误日志。\n今后，在碰到这种“狂打日志”的场景时，你可以用 iostat、strace、lsof 等工具来定位狂打日志的进程，找出相应的日志文件，再通过应用程序的接口，调整日志级别来解决问题。\n","description":"文件系统、通用块层以及设备层，就构成了 Linux 的存储 I/O 栈。\n为了优化文件访问的性能，采用页缓存、索引节点缓存、目录项缓存等多种缓存机制，减少对下层块设备的直接调用。\n同样的，为了优化块设备的访问效率，使用缓冲区来缓存块设备的数据。\n$ strace -p 18940 strace: Process 18940 attached ."},{"id":36,"href":"/post/27%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E7%9A%84%E7%A3%81%E7%9B%98IO%E5%BB%B6%E8%BF%9F%E5%BE%88%E9%AB%98/","title":"27|案例篇--为什么我的磁盘I/O延迟很高？","parent":"Linux性能优化","content":" 用 iostat ，确认是否有 I/O 性能瓶颈。再用 strace 和 lsof ，来定位应用程序以及它正在写入的日志文件路径。最后通过应用程序的接口调整日志级别，完美解决 I/O 问题。 $ top top - 14:27:02 up 10:30, 1 user, load average: 1.82, 1.26, 0.76 Tasks: 129 total, 1 running, 74 sleeping, 0 stopped, 0 zombie %Cpu0 : 3.5 us, 2.1 sy, 0.0 ni, 0.0 id, 94.4 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu1 : 2.4 us, 0.7 sy, 0.0 ni, 70.4 id, 26.5 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 8169300 total, 3323248 free, 436748 used, 4409304 buff/cache KiB Swap: 0 total, 0 free, 0 used. 7412556 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 12280 root 20 0 103304 28824 7276 S 14.0 0.4 0:08.77 python 16 root 20 0 0 0 0 S 0.3 0.0 0:09.22 ksoftirqd/1 1549 root 20 0 236712 24480 9864 S 0.3 0.3 3:31.38 python3 运行下面的 iostat 命令，其中:\n-d 选项是指显示出 I/O 的性能指标； -x 选项是指显示出扩展统计信息（即显示所有 I/O 指标） $ iostat -d -x 1 Device r/s w/s rkB/s wkB/s rrqm/s wrqm/s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %util loop0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 sda 0.00 71.00 0.00 32912.00 0.00 0.00 0.00 0.00 0.00 18118.31 241.89 0.00 463.55 13.86 98.40 运行下面的 pidstat 命令，观察进程的 I/O 情况：\n$ pidstat -d 1 14:39:14 UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 14:39:15 0 12280 0.00 335716.00 0.00 0 python 先用 strace 确认它是不是在写文件，再用 lsof 找出文件描述符对应的文件即可。\n$ strace -p 12280 strace: Process 12280 attached select(0, NULL, NULL, NULL, {tv_sec=0, tv_usec=567708}) = 0 (Timeout) stat(\u0026#34;/usr/local/lib/python3.7/importlib/_bootstrap.py\u0026#34;, {st_mode=S_IFREG|0644, st_size=39278, ...}) = 0 stat(\u0026#34;/usr/local/lib/python3.7/importlib/_bootstrap.py\u0026#34;, {st_mode=S_IFREG|0644, st_size=39278, ...}) = 0 借助动态追踪工具包 bcc 中的 filetop 和 opensnoop\n","description":"用 iostat ，确认是否有 I/O 性能瓶颈。再用 strace 和 lsof ，来定位应用程序以及它正在写入的日志文件路径。最后通过应用程序的接口调整日志级别，完美解决 I/O 问题。 $ top top - 14:27:02 up 10:30, 1 user, load average: 1."},{"id":37,"href":"/post/28%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%80%E4%B8%AASQL%E6%9F%A5%E8%AF%A2%E8%A6%8115%E7%A7%92%E8%BF%99%E6%98%AF%E6%80%8E%E4%B9%88%E5%9B%9E%E4%BA%8B/","title":"28|案例篇--一个SQL查询要15秒，这是怎么回事？","parent":"Linux性能优化","content":"运行下面的 docker exec 命令，进入 MySQL 的命令行界面：\n$ docker exec -i -t mysql mysql ... ​ Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. ​ mysql\u0026gt; 今天我们分析了一个商品搜索的应用程序。我们先是通过 top、iostat 分析了系统的 CPU 和磁盘使用情况，发现了磁盘的 I/O 瓶颈。接着，我们借助 pidstat ，发现瓶颈是 mysqld 导致的。 紧接着，我们又通过 strace、lsof，找出了 mysqld 正在读的文件。同时，根据文件的名字和路径，我们找出了 mysqld 正在操作的数据库和数据表。综合这些信息，我们判断，这是一个没有利用索引导致的慢查询问题。 于是，我们登录到 MySQL 命令行终端，用数据库分析工具进行验证，发现 MySQL 查询语句访问的字段，果然没有索引。所以，增加索引，就可以解决案例的性能问题了。\n","description":"运行下面的 docker exec 命令，进入 MySQL 的命令行界面：\n$ docker exec -i -t mysql mysql ."},{"id":38,"href":"/post/29%E6%A1%88%E4%BE%8B%E7%AF%87Redis%E5%93%8D%E5%BA%94%E4%B8%A5%E9%87%8D%E5%BB%B6%E8%BF%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/","title":"29|案例篇--Redis响应严重延迟，如何解决？","parent":"Linux性能优化","content":" # -f表示跟踪子进程和子线程，-T表示显示系统调用的时长，-tt表示显示跟踪时间 $ strace -f -T -tt -p 9085 [pid 9085] 14:20:16.826131 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 65, NULL, 8) = 1 \u0026lt;0.000055\u0026gt; [pid 9085] 14:20:16.826301 read(8, \u0026#34;*2\\r\\n$3\\r\\nGET\\r\\n$41\\r\\nuuid:5b2e76cc-\u0026#34;..., 16384) = 61 \u0026lt;0.000071\u0026gt; [pid 9085] 14:20:16.826477 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) \u0026lt;0.000063\u0026gt; [pid 9085] 14:20:16.826645 write(8, \u0026#34;$3\\r\\nbad\\r\\n\u0026#34;, 9) = 9 \u0026lt;0.000173\u0026gt; [pid 9085] 14:20:16.826907 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 65, NULL, 8) = 1 \u0026lt;0.000032\u0026gt; [pid 9085] 14:20:16.827030 read(8, \u0026#34;*2\\r\\n$3\\r\\nGET\\r\\n$41\\r\\nuuid:55862ada-\u0026#34;..., 16384) = 61 \u0026lt;0.000044\u0026gt; [pid 9085] 14:20:16.827149 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) \u0026lt;0.000043\u0026gt; [pid 9085] 14:20:16.827285 write(8, \u0026#34;$3\\r\\nbad\\r\\n\u0026#34;, 9) = 9 \u0026lt;0.000141\u0026gt; [pid 9085] 14:20:16.827514 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 64, NULL, 8) = 1 \u0026lt;0.000049\u0026gt; [pid 9085] 14:20:16.827641 read(8, \u0026#34;*2\\r\\n$3\\r\\nGET\\r\\n$41\\r\\nuuid:53522908-\u0026#34;..., 16384) = 61 \u0026lt;0.000043\u0026gt; [pid 9085] 14:20:16.827784 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) \u0026lt;0.000034\u0026gt; [pid 9085] 14:20:16.827945 write(8, \u0026#34;$4\\r\\ngood\\r\\n\u0026#34;, 10) = 10 \u0026lt;0.000288\u0026gt; [pid 9085] 14:20:16.828339 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 63, NULL, 8) = 1 \u0026lt;0.000057\u0026gt; [pid 9085] 14:20:16.828486 read(8, \u0026#34;*3\\r\\n$4\\r\\nSADD\\r\\n$4\\r\\ngood\\r\\n$36\\r\\n535\u0026#34;..., 16384) = 67 \u0026lt;0.000040\u0026gt; [pid 9085] 14:20:16.828623 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) \u0026lt;0.000052\u0026gt; [pid 9085] 14:20:16.828760 write(7, \u0026#34;*3\\r\\n$4\\r\\nSADD\\r\\n$4\\r\\ngood\\r\\n$36\\r\\n535\u0026#34;..., 67) = 67 \u0026lt;0.000060\u0026gt; [pid 9085] 14:20:16.828970 fdatasync(7) = 0 \u0026lt;0.005415\u0026gt; [pid 9085] 14:20:16.834493 write(8, \u0026#34;:1\\r\\n\u0026#34;, 4) = 4 \u0026lt;0.000250\u0026gt; 事实上，从系统调用来看， epoll_pwait、read、write、fdatasync 这些系统调用都比较频繁。那么，刚才观察到的写磁盘，应该就是 write 或者 fdatasync 导致的了。\n$ lsof -p 9085 redis-ser 9085 systemd-network 3r FIFO 0,12 0t0 15447970 pipe redis-ser 9085 systemd-network 4w FIFO 0,12 0t0 15447970 pipe redis-ser 9085 systemd-network 5u a_inode 0,13 0 10179 [eventpoll] redis-ser 9085 systemd-network 6u sock 0,9 0t0 15447972 protocol: TCP redis-ser 9085 systemd-network 7w REG 8,1 8830146 2838532 /data/appendonly.aof redis-ser 9085 systemd-network 8u sock 0,9 0t0 15448709 protocol: TCP Redis 提供了两种数据持久化的方式，分别是快照和追加文件。\n快照方式，会按照指定的时间间隔，生成数据的快照，并且保存到磁盘文件中。为了避免阻塞主进程，Redis 还会 fork 出一个子进程，来负责快照的保存。这种方式的性能好，无论是备份还是恢复，都比追加文件好很多。 追加文件，则是用在文件末尾追加记录的方式，对 Redis 写入的数据，依次进行持久化，所以它的持久化也更安全。 此外，它还提供了一个用 appendfsync 选项设置 fsync 的策略，确保写入的数据都落到磁盘中，具体选项包括 always、everysec、no 等。\nalways 表示，每个操作都会执行一次 fsync，是最为安全的方式； everysec 表示，每秒钟调用一次 fsync ，这样可以保证即使是最坏情况下，也只丢失 1 秒的数据； 而 no 表示交给操作系统来处理。 ","description":"# -f表示跟踪子进程和子线程，-T表示显示系统调用的时长，-tt表示显示跟踪时间 $ strace -f -T -tt -p 9085 [pid 9085] 14:20:16."},{"id":39,"href":"/docker/","title":"容器","parent":"首页","content":" Docker 安装 ClickHouse Docker 安装 etcd Docker 安装 Hive Docker 安装 MongoDB Docker 安装 MySQL Docker 安装 Redis PostgreSQL数据库——Docker版本的postgres安装 ","description":" Docker 安装 ClickHouse Docker 安装 etcd Docker 安装 Hive Docker 安装 MongoDB Docker 安装 MySQL Docker 安装 Redis PostgreSQL数据库——Docker版本的postgres安装 "},{"id":40,"href":"/post/30%E5%A5%97%E8%B7%AF%E7%AF%87%E5%A6%82%E4%BD%95%E8%BF%85%E9%80%9F%E5%88%86%E6%9E%90%E5%87%BA%E7%B3%BB%E7%BB%9FIO%E7%9A%84%E7%93%B6%E9%A2%88%E5%9C%A8%E5%93%AA%E9%87%8C/","title":"30|套路篇--如何迅速分析出系统I/O的瓶颈在哪里？","parent":"Linux性能优化","content":" 性能指标 文件系统 I/O 性能指标 首先，最容易想到的是存储空间的使用情况，包括容量、使用量以及剩余空间等。我们通常也称这些为磁盘空间的使用量，因为文件系统的数据最终还是存储在磁盘上。 容易忽略的是索引节点的使用情况，它也包括容量、使用量以及剩余量等三个指标。如果文件系统中存储过多的小文件，就可能碰到索引节点容量已满的问题。 其次，你应该想到的是前面多次提到过的缓存使用情况，包括页缓存、目录项缓存、索引节点缓存以及各个具体文件系统（如 ext4、XFS 等）的缓存。这些缓存会使用速度更快的内存，用来临时存储文件数据或者文件系统的元数据，从而可以减少访问慢速磁盘的次数。 磁盘 I/O 性能指标 使用率，是指磁盘忙处理 I/O 请求的百分比。过高的使用率（比如超过 60%）通常意味着磁盘 I/O 存在性能瓶颈。 IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。 吞吐量，是指每秒的 I/O 请求大小。 响应时间，是指从发出 I/O 请求到收到响应的间隔时间。 性能工具 第一，在文件系统的原理中，我介绍了查看文件系统容量的工具 df。它既可以查看文件系统数据的空间容量，也可以查看索引节点的容量。至于文件系统缓存，我们通过 /proc/meminfo、/proc/slabinfo 以及 slabtop 等各种来源，观察页缓存、目录项缓存、索引节点缓存以及具体文件系统的缓存情况。 第二，在磁盘 I/O 的原理中，我们分别用 iostat 和 pidstat 观察了磁盘和进程的 I/O 情况。它们都是最常用的 I/O 性能分析工具。通过 iostat ，我们可以得到磁盘的 I/O 使用率、吞吐量、响应时间以及 IOPS 等性能指标；而通过 pidstat ，则可以观察到进程的 I/O 吞吐量以及块设备 I/O 的延迟等。 第三，在狂打日志的案例中，我们先用 top 查看系统的 CPU 使用情况，发现 iowait 比较高；然后，又用 iostat 发现了磁盘的 I/O 使用率瓶颈，并用 pidstat 找出了大量 I/O 的进程；最后，通过 strace 和 lsof，我们找出了问题进程正在读写的文件，并最终锁定性能问题的来源——原来是进程在狂打日志。 第四，在磁盘 I/O 延迟的单词热度案例中，我们同样先用 top、iostat ，发现磁盘有 I/O 瓶颈，并用 pidstat 找出了大量 I/O 的进程。可接下来，想要照搬上次操作的我们失败了。在随后的 strace 命令中，我们居然没看到 write 系统调用。于是，我们换了一个思路，用新工具 filetop 和 opensnoop ，从内核中跟踪系统调用，最终找出瓶颈的来源。 最后，在 MySQL 和 Redis 的案例中，同样的思路，我们先用 top、iostat 以及 pidstat ，确定并找出 I/O 性能问题的瓶颈来源，它们正是 mysqld 和 redis-server。随后，我们又用 strace+lsof 找出了它们正在读写的文件。 性能指标和工具的联系 从 I/O 指标出发，你更容易把性能工具同系统工作原理关联起来，对性能问题有宏观的认识和把握。 而从性能工具出发，可以让你更快上手使用工具，迅速找出我们想观察的性能指标。特别是在工具有限的情况下，我们更要充分利用好手头的每一个工具，少量工具也要尽力挖掘出大量信息。 第一个维度，从文件系统和磁盘 I/O 的性能指标出发。换句话说，当你想查看某个性能指标时，要清楚知道，哪些工具可以做到。 第二个维度，从工具出发。也就是当你已经安装了某个工具后，要知道这个工具能提供哪些指标。 如何迅速分析 I/O 的性能瓶颈 想弄清楚性能指标的关联性，就要通晓每种性能指标的工作原理。\n先用 iostat 发现磁盘 I/O 性能瓶颈； 再借助 pidstat ，定位出导致瓶颈的进程； 随后分析进程的 I/O 行为； 最后，结合应用程序的原理，分析这些 I/O 的来源。 为了缩小排查范围，我通常会先运行那几个支持指标较多的工具，如 iostat、vmstat、pidstat 等。 ","description":"性能指标 文件系统 I/O 性能指标 首先，最容易想到的是存储空间的使用情况，包括容量、使用量以及剩余空间等。我们通常也称这些为磁盘空间的使用量，因为文件系统的数据最终还是存储在磁盘上。 容易忽略的是索引节点的使用情况，它也包括容量、使用量以及剩余量等三个指标。如果文件系统中存储过多的小文件，就可能碰到索引节点容量已满的问题。 其次，你应该想到的是前面多次提到过的缓存使用情况，包括页缓存、目录项缓存、索引节点缓存以及各个具体文件系统（如 ext4、XFS 等）的缓存。这些缓存会使用速度更快的内存，用来临时存储文件数据或者文件系统的元数据，从而可以减少访问慢速磁盘的次数。 磁盘 I/O 性能指标 使用率，是指磁盘忙处理 I/O 请求的百分比。过高的使用率（比如超过 60%）通常意味着磁盘 I/O 存在性能瓶颈。 IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。 吞吐量，是指每秒的 I/O 请求大小。 响应时间，是指从发出 I/O 请求到收到响应的间隔时间。 性能工具 第一，在文件系统的原理中，我介绍了查看文件系统容量的工具 df。它既可以查看文件系统数据的空间容量，也可以查看索引节点的容量。至于文件系统缓存，我们通过 /proc/meminfo、/proc/slabinfo 以及 slabtop 等各种来源，观察页缓存、目录项缓存、索引节点缓存以及具体文件系统的缓存情况。 第二，在磁盘 I/O 的原理中，我们分别用 iostat 和 pidstat 观察了磁盘和进程的 I/O 情况。它们都是最常用的 I/O 性能分析工具。通过 iostat ，我们可以得到磁盘的 I/O 使用率、吞吐量、响应时间以及 IOPS 等性能指标；而通过 pidstat ，则可以观察到进程的 I/O 吞吐量以及块设备 I/O 的延迟等。 第三，在狂打日志的案例中，我们先用 top 查看系统的 CPU 使用情况，发现 iowait 比较高；然后，又用 iostat 发现了磁盘的 I/O 使用率瓶颈，并用 pidstat 找出了大量 I/O 的进程；最后，通过 strace 和 lsof，我们找出了问题进程正在读写的文件，并最终锁定性能问题的来源——原来是进程在狂打日志。 第四，在磁盘 I/O 延迟的单词热度案例中，我们同样先用 top、iostat ，发现磁盘有 I/O 瓶颈，并用 pidstat 找出了大量 I/O 的进程。可接下来，想要照搬上次操作的我们失败了。在随后的 strace 命令中，我们居然没看到 write 系统调用。于是，我们换了一个思路，用新工具 filetop 和 opensnoop ，从内核中跟踪系统调用，最终找出瓶颈的来源。 最后，在 MySQL 和 Redis 的案例中，同样的思路，我们先用 top、iostat 以及 pidstat ，确定并找出 I/O 性能问题的瓶颈来源，它们正是 mysqld 和 redis-server。随后，我们又用 strace+lsof 找出了它们正在读写的文件。 性能指标和工具的联系 从 I/O 指标出发，你更容易把性能工具同系统工作原理关联起来，对性能问题有宏观的认识和把握。 而从性能工具出发，可以让你更快上手使用工具，迅速找出我们想观察的性能指标。特别是在工具有限的情况下，我们更要充分利用好手头的每一个工具，少量工具也要尽力挖掘出大量信息。 第一个维度，从文件系统和磁盘 I/O 的性能指标出发。换句话说，当你想查看某个性能指标时，要清楚知道，哪些工具可以做到。 第二个维度，从工具出发。也就是当你已经安装了某个工具后，要知道这个工具能提供哪些指标。 如何迅速分析 I/O 的性能瓶颈 想弄清楚性能指标的关联性，就要通晓每种性能指标的工作原理。"},{"id":41,"href":"/post/31%E5%A5%97%E8%B7%AF%E7%AF%87%E7%A3%81%E7%9B%98IO%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF/","title":"31|套路篇--磁盘I/O性能优化的几个思路","parent":"Linux性能优化","content":" I/O 基准测试 I/O 性能优化 应用程序优化 第一，可以用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。 第二，可以借助缓存 I/O ，充分利用系统缓存，降低实际 I/O 的次数。 第三，可以在应用程序内部构建自己的缓存，或者用 Redis 这类外部缓存系统。这样，一方面，能在应用程序内部，控制缓存的数据和生命周期；另一方面，也能降低其他应用程序使用缓存对自身的影响。 第四，在需要频繁读写同一块磁盘空间时，可以用 mmap 代替 read/write，减少内存的拷贝次数。 第五，在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC。 第六，在多个应用程序共享相同磁盘时，为了保证 I/O 不被某个应用完全占用，推荐你使用 cgroups 的 I/O 子系统，来限制进程 / 进程组的 IOPS 以及吞吐量。 最后，在使用 CFQ 调度器时，可以用 ionice 来调整进程的 I/O 调度优先级，特别是提高核心应用的 I/O 优先级。ionice 支持三个优先级类：Idle、Best-effort 和 Realtime。其中， Best-effort 和 Realtime 还分别支持 0-7 的级别，数值越小，则表示优先级别越高。 文件系统优化 第一，你可以根据实际负载场景的不同，选择最适合的文件系统。比如 Ubuntu 默认使用 ext4 文件系统，而 CentOS 7 默认使用 xfs 文件系统。 第二，在选好文件系统后，还可以进一步优化文件系统的配置选项，包括文件系统的特性（如 ext_attr、dir_index）、日志模式（如 journal、ordered、writeback）、挂载选项（如 noatime）等等。 第三，可以优化文件系统的缓存。 最后，在不需要持久化时，你还可以用内存文件系统 tmpfs，以获得更好的 I/O 性能 。tmpfs 把数据直接保存在内存中，而不是磁盘中。比如 /dev/shm/ ，就是大多数 Linux 默认配置的一个内存文件系统，它的大小默认为总内存的一半。 磁盘优化 第一，最简单有效的优化方法，就是换用性能更好的磁盘，比如用 SSD 替代 HDD。 第二，我们可以使用 RAID ，把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列。这样做既可以提高数据的可靠性，又可以提升数据的访问性能。 第三，针对磁盘和应用程序 I/O 模式的特征，我们可以选择最适合的 I/O 调度算法。比方说，SSD 和虚拟机中的磁盘，通常用的是 noop 调度算法。而数据库应用，我更推荐使用 deadline 算法。 第四，我们可以对应用程序的数据，进行磁盘级别的隔离。比如，我们可以为日志、数据库等 I/O 压力比较重的应用，配置单独的磁盘。 第五，在顺序读比较多的场景中，我们可以增大磁盘的预读数据，比如，你可以通过下面两种方法，调整 /dev/sdb 的预读大小。 第六，我们可以优化内核块设备 I/O 的选项。比如，可以调整磁盘队列的长度 /sys/block/sdb/queue/nr_requests，适当增大队列长度，可以提升磁盘的吞吐量（当然也会导致 I/O 延迟增大）。 ","description":" I/O 基准测试 I/O 性能优化 应用程序优化 第一，可以用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。 第二，可以借助缓存 I/O ，充分利用系统缓存，降低实际 I/O 的次数。 第三，可以在应用程序内部构建自己的缓存，或者用 Redis 这类外部缓存系统。这样，一方面，能在应用程序内部，控制缓存的数据和生命周期；另一方面，也能降低其他应用程序使用缓存对自身的影响。 第四，在需要频繁读写同一块磁盘空间时，可以用 mmap 代替 read/write，减少内存的拷贝次数。 第五，在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC。 第六，在多个应用程序共享相同磁盘时，为了保证 I/O 不被某个应用完全占用，推荐你使用 cgroups 的 I/O 子系统，来限制进程 / 进程组的 IOPS 以及吞吐量。 最后，在使用 CFQ 调度器时，可以用 ionice 来调整进程的 I/O 调度优先级，特别是提高核心应用的 I/O 优先级。ionice 支持三个优先级类：Idle、Best-effort 和 Realtime。其中， Best-effort 和 Realtime 还分别支持 0-7 的级别，数值越小，则表示优先级别越高。 文件系统优化 第一，你可以根据实际负载场景的不同，选择最适合的文件系统。比如 Ubuntu 默认使用 ext4 文件系统，而 CentOS 7 默认使用 xfs 文件系统。 第二，在选好文件系统后，还可以进一步优化文件系统的配置选项，包括文件系统的特性（如 ext_attr、dir_index）、日志模式（如 journal、ordered、writeback）、挂载选项（如 noatime）等等。 第三，可以优化文件系统的缓存。 最后，在不需要持久化时，你还可以用内存文件系统 tmpfs，以获得更好的 I/O 性能 。tmpfs 把数据直接保存在内存中，而不是磁盘中。比如 /dev/shm/ ，就是大多数 Linux 默认配置的一个内存文件系统，它的大小默认为总内存的一半。 磁盘优化 第一，最简单有效的优化方法，就是换用性能更好的磁盘，比如用 SSD 替代 HDD。 第二，我们可以使用 RAID ，把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列。这样做既可以提高数据的可靠性，又可以提升数据的访问性能。 第三，针对磁盘和应用程序 I/O 模式的特征，我们可以选择最适合的 I/O 调度算法。比方说，SSD 和虚拟机中的磁盘，通常用的是 noop 调度算法。而数据库应用，我更推荐使用 deadline 算法。 第四，我们可以对应用程序的数据，进行磁盘级别的隔离。比如，我们可以为日志、数据库等 I/O 压力比较重的应用，配置单独的磁盘。 第五，在顺序读比较多的场景中，我们可以增大磁盘的预读数据，比如，你可以通过下面两种方法，调整 /dev/sdb 的预读大小。 第六，我们可以优化内核块设备 I/O 的选项。比如，可以调整磁盘队列的长度 /sys/block/sdb/queue/nr_requests，适当增大队列长度，可以提升磁盘的吞吐量（当然也会导致 I/O 延迟增大）。 "},{"id":42,"href":"/post/32%E7%AD%94%E7%96%91%E5%9B%9B%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E-IO-%E4%B8%8E%E5%90%8C%E6%AD%A5%E5%BC%82%E6%AD%A5-IO-%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB/","title":"32|答疑（四）--阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系","parent":"Linux性能优化","content":" 问题 1：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系 所谓阻塞 I/O，是指应用程序在执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程，不能执行其他任务。 所谓非阻塞 I/O，是指应用程序在执行 I/O 操作后，不会阻塞当前的线程，可以继续执行其他的任务。 所谓同步 I/O，是指收到 I/O 请求后，系统不会立刻响应应用程序；等到处理完成，系统才会通过系统调用的方式，告诉应用程序 I/O 结果。 所谓异步 I/O，是指收到 I/O 请求后，系统会先告诉应用程序 I/O 请求已经收到，随后再去异步处理；等处理完成后，系统再通过事件通知的方式，告诉应用程序结果。 在 Linux I/O 调用中，\n系统调用 read 是同步读，所以，在没有得到磁盘数据前，read 不会响应应用程序。 而 aio_read 是异步读，系统收到 AIO 读请求后不等处理就返回了，而具体的 read 结果，再通过回调异步通知应用程序。 在网络套接字的接口中，\n使用 send() 直接向套接字发送数据时，如果套接字没有设置 O_NONBLOCK 标识，那么 send() 操作就会一直阻塞，当前线程也没法去做其他事情。 当然，如果你用了 epoll，系统会告诉你这个套接字的状态，那就可以用非阻塞的方式使用。当这个套接字不可写的时候，你可以去做其他事情，比如读写其他套接字。 问题 2：“文件系统”课后思考 问题 3：“磁盘 I/O 延迟”课后思考 问题 4：“MySQL 案例”课后思考 为什么 DataService 应用停止后，即使仍没有索引，MySQL 的查询速度还是快了很多，并且磁盘 I/O 瓶颈也消失了呢？ 事实上，当你看到 DataService 在修改 /proc/sys/vm/drop_caches 时，就应该想到前面学过的 Cache 的作用。 我们知道，案例应用访问的数据表，基于 MyISAM 引擎，而 MyISAM 的一个特点，就是只在内存中缓存索引，并不缓存数据。所以，在查询语句无法使用索引时，就需要数据表从数据库文件读入内存，然后再进行处理。\n","description":"问题 1：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系 所谓阻塞 I/O，是指应用程序在执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程，不能执行其他任务。 所谓非阻塞 I/O，是指应用程序在执行 I/O 操作后，不会阻塞当前的线程，可以继续执行其他的任务。 所谓同步 I/O，是指收到 I/O 请求后，系统不会立刻响应应用程序；等到处理完成，系统才会通过系统调用的方式，告诉应用程序 I/O 结果。 所谓异步 I/O，是指收到 I/O 请求后，系统会先告诉应用程序 I/O 请求已经收到，随后再去异步处理；等处理完成后，系统再通过事件通知的方式，告诉应用程序结果。 在 Linux I/O 调用中，"},{"id":43,"href":"/post/33%E5%85%B3%E4%BA%8E-Linux-%E7%BD%91%E7%BB%9C%E4%BD%A0%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E8%BF%99%E4%BA%9B%E4%B8%8A/","title":"33|关于 Linux 网络，你必须知道这些（上）","parent":"Linux性能优化","content":" 网络模型 开放式系统互联通信参考模型（Open System Interconnection Reference Model），简称为 OSI 网络模型。\nOSI 模型把网络互联的框架分为应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层等七层，每个层负责不同的功能。其中，\n应用层，负责为应用程序提供统一的接口。 表示层，负责把数据转换成兼容接收系统的格式。 会话层，负责维护计算机之间的通信连接。 传输层，负责为数据加上传输表头，形成数据包。 网络层，负责数据的路由和转发。 数据链路层，负责 MAC 寻址、错误侦测和改错。 物理层，负责在物理网络中传输数据帧。 在 Linux 中，我们实际上使用的是另一个更实用的四层模型，即 TCP/IP 网络模型。\nTCP/IP 模型，把网络互联的框架分为应用层、传输层、网络层、网络接口层等四层，其中，\n应用层，负责向用户提供一组应用程序，比如 HTTP、FTP、DNS 等。 传输层，负责端到端的通信，比如 TCP、UDP 等。 网络层，负责网络包的封装、寻址和路由，比如 IP、ICMP 等。 网络接口层，负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。 Linux 网络栈 有了 TCP/IP 模型后，在进行网络传输时，数据包就会按照协议栈，对上一层发来的数据进行逐层处理；然后封装上该层的协议头，再发送给下一层。\n传输层在应用程序数据前面增加了 TCP 头； 网络层在 TCP 数据包前增加了 IP 头； 而网络接口层，又在 IP 数据包前后分别增加了帧头和帧尾。 这些新增的头部和尾部，增加了网络包的大小，但我们都知道，物理链路中并不能传输任意大小的数据包。网络接口配置的最大传输单元（MTU），就规定了最大的 IP 包大小。在我们最常用的以太网中，MTU 默认值是 1500（这也是 Linux 的默认值）。\n一旦网络包超过 MTU 的大小，就会在网络层分片，以保证分片后的 IP 包不大于 MTU 值。显然，MTU 越大，需要的分包也就越少，自然，网络吞吐能力就越好。\n理解了 TCP/IP 网络模型和网络包的封装原理后，你很容易能想到，Linux 内核中的网络栈，其实也类似于 TCP/IP 的四层结构。如下图所示，就是 Linux 通用 IP 网络栈的示意图：\n最上层的应用程序，需要通过系统调用，来跟套接字接口进行交互； 套接字的下面，就是我们前面提到的传输层、网络层和网络接口层； 最底层，则是网卡驱动程序以及物理网卡设备。 Linux 网络收发流程 网络包的接收流程 内核协议栈从缓冲区中取出网络帧，并通过网络协议栈，从下到上逐层处理这个网络帧。比如，\n在链路层检查报文的合法性，找出上层协议的类型（比如 IPv4 还是 IPv6），再去掉帧头、帧尾，然后交给网络层。 网络层取出 IP 头，判断网络包下一步的走向，比如是交给上层处理还是转发。当网络层确认这个包是要发送到本机后，就会取出上层协议的类型（比如 TCP 还是 UDP），去掉 IP 头，再交给传输层处理。 传输层取出 TCP 头或者 UDP 头后，根据 \u0026lt; 源 IP、源端口、目的 IP、目的端口 \u0026gt; 四元组作为标识，找出对应的 Socket，并把数据拷贝到 Socket 的接收缓存中。 最后，应用程序就可以使用 Socket 接口，读取到新接收到的数据了。 网络包的发送流程 首先，应用程序调用 Socket API（比如 sendmsg）发送网络包。由于这是一个系统调用，所以会陷入到内核态的套接字层中。\n套接字层会把数据包放到 Socket 发送缓冲区中。\n接下来，网络协议栈从 Socket 发送缓冲区中，取出数据包；再按照 TCP/IP 栈，从上到下逐层处理。比如，传输层和网络层，分别为其增加 TCP 头和 IP 头，执行路由查找确认下一跳的 IP，并按照 MTU 大小进行分片。\n分片后的网络包，再送到网络接口层，进行物理地址寻址，以找到下一跳的 MAC 地址。然后添加帧头和帧尾，放到发包队列中。\n这一切完成后，会有软中断通知驱动程序：发包队列中有新的网络帧需要发送。\n最后，驱动程序通过 DMA ，从发包队列中读出网络帧，并通过物理网卡把它发送出去。\n小结 TCP/IP 模型，把网络互联的框架，分为应用层、传输层、网络层、网络接口层等四层，这也是 Linux 网络栈最核心的构成部分。\n应用程序通过套接字接口发送数据包，先要在网络协议栈中从上到下进行逐层处理，最终再送到网卡发送出去。而接收时，同样先经过网络栈从下到上的逐层处理，最终才会送到应用程序。\n","description":"网络模型 开放式系统互联通信参考模型（Open System Interconnection Reference Model），简称为 OSI 网络模型。\nOSI 模型把网络互联的框架分为应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层等七层，每个层负责不同的功能。其中，"},{"id":44,"href":"/post/34%E5%85%B3%E4%BA%8E-Linux-%E7%BD%91%E7%BB%9C%E4%BD%A0%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E8%BF%99%E4%BA%9B%E4%B8%8B/","title":"34|关于 Linux 网络，你必须知道这些（下）","parent":"Linux性能优化","content":" 性能指标 通常用带宽、吞吐量、延时、PPS（Packet Per Second）等指标衡量网络的性能。\n带宽，表示链路的最大传输速率，单位通常为 b/s （比特 / 秒）。 吞吐量，表示单位时间内成功传输的数据量，单位通常为 b/s（比特 / 秒）或者 B/s（字节 / 秒）。吞吐量受带宽限制，而吞吐量 / 带宽，也就是该网络的使用率。 延时，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。在不同场景中，这一指标可能会有不同含义。比如，它可以表示，建立连接需要的时间（比如 TCP 握手延时），或一个数据包往返所需的时间（比如 RTT）。 PPS，是 Packet Per Second（包 / 秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力，比如硬件交换机，通常可以达到线性转发（即 PPS 可以达到或者接近理论最大值）。而基于 Linux 服务器的转发，则容易受网络包大小的影响。 除了这些指标，网络的可用性（网络能否正常通信）、并发连接数（TCP 连接数量）、丢包率（丢包百分比）、重传率（重新传输的网络包比例）等也是常用的性能指标。\n网络配置 ifconfig 和 ip 分别属于软件包 net-tools 和 iproute2，iproute2 是 net-tools 的下一代。通常情况下它们会在发行版中默认安装。但如果你找不到 ifconfig 或者 ip 命令，可以安装这两个软件包。 $ ifconfig en0 en0: flags=8823\u0026lt;UP,BROADCAST,SMART,SIMPLEX,MULTICAST\u0026gt; mtu 1500 options=400\u0026lt;CHANNEL_IO\u0026gt; ether 78:4f:43:68:02:c6 nd6 options=201\u0026lt;PERFORMNUD,DAD\u0026gt; media: autoselect (\u0026lt;unknown type\u0026gt;) status: inactive ip -s addr show dev eth0\nifconfig 和 ip 命令输出的指标基本相同，只是显示格式略微不同。比如，它们都包括了网络接口的状态标志、MTU 大小、IP、子网、MAC 地址以及网络包收发的统计信息。\n第一，网络接口的状态标志。ifconfig 输出中的 RUNNING ，或 ip 输出中的 LOWER_UP ，都表示物理网络是连通的，即网卡已经连接到了交换机或者路由器中。如果你看不到它们，通常表示网线被拔掉了。\n第二，MTU 的大小。MTU 默认大小是 1500，根据网络架构的不同（比如是否使用了 VXLAN 等叠加网络），你可能需要调大或者调小 MTU 的数值。\n第三，网络接口的 IP 地址、子网以及 MAC 地址。这些都是保障网络功能正常工作所必需的，你需要确保配置正确。\n第四，网络收发的字节数、包数、错误数以及丢包情况，特别是 TX 和 RX 部分的 errors、dropped、overruns、carrier 以及 collisions 等指标不为 0 时，通常表示出现了网络 I/O 问题。其中：\nerrors 表示发生错误的数据包数，比如校验错误、帧同步错误等； dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包； overruns 表示超限数据包数，即网络 I/O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包； carrier 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等； collisions 表示碰撞数据包数。 套接字信息 ifconfig 和 ip 只显示了网络接口收发数据包的统计信息，但在实际的性能问题中，网络协议栈中的统计信息，我们也必须关注。你可以用 netstat 或者 ss ，来查看套接字、网络栈、网络接口以及路由表的信息。\n# head -n 3 表示只显示前面3行 # -l 表示只显示监听套接字 # -n 表示显示数字地址和端口(而不是名字) # -p 表示显示进程信息 $ netstat -nlp | head -n 3 Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.53:53 0.0.0.0:* LISTEN 840/systemd-resolve # -l 表示只显示监听套接字 # -t 表示只显示 TCP 套接字 # -n 表示显示数字地址和端口(而不是名字) # -p 表示显示进程信息 $ ss -ltnp | head -n 3 State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.53%lo:53 0.0.0.0:* users:((\u0026#34;systemd-resolve\u0026#34;,pid=840,fd=13)) LISTEN 0 128 0.0.0.0:22 0.0.0.0:* users:((\u0026#34;sshd\u0026#34;,pid=1459,fd=3)) 其中，接收队列（Recv-Q）和发送队列（Send-Q）需要你特别关注，它们通常应该是 0。当你发现它们不是 0 时，说明有网络包的堆积发生。\n当然还要注意，在不同套接字状态下，它们的含义不同。当套接字处于连接状态（Established）时，\nRecv-Q 表示套接字缓冲还没有被应用程序取走的字节数（即接收队列长度）。 而 Send-Q 表示还没有被远端主机确认的字节数（即发送队列长度）。 当套接字处于监听状态（Listening）时，\nRecv-Q 表示全连接队列的长度。 而 Send-Q 表示全连接队列的最大长度。 所谓全连接，是指服务器收到了客户端的 ACK，完成了 TCP 三次握手，然后就会把这个连接挪到全连接队列中。这些全连接中的套接字，还需要被 accept() 系统调用取走，服务器才可以开始真正处理客户端的请求。\n与全连接队列相对应的，还有一个半连接队列。所谓半连接是指还没有完成 TCP 三次握手的连接，连接只进行了一半。服务器收到了客户端的 SYN 包后，就会把这个连接放到半连接队列中，然后再向客户端发送 SYN+ACK 包。\n协议栈统计信息 $ netstat -s ... Tcp: 3244906 active connection openings 23143 passive connection openings 115732 failed connection attempts 2964 connection resets received 1 connections established 13025010 segments received 17606946 segments sent out 44438 segments retransmitted 42 bad segments received 5315 resets sent InCsumErrors: 42 ... $ ss -s Total: 186 (kernel 1446) TCP: 4 (estab 1, closed 0, orphaned 0, synrecv 0, timewait 0/0), ports 0 Transport Total IP IPv6 * 1446 - - RAW 2 1 1 UDP 2 2 0 TCP 4 3 1 ... 这些协议栈的统计信息都很直观。ss 只显示已经连接、关闭、孤儿套接字等简要统计，而 netstat 则提供的是更详细的网络协议栈信息。\n网络吞吐和 PPS 给 sar 增加 -n 参数就可以查看网络的统计信息，比如网络接口（DEV）、网络接口错误（EDEV）、TCP、UDP、ICMP 等等。执行下面的命令，你就可以得到网络接口统计信息：\n# 数字1表示每隔1秒输出一组数据 $ sar -n DEV 1 Linux 4.15.0-1035-azure (ubuntu) 01/06/19 _x86_64_ (2 CPU) 13:21:40 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 13:21:41 eth0 18.00 20.00 5.79 4.25 0.00 0.00 0.00 0.00 13:21:41 docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 13:21:41 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 这儿输出的指标比较多，我来简单解释下它们的含义。\nrxpck/s 和 txpck/s 分别是接收和发送的 PPS，单位为包 / 秒。 rxkB/s 和 txkB/s 分别是接收和发送的吞吐量，单位是 KB/ 秒。 rxcmp/s 和 txcmp/s 分别是接收和发送的压缩数据包数，单位是包 / 秒。 %ifutil 是网络接口的使用率，即半双工模式下为 (rxkB/s+txkB/s)/Bandwidth，而全双工模式下为 max(rxkB/s, txkB/s)/Bandwidth。 其中，Bandwidth 可以用 ethtool 来查询，它的单位通常是 Gb/s 或者 Mb/s，不过注意这里小写字母 b ，表示比特而不是字节。我们通常提到的千兆网卡、万兆网卡等，单位也都是比特。\n连通性和延时 通常使用 ping ，来测试远程主机的连通性和延时，而这基于 ICMP 协议。比如，执行下面的命令，你就可以测试本机到 114.114.114.114 这个 IP 地址的连通性和延时：\n# -c3表示发送三次ICMP包后停止 $ ping -c3 114.114.114.114 PING 114.114.114.114 (114.114.114.114) 56(84) bytes of data. 64 bytes from 114.114.114.114: icmp_seq=1 ttl=54 time=244 ms 64 bytes from 114.114.114.114: icmp_seq=2 ttl=47 time=244 ms 64 bytes from 114.114.114.114: icmp_seq=3 ttl=67 time=244 ms --- 114.114.114.114 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2001ms rtt min/avg/max/mdev = 244.023/244.070/244.105/0.034 ms ping 的输出，可以分为两部分。\n第一部分，是每个 ICMP 请求的信息，包括 ICMP 序列号（icmp_seq）、TTL（生存时间，或者跳数）以及往返延时。 第二部分，则是三次 ICMP 请求的汇总。 小结 我们通常使用带宽、吞吐量、延时等指标，来衡量网络的性能；相应的，你可以用 ifconfig、netstat、ss、sar、ping 等工具，来查看这些网络的性能指标。\n","description":"性能指标 通常用带宽、吞吐量、延时、PPS（Packet Per Second）等指标衡量网络的性能。\n带宽，表示链路的最大传输速率，单位通常为 b/s （比特 / 秒）。 吞吐量，表示单位时间内成功传输的数据量，单位通常为 b/s（比特 / 秒）或者 B/s（字节 / 秒）。吞吐量受带宽限制，而吞吐量 / 带宽，也就是该网络的使用率。 延时，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。在不同场景中，这一指标可能会有不同含义。比如，它可以表示，建立连接需要的时间（比如 TCP 握手延时），或一个数据包往返所需的时间（比如 RTT）。 PPS，是 Packet Per Second（包 / 秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力，比如硬件交换机，通常可以达到线性转发（即 PPS 可以达到或者接近理论最大值）。而基于 Linux 服务器的转发，则容易受网络包大小的影响。 除了这些指标，网络的可用性（网络能否正常通信）、并发连接数（TCP 连接数量）、丢包率（丢包百分比）、重传率（重新传输的网络包比例）等也是常用的性能指标。"},{"id":45,"href":"/post/35%E5%9F%BA%E7%A1%80%E7%AF%87C10K-%E5%92%8C-C1000K-%E5%9B%9E%E9%A1%BE/","title":"35|基础篇：C10K 和 C1000K 回顾","parent":"Linux性能优化","content":"C10K 和 C1000K 的首字母 C 是 Client 的缩写。C10K 就是单机同时处理 1 万个请求（并发连接 1 万）的问题，而 C1000K 也就是单机支持处理 100 万个请求（并发连接 100 万）的问题。\nC10K 最早由 Dan Kegel 在 1999 年提出。那时的服务器还只是 32 位系统，运行着 Linux 2.2 版本（后来又升级到了 2.4 和 2.6，而 2.6 才支持 x86_64），只配置了很少的内存（2GB）和千兆网卡。\n怎么在这样的系统中支持并发 1 万的请求呢？\n从资源上来说，对 2GB 内存和千兆网卡的服务器来说，同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB/10000）的内存和 100Kbit （1000Mbit/10000）的网络带宽就可以。所以，物理资源是足够的，接下来自然是软件的问题，特别是网络的 I/O 模型问题。\n说到 I/O 的模型，我在文件系统的原理中，曾经介绍过文件 I/O，其实网络 I/O 模型也类似。在 C10K 以前，Linux 中网络处理都用同步阻塞的方式，也就是每个请求都分配一个进程或者线程。请求数只有 100 个时，这种方式自然没问题，但增加到 10000 个请求时，10000 个进程或线程的调度、上下文切换乃至它们占用的内存，都会成为瓶颈。\n为了支持 10000 个并发请求，这里就有两个问题需要我们解决。\n第一，怎样在一个线程内处理多个请求，也就是要在一个线程内响应多个网络 I/O。以前的同步阻塞方式下，一个线程只能处理一个请求，到这里不再适用，是不是可以用非阻塞 I/O 或者异步 I/O 来处理多个网络请求呢？ 第二，怎么更节省资源地处理客户请求，也就是要用更少的线程来服务这些请求。是不是可以继续用原来的 100 个或者更少的线程，来服务现在的 10000 个请求呢？ I/O 模型优化 异步、非阻塞 I/O 的解决思路，你应该听说过，其实就是我们在网络编程中经常用到的 I/O 多路复用（I/O Multiplexing）。I/O 多路复用是什么意思呢？\n水平触发：只要文件描述符可以非阻塞地执行 I/O ，就会触发通知。也就是说，应用程序可以随时检查文件描述符的状态，然后再根据状态，进行 I/O 操作。 边缘触发：只有在文件描述符的状态发生改变（也就是 I/O 请求达到）时，才发送一次通知。这时候，应用程序需要尽可能多地执行 I/O，直到无法继续读写，才可以停止。如果 I/O 没执行完，或者因为某种原因没来得及处理，那么这次通知也就丢失了。 第一种，使用非阻塞 I/O 和水平触发通知，比如使用 select 或者 poll select 和 poll 需要从文件描述符列表中，找出哪些可以执行 I/O ，然后进行真正的网络 I/O 读写。由于 I/O 是非阻塞的，一个线程中就可以同时监控一批套接字的文件描述符，这样就达到了单线程处理多请求的目的。\n所以，这种方式的最大优点，是对应用程序比较友好，它的 API 非常简单。\n但是，应用软件使用 select 和 poll 时，需要对这些文件描述符列表进行轮询，这样，请求数多的时候就会比较耗时。并且，select 和 poll 还有一些其他的限制。\nselect 使用固定长度的位相量，表示文件描述符的集合，因此会有最大描述符数量的限制。比如，在 32 位系统中，默认限制是 1024。并且，在 select 内部，检查套接字状态是用轮询的方法，再加上应用软件使用时的轮询，就变成了一个 O(n^2) 的关系。\n而 poll 改进了 select 的表示方法，换成了一个没有固定长度的数组，这样就没有了最大描述符数量的限制（当然还会受到系统文件描述符限制）。但应用程序在使用 poll 时，同样需要对文件描述符列表进行轮询，这样，处理耗时跟描述符数量就是 O(N) 的关系。\n除此之外，应用程序每次调用 select 和 poll 时，还需要把文件描述符的集合，从用户空间传入内核空间，由内核修改后，再传出到用户空间中。这一来一回的内核空间与用户空间切换，也增加了处理成本。\n第二种，使用非阻塞 I/O 和边缘触发通知，比如 epoll 既然 select 和 poll 有那么多的问题，就需要继续对其进行优化，而 epoll 就很好地解决了这些问题。\nepoll 使用红黑树，在内核中管理文件描述符的集合，这样，就不需要应用程序在每次操作时都传入、传出这个集合。 epoll 使用事件驱动的机制，只关注有 I/O 事件发生的文件描述符，不需要轮询扫描整个集合。 注意，epoll 是在 Linux 2.6 中才新增的功能（2.4 虽然也有，但功能不完善）。由于边缘触发只在文件描述符可读或可写事件发生时才通知，那么应用程序就需要尽可能多地执行 I/O，并要处理更多的异常事件。\n第三种，使用异步 I/O（Asynchronous I/O，简称为 AIO） 异步 I/O 允许应用程序同时发起很多 I/O 操作，而不用等待这些操作完成。而在 I/O 完成后，系统会用事件通知（比如信号或者回调函数）的方式，告诉应用程序。这时，应用程序才会去查询 I/O 操作的结果。\n异步 I/O 也是到了 Linux 2.6 才支持的功能，并且在很长时间里都处于不完善的状态，比如 glibc 提供的异步 I/O 库，就一直被社区诟病。同时，由于异步 I/O 跟我们的直观逻辑不太一样，想要使用的话，一定要小心设计，其使用难度比较高。\n工作模型优化 使用 I/O 多路复用后，就可以在一个进程或线程中处理多个请求，其中，又有下面两种不同的工作模型。\n第一种，主进程 + 多个 worker 子进程，这也是最常用的一种模型 主进程执行 bind() + listen() 后，创建多个子进程； 然后，在每个子进程中，都通过 accept() 或 epoll_wait() ，来处理相同的套接字。 比如，最常用的反向代理服务器 Nginx 就是这么工作的。它也是由主进程和多个 worker 进程组成。主进程主要用来初始化套接字，并管理子进程的生命周期；而 worker 进程，则负责实际的请求处理。我画了一张图来表示这个关系。\n要注意，accept() 和 epoll_wait() 调用，还存在一个惊群的问题。换句话说，当网络 I/O 事件发生时，多个进程被同时唤醒，但实际上只有一个进程来响应这个事件，其他被唤醒的进程都会重新休眠。\n其中，accept() 的惊群问题，已经在 Linux 2.6 中解决了； 而 epoll 的问题，到了 Linux 4.5 ，才通过 EPOLLEXCLUSIVE 解决 为了避免惊群问题， Nginx 在每个 worker 进程中，都增加一个了全局锁（accept_mutex）。这些 worker 进程需要首先竞争到锁，只有竞争到锁的进程，才会加入到 epoll 中，这样就确保只有一个 worker 子进程被唤醒。\n第二种，监听到相同端口的多进程模型 在这种方式下，所有的进程都监听相同的接口，并且开启 SO_REUSEPORT 选项，由内核负责将请求负载均衡到这些监听进程中去。这一过程如下图所示。\n由于内核确保了只有一个进程被唤醒，就不会出现惊群问题了。比如，Nginx 在 1.9.1 中就已经支持了这种模式。\nC1000K 从 1 万到 10 万，其实还是基于 C10K 的这些理论，epoll 配合线程池，再加上 CPU、内存和网络接口的性能和容量提升。大部分情况下，C100K 很自然就可以达到。\n那么，再进一步，C1000K 是不是也可以很容易就实现呢？这其实没有那么简单了。\n首先从物理资源使用上来说，100 万个请求需要大量的系统资源。比如，\n假设每个请求需要 16KB 内存的话，那么总共就需要大约 15 GB 内存。 而从带宽上来说，假设只有 20% 活跃连接，即使每个连接只需要 1KB/s 的吞吐量，总共也需要 1.6 Gb/s 的吞吐量。千兆网卡显然满足不了这么大的吞吐量，所以还需要配置万兆网卡，或者基于多网卡 Bonding 承载更大的吞吐量。 其次，从软件资源上来说，大量的连接也会占用大量的软件资源，比如文件描述符的数量、连接状态的跟踪（CONNTRACK）、网络协议栈的缓存大小（比如套接字读写缓存、TCP 读写缓存）等等。\n最后，大量请求带来的中断处理，也会带来非常高的处理成本。这样，就需要多队列网卡、中断负载均衡、CPU 绑定、RPS/RFS（软中断负载均衡到多个 CPU 核上），以及将网络包的处理卸载（Offload）到网络设备（如 TSO/GSO、LRO/GRO、VXLAN OFFLOAD）等各种硬件和软件的优化。\nC1000K 的解决方法，本质上还是构建在 epoll 的非阻塞 I/O 模型上。只不过，除了 I/O 模型之外，还需要从应用程序到 Linux 内核、再到 CPU、内存和网络等各个层次的深度优化，特别是需要借助硬件，来卸载那些原来通过软件处理的大量功能。\nC10M 实际上，在 C1000K 问题中，各种软件、硬件的优化很可能都已经做到头了。特别是当升级完硬件（比如足够多的内存、带宽足够大的网卡、更多的网络功能卸载等）后，你可能会发现，无论你怎么优化应用程序和内核中的各种网络参数，想实现 1000 万请求的并发，都是极其困难的。\n究其根本，还是 Linux 内核协议栈做了太多太繁重的工作。从网卡中断带来的硬中断处理程序开始，到软中断中的各层网络协议处理，最后再到应用程序，这个路径实在是太长了，就会导致网络包的处理优化，到了一定程度后，就无法更进一步了。\n要解决这个问题，最重要就是跳过内核协议栈的冗长路径，把网络包直接送到要处理的应用程序那里去。这里有两种常见的机制，DPDK 和 XDP。\n第一种机制，DPDK，是用户态网络的标准。它跳过内核协议栈，直接由用户态进程通过轮询的方式，来处理网络接收。\n说起轮询，你肯定会下意识认为它是低效的象征，但是进一步反问下自己，它的低效主要体现在哪里呢？是查询时间明显多于实际工作时间的情况下吧！那么，换个角度来想，如果每时每刻都有新的网络包需要处理，轮询的优势就很明显了。比如：\n在 PPS 非常高的场景中，查询时间比实际工作时间少了很多，绝大部分时间都在处理网络包； 而跳过内核协议栈后，就省去了繁杂的硬中断、软中断再到 Linux 网络协议栈逐层处理的过程，应用程序可以针对应用的实际场景，有针对性地优化网络包的处理逻辑，而不需要关注所有的细节。 此外，DPDK 还通过大页、CPU 绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率。\n第二种机制，XDP（eXpress Data Path），则是 Linux 内核提供的一种高性能网络数据路径。它允许网络包，在进入内核协议栈之前，就进行处理，也可以带来更高的性能。XDP 底层跟我们之前用到的 bcc-tools 一样，都是基于 Linux 内核的 eBPF 机制实现的。\n小结 C10K 问题的根源，一方面在于系统有限的资源；另一方面，也是更重要的因素，是同步阻塞的 I/O 模型以及轮询的套接字接口，限制了网络事件的处理效率。Linux 2.6 中引入的 epoll ，完美解决了 C10K 的问题，现在的高性能网络方案都基于 epoll。\n从 C10K 到 C100K ，可能只需要增加系统的物理资源就可以满足；但从 C100K 到 C1000K ，就不仅仅是增加物理资源就能解决的问题了。这时，就需要多方面的优化工作了，从硬件的中断处理和网络功能卸载、到网络协议栈的文件描述符数量、连接状态跟踪、缓存队列等内核的优化，再到应用程序的工作模型优化，都是考虑的重点。\n再进一步，要实现 C10M ，就不只是增加物理资源，或者优化内核和应用程序可以解决的问题了。这时候，就需要用 XDP 的方式，在内核协议栈之前处理网络包；或者用 DPDK 直接跳过网络协议栈，在用户空间通过轮询的方式直接处理网络包。\n","description":"C10K 和 C1000K 的首字母 C 是 Client 的缩写。C10K 就是单机同时处理 1 万个请求（并发连接 1 万）的问题，而 C1000K 也就是单机支持处理 100 万个请求（并发连接 100 万）的问题。"},{"id":46,"href":"/post/36%E5%A5%97%E8%B7%AF%E7%AF%87%E6%80%8E%E4%B9%88%E8%AF%84%E4%BC%B0%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD/","title":"36|套路篇：怎么评估系统的网络性能？","parent":"Linux性能优化","content":"要实现 C10M，就不是增加物理资源、调优内核和应用程序可以解决的问题了。这时内核中冗长的网络协议栈就成了最大的负担。\n需要用 XDP 方式，在内核协议栈之前，先处理网络包。 或基于 DPDK ，直接跳过网络协议栈，在用户空间通过轮询的方式处理。 性能指标回顾 首先，带宽，表示链路的最大传输速率，单位是 b/s（比特 / 秒）。在你为服务器选购网卡时，带宽就是最核心的参考指标。常用的带宽有 1000M、10G、40G、100G 等。\n第二，吞吐量，表示没有丢包时的最大数据传输速率，单位通常为 b/s （比特 / 秒）或者 B/s（字节 / 秒）。吞吐量受带宽的限制，吞吐量 / 带宽也就是该网络链路的使用率。\n第三，延时，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。这个指标在不同场景中可能会有不同的含义。它可以表示建立连接需要的时间（比如 TCP 握手延时），或者一个数据包往返所需时间（比如 RTT）。\n最后，PPS，是 Packet Per Second（包 / 秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力，而基于 Linux 服务器的转发，很容易受到网络包大小的影响（交换机通常不会受到太大影响，即交换机可以线性转发）。\n这四个指标中，带宽跟物理网卡配置是直接关联的。一般来说，网卡确定后，带宽也就确定了（当然，实际带宽会受限于整个网络链路中最小的那个模块）。\n网络基准测试 基于 HTTP 或者 HTTPS 的 Web 应用程序，显然属于应用层，需要我们测试 HTTP/HTTPS 的性能； 而对大多数游戏服务器来说，为了支持更大的同时在线人数，通常会基于 TCP 或 UDP ，与客户端进行交互，这时就需要我们测试 TCP/UDP 的性能；当 然，还有一些场景，是把 Linux 作为一个软交换机或者路由器来用的。这种情况下，你更关注网络包的处理能力（即 PPS），重点关注网络层的转发性能。 各协议层的性能测试 转发性能 Linux 内核自带的高性能网络测试工具 pktgen。pktgen 支持丰富的自定义选项，方便你根据实际需要构造所需网络包，从而更准确地测试出目标服务器的性能。\nTCP/UDP 性能 相应的测试工具，比如 iperf 或者 netperf。\nHTTP 性能 要测试 HTTP 的性能，也有大量的工具可以使用，比如 ab、webbench 等，都是常用的 HTTP 压力测试工具。其中，ab 是 Apache 自带的 HTTP 压测工具，主要测试 HTTP 服务的每秒请求数、请求延迟、吞吐量以及请求延迟的分布情况等。\n应用负载性能 可以用 wrk、TCPCopy、Jmeter 或者 LoadRunner 等实现这个目标。\n小结 性能评估是优化网络性能的前提，只有在你发现网络性能瓶颈时，才需要进行网络性能优化。根据 TCP/IP 协议栈的原理，不同协议层关注的性能重点不完全一样，也就对应不同的性能测试方法。比如，\n在应用层，你可以使用 wrk、Jmeter 等模拟用户的负载，测试应用程序的每秒请求数、处理延迟、错误数等； 而在传输层，则可以使用 iperf 等工具，测试 TCP 的吞吐情况； 再向下，你还可以用 Linux 内核自带的 pktgen ，测试服务器的 PPS。由于低层协议是高层协议的基础。 所以，一般情况下，我们需要从上到下，对每个协议层进行性能测试，然后根据性能测试的结果，结合 Linux 网络协议栈的原理，找出导致性能瓶颈的根源，进而优化网络性能。\n","description":"要实现 C10M，就不是增加物理资源、调优内核和应用程序可以解决的问题了。这时内核中冗长的网络协议栈就成了最大的负担。\n需要用 XDP 方式，在内核协议栈之前，先处理网络包。 或基于 DPDK ，直接跳过网络协议栈，在用户空间通过轮询的方式处理。 性能指标回顾 首先，带宽，表示链路的最大传输速率，单位是 b/s（比特 / 秒）。在你为服务器选购网卡时，带宽就是最核心的参考指标。常用的带宽有 1000M、10G、40G、100G 等。"},{"id":47,"href":"/post/37%E6%A1%88%E4%BE%8B%E7%AF%87DNS-%E8%A7%A3%E6%9E%90%E6%97%B6%E5%BF%AB%E6%97%B6%E6%85%A2%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/","title":"37|案例篇：DNS 解析时快时慢，我该怎么办？","parent":"Linux性能优化","content":"Linux 网络基于 TCP/IP 协议栈构建，而在协议栈的不同层，我们所关注的网络性能也不尽相同。\n在应用层，我们关注的是应用程序的并发连接数、每秒请求数、处理延迟、错误数等，可以使用 wrk、JMeter 等工具，模拟用户的负载，得到想要的测试结果。\n而在传输层，我们关注的是 TCP、UDP 等传输层协议的工作状况，比如 TCP 连接数、 TCP 重传、TCP 错误数等。此时，你可以使用 iperf、netperf 等，来测试 TCP 或 UDP 的性能。\n再向下到网络层，我们关注的则是网络包的处理能力，即 PPS。Linux 内核自带的 pktgen，就可以帮你测试这个指标。\nDNS（Domain Name System），即域名系统，是互联网中最基础的一项服务，主要提供域名和 IP 地址之间映射关系的查询服务。\nDNS 不仅方便了人们访问不同的互联网服务，更为很多应用提供了，动态服务发现和全局负载均衡（Global Server Load Balance，GSLB）的机制。这样，DNS 就可以选择离用户最近的 IP 来提供服务。即使后端服务的 IP 地址发生变化，用户依然可以用相同域名来访问。\n域名与 DNS 解析 域名是全球唯一的，需要通过专门的域名注册商才可以申请注册。为了组织全球互联网中的众多计算机，域名同样用点来分开，形成一个分层的结构。而每个被点分割开的字符串，就构成了域名中的一个层级，并且位置越靠后，层级越高。\n域名主要是为了方便让人记住，而 IP 地址是机器间的通信的真正机制。\n把域名转换为 IP 地址的服务，也就是域名解析服务（DNS），而对应的服务器就是域名服务器，网络协议则是 DNS 协议。\nDNS 协议在 TCP/IP 栈中属于应用层，不过实际传输还是基于 UDP 或者 TCP 协议（UDP 居多） ，并且域名服务器一般监听在端口 53 上。\nDNS 服务通过资源记录的方式，来管理所有数据，它支持 A、CNAME、MX、NS、PTR 等多种类型的记录。比如：\nA 记录，用来把域名转换成 IP 地址； CNAME 记录，用来创建别名； 而 NS 记录，则表示该域名对应的域名服务器地址。 以极客时间的网站 time.geekbang.org 为例，执行下面的 nslookup 命令，就可以查询到这个域名的 A 记录，可以看到，它的 IP 地址是 39.106.233.176：\n$ nslookup time.geekbang.org # 域名服务器及端口信息 Server: 114.114.114.114 Address: 114.114.114.114#53 # 非权威查询结果 Non-authoritative answer: Name: time.geekbang.org Address: 39.106.233.17 除了 nslookup，另外一个常用的 DNS 解析工具 dig ，就提供了 trace 功能，可以展示递归查询的整个过程。比如你可以执行下面的命令，得到查询结果：\n# +trace表示开启跟踪查询 # +nodnssec表示禁止DNS安全扩展 $ dig +trace +nodnssec time.geekbang.org ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.11.3-1ubuntu1.3-Ubuntu \u0026lt;\u0026lt;\u0026gt;\u0026gt; +trace +nodnssec time.geekbang.org ;; global options: +cmd . 322086 IN NS m.root-servers.net. . 322086 IN NS a.root-servers.net. . 322086 IN NS i.root-servers.net. . 322086 IN NS d.root-servers.net. . 322086 IN NS g.root-servers.net. . 322086 IN NS l.root-servers.net. . 322086 IN NS c.root-servers.net. . 322086 IN NS b.root-servers.net. . 322086 IN NS h.root-servers.net. . 322086 IN NS e.root-servers.net. . 322086 IN NS k.root-servers.net. . 322086 IN NS j.root-servers.net. . 322086 IN NS f.root-servers.net. ;; Received 239 bytes from 114.114.114.114#53(114.114.114.114) in 1340 ms org. 172800 IN NS a0.org.afilias-nst.info. org. 172800 IN NS a2.org.afilias-nst.info. org. 172800 IN NS b0.org.afilias-nst.org. org. 172800 IN NS b2.org.afilias-nst.org. org. 172800 IN NS c0.org.afilias-nst.info. org. 172800 IN NS d0.org.afilias-nst.org. ;; Received 448 bytes from 198.97.190.53#53(h.root-servers.net) in 708 ms geekbang.org. 86400 IN NS dns9.hichina.com. geekbang.org. 86400 IN NS dns10.hichina.com. ;; Received 96 bytes from 199.19.54.1#53(b0.org.afilias-nst.org) in 1833 ms time.geekbang.org. 600 IN A 39.106.233.176 ;; Received 62 bytes from 140.205.41.16#53(dns10.hichina.com) in 4 ms dig trace 的输出，主要包括四部分。\n第一部分，是从 114.114.114.114 查到的一些根域名服务器（.）的 NS 记录。 第二部分，是从 NS 记录结果中选一个（h.root-servers.net），并查询顶级域名 org. 的 NS 记录。 第三部分，是从 org. 的 NS 记录中选择一个（b0.org.afilias-nst.org），并查询二级域名 geekbang.org. 的 NS 服务器。 最后一部分，就是从 geekbang.org. 的 NS 服务器（dns10.hichina.com）查询最终主机 time.geekbang.org. 的 A 记录。 不仅仅是发布到互联网的服务需要域名，很多时候，我们也希望能对局域网内部的主机进行域名解析（即内网域名，大多数情况下为主机名）。Linux 也支持这种行为。\n可以把主机名和 IP 地址的映射关系，写入本机的 /etc/hosts 文件中。这样，指定的主机名就可以在本地直接找到目标 IP。比如，你可以执行下面的命令来操作：\n$ cat /etc/hosts 127.0.0.1 localhost localhost.localdomain ::1 localhost6 localhost6.localdomain6 192.168.0.100 domain.com 案例分析 案例 1：DNS 解析失败 案例 2：DNS 解析不稳定 dnsmasq 是最常用的 DNS 缓存服务之一，还经常作为 DHCP 服务来使用。它的安装和配置都比较简单，性能也可以满足绝大多数应用程序对 DNS 缓存的需求。\n小结 在应用程序的开发过程中，我们必须考虑到 DNS 解析可能带来的性能问题，掌握常见的优化方法。这里，我总结了几种常见的 DNS 优化方法。\n对 DNS 解析的结果进行缓存。缓存是最有效的方法，但要注意，一旦缓存过期，还是要去 DNS 服务器重新获取新记录。不过，这对大部分应用程序来说都是可接受的。 对 DNS 解析的结果进行预取。这是浏览器等 Web 应用中最常用的方法，也就是说，不等用户点击页面上的超链接，浏览器就会在后台自动解析域名，并把结果缓存起来。 使用 HTTPDNS 取代常规的 DNS 解析。这是很多移动应用会选择的方法，特别是如今域名劫持普遍存在，使用 HTTP 协议绕过链路中的 DNS 服务器，就可以避免域名劫持的问题。 基于 DNS 的全局负载均衡（GSLB）。这不仅为服务提供了负载均衡和高可用的功能，还可以根据用户的位置，返回距离最近的 IP 地址。 ","description":"Linux 网络基于 TCP/IP 协议栈构建，而在协议栈的不同层，我们所关注的网络性能也不尽相同。\n在应用层，我们关注的是应用程序的并发连接数、每秒请求数、处理延迟、错误数等，可以使用 wrk、JMeter 等工具，模拟用户的负载，得到想要的测试结果。\n而在传输层，我们关注的是 TCP、UDP 等传输层协议的工作状况，比如 TCP 连接数、 TCP 重传、TCP 错误数等。此时，你可以使用 iperf、netperf 等，来测试 TCP 或 UDP 的性能。"},{"id":48,"href":"/post/38%E6%A1%88%E4%BE%8B%E7%AF%87%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8-tcpdump-%E5%92%8C-Wireshark-%E5%88%86%E6%9E%90%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F/","title":"38|案例篇：怎么使用 tcpdump 和 Wireshark 分析网络流量？","parent":"Linux性能优化","content":"可以借助 nslookup 或者 dig 的调试功能，分析 DNS 的解析过程，再配合 ping 等工具调试 DNS 服务器的延迟，从而定位出性能瓶颈。通常，你可以用缓存、预取、HTTPDNS 等方法，优化 DNS 的性能。\ntcpdump 和 Wireshark 就是最常用的网络抓包和分析工具，更是分析网络性能必不可少的利器。\ntcpdump 仅支持命令行格式使用，常用在服务器中抓取和分析网络包。 Wireshark 除了可以抓包外，还提供了强大的图形界面和汇总分析工具，在分析复杂的网络情景时，尤为简单和实用。 tcpdump -nn udp port 53 or host 35.190.27.188 -nn ，表示不解析抓包中的域名（即不反向解析）、协议以及端口号。 udp port 53 ，表示只显示 UDP 协议的端口号（包括源端口和目的端口）为 53 的包。 host 35.190.27.188 ，表示只显示 IP 地址（包括源地址和目的地址）为 35.190.27.188 的包。 这两个过滤条件中间的“ or ”，表示或的关系，也就是说，只要满足上面两个条件中的任一个，就可以展示出来。 tcpdump tcpdump 为你展示了每个网络包的详细细节，这就要求，在使用前，你必须要对网络协议有基本了解。而要了解网络协议的详细设计和实现细节， RFC 当然是最权威的资料。\ntcpdump 的输出格式:\n时间戳 协议 源地址.源端口 \u0026gt; 目的地址.目的端口 网络包详细信息 Wireshark Wireshark 也是最流行的一个网络分析工具，它最大的好处就是提供了跨平台的图形界面。跟 tcpdump 类似，Wireshark 也提供了强大的过滤规则表达式，同时，还内置了一系列的汇总分析工具。\n拿的 ping 案例来说，你可以执行下面的命令，把抓取的网络包保存到 ping.pcap 文件中：\ntcpdump -nn udp port 53 or host 35.190.27.188 -w ping.pcap 用 Wireshark 打开它。打开后，你就可以看到下面这个界面：\n从 Wireshark 的界面里，你可以发现，它不仅以更规整的格式，展示了各个网络包的头部信息；还用了不同颜色，展示 DNS 和 ICMP 这两种不同的协议。你也可以一眼看出，中间的两条 PTR 查询并没有响应包。\n接着，在网络包列表中选择某一个网络包后，在其下方的网络包详情中，你还可以看到，这个包在协议栈各层的详细信息。比如，以编号为 5 的 PTR 包为例：\n你可以看到，IP 层（Internet Protocol）的源地址和目的地址、传输层的 UDP 协议（Uder Datagram Protocol）、应用层的 DNS 协议（Domain Name System）的概要信息。\n继续点击每层左边的箭头，就可以看到该层协议头的所有信息。比如点击 DNS 后，就可以看到 Transaction ID、Flags、Queries 等 DNS 协议各个字段的数值以及含义。\n通常看到的 TCP 三次握手和四次挥手的流程，基本是这样的：\n小结 根据 IP 地址反查域名、根据端口号反查协议名称，是很多网络工具默认的行为，而这往往会导致性能工具的工作缓慢。所以，通常，网络性能工具都会提供一个选项（比如 -n 或者 -nn），来禁止名称解析。\n","description":"可以借助 nslookup 或者 dig 的调试功能，分析 DNS 的解析过程，再配合 ping 等工具调试 DNS 服务器的延迟，从而定位出性能瓶颈。通常，你可以用缓存、预取、HTTPDNS 等方法，优化 DNS 的性能。"},{"id":49,"href":"/post/39%E6%A1%88%E4%BE%8B%E7%AF%87%E6%80%8E%E4%B9%88%E7%BC%93%E8%A7%A3-DDoS-%E6%94%BB%E5%87%BB%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%80%A7%E8%83%BD%E4%B8%8B%E9%99%8D%E9%97%AE%E9%A2%98/","title":"39|案例篇：怎么缓解 DDoS 攻击带来的性能下降问题？","parent":"Linux性能优化","content":" DDoS 简介 DDoS 的前身是 DoS（Denail of Service），即拒绝服务攻击，指利用大量的合理请求，来占用过多的目标资源，从而使目标服务无法响应正常请求。\nDDoS（Distributed Denial of Service） 则是在 DoS 的基础上，采用了分布式架构，利用多台主机同时攻击目标主机。这样，即使目标服务部署了网络防御设备，面对大量网络请求时，还是无力应对。\n比如，目前已知的最大流量攻击，正是去年 Github 遭受的 DDoS 攻击，其峰值流量已经达到了 1.35Tbps，PPS 更是超过了 1.2 亿（126.9 million）。\nDDoS 可以分为下面几种类型。\n第一种，耗尽带宽。无论是服务器还是路由器、交换机等网络设备，带宽都有固定的上限。带宽耗尽后，就会发生网络拥堵，从而无法传输其他正常的网络报文。 第二种，耗尽操作系统的资源。网络服务的正常运行，都需要一定的系统资源，像是 CPU、内存等物理资源，以及连接表等软件资源。一旦资源耗尽，系统就不能处理其他正常的网络连接。 第三种，消耗应用程序的运行资源。应用程序的运行，通常还需要跟其他的资源或系统交互。如果应用程序一直忙于处理无效请求，也会导致正常请求的处理变慢，甚至得不到响应。 比如，构造大量不同的域名来攻击 DNS 服务器，就会导致 DNS 服务器不停执行迭代查询，并更新缓存。这会极大地消耗 DNS 服务器的资源，使 DNS 的响应变慢。 案例 首先，在终端一中，执行下面的命令运行案例，也就是启动一个最基本的 Nginx 应用：\n# 运行Nginx服务并对外开放80端口 # --network=host表示使用主机网络（这是为了方便后面排查问题） $ docker run -itd --name=nginx --network=host nginx 然后，在终端二和终端三中，使用 curl 访问 Nginx 监听的端口，确认 Nginx 正常启动。假设 192.168.0.30 是 Nginx 所在虚拟机的 IP 地址，那么运行 curl 命令后，你应该会看到下面这个输出界面：\n# -w表示只输出HTTP状态码及总时间，-o表示将响应重定向到/dev/null $ curl -s -w \u0026#39;Http code: %{http_code}\\nTotal time:%{time_total}s\\n\u0026#39; -o /dev/null http://192.168.0.30/ ... Http code: 200 Total time:0.002s 从这里可以看到，正常情况下，我们访问 Nginx 只需要 2ms（0.002s）。\n接着，在终端二中，运行 hping3 命令，来模拟 DoS 攻击：\n# -S参数表示设置TCP协议的SYN（同步序列号），-p表示目的端口为80 # -i u10表示每隔10微秒发送一个网络帧 $ hping3 -S -p 80 -i u10 192.168.0.30 然后，到终端三中，执行下面的命令，模拟正常客户端的连接：\n# --connect-timeout表示连接超时时间 $ curl -w \u0026#39;Http code: %{http_code}\\nTotal time:%{time_total}s\\n\u0026#39; -o /dev/null --connect-timeout 10 http://192.168.0.30 ... Http code: 000 Total time:10.001s curl: (28) Connection timed out after 10000 milliseconds 你可以发现，在终端三中，正常客户端的连接超时了，并没有收到 Nginx 服务的响应。\n可以回到终端一中，执行下面的命令：\n$ sar -n DEV 1 08:55:49 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 08:55:50 docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 08:55:50 eth0 22274.00 629.00 1174.64 37.78 0.00 0.00 0.00 0.02 08:55:50 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 在终端一中，执行下面的 tcpdump 命令：\n# -i eth0 只抓取eth0网卡，-n不解析协议名和主机名 # tcp port 80表示只抓取tcp协议并且端口号为80的网络帧 $ tcpdump -i eth0 -n tcp port 80 09:15:48.287047 IP 192.168.0.2.27095 \u0026gt; 192.168.0.30: Flags [S], seq 1288268370, win 512, length 0 09:15:48.287050 IP 192.168.0.2.27131 \u0026gt; 192.168.0.30: Flags [S], seq 2084255254, win 512, length 0 09:15:48.287052 IP 192.168.0.2.27116 \u0026gt; 192.168.0.30: Flags [S], seq 677393791, win 512, length 0 09:15:48.287055 IP 192.168.0.2.27141 \u0026gt; 192.168.0.30: Flags [S], seq 1276451587, win 512, length 0 09:15:48.287068 IP 192.168.0.2.27154 \u0026gt; 192.168.0.30: Flags [S], seq 1851495339, win 512, length 0 ... DDoS 到底该怎么防御 当 DDoS 报文到达服务器后，Linux 提供的机制只能缓解，而无法彻底解决。即使像是 SYN Flood 这样的小包攻击，其巨大的 PPS ，也会导致 Linux 内核消耗大量资源，进而导致其他网络报文的处理缓慢。\n对于流量型的 DDoS 来说，当服务器的带宽被耗尽后，在服务器内部处理就无能为力了。这时，只能在服务器外部的网络设备中，设法识别并阻断流量（当然前提是网络设备要能扛住流量攻击）。比如，购置专业的入侵检测和防御设备，配置流量清洗设备阻断恶意流量等。\nDDoS 并不一定是因为大流量或者大 PPS，有时候，慢速的请求也会带来巨大的性能下降（这种情况称为慢速 DDoS）。\n比如，很多针对应用程序的攻击，都会伪装成正常用户来请求资源。这种情况下，请求流量可能本身并不大，但响应流量却可能很大，并且应用程序内部也很可能要耗费大量资源处理。\n这时，就需要应用程序考虑识别，并尽早拒绝掉这些恶意流量，比如合理利用缓存、增加 WAF（Web Application Firewall）、使用 CDN 等等。\n小结 学习了分布式拒绝服务（DDoS）时的缓解方法。DDoS 利用大量的伪造请求，使目标服务耗费大量资源，来处理这些无效请求，进而无法正常响应正常的用户请求。\n由于 DDoS 的分布式、大流量、难追踪等特点，目前还没有方法可以完全防御 DDoS 带来的问题，只能设法缓解这个影响。\n比如，你可以购买专业的流量清洗设备和网络防火墙，在网络入口处阻断恶意流量，只保留正常流量进入数据中心的服务器中。\n在 Linux 服务器中，你可以通过内核调优、DPDK、XDP 等多种方法，来增大服务器的抗攻击能力，降低 DDoS 对正常服务的影响。而在应用程序中，你可以利用各级缓存、 WAF、CDN 等方式，缓解 DDoS 对应用程序的影响。\n","description":"DDoS 简介 DDoS 的前身是 DoS（Denail of Service），即拒绝服务攻击，指利用大量的合理请求，来占用过多的目标资源，从而使目标服务无法响应正常请求。\nDDoS（Distributed Denial of Service） 则是在 DoS 的基础上，采用了分布式架构，利用多台主机同时攻击目标主机。这样，即使目标服务部署了网络防御设备，面对大量网络请求时，还是无力应对。"},{"id":50,"href":"/post/40%E6%A1%88%E4%BE%8B%E7%AF%87%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F%E5%8F%98%E5%A4%A7%E4%BA%86%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/","title":"40|案例篇：网络请求延迟变大了，我该怎么办？","parent":"Linux性能优化","content":"除了 DDoS 会带来网络延迟增大外，我想，你肯定见到过不少其他原因导致的网络延迟，比如\n网络传输慢，导致延迟； Linux 内核协议栈报文处理慢，导致延迟； 应用程序数据处理慢，导致延迟等等。 网络延迟 网络数据传输所用的时间。不过要注意，这个时间可能是单向的，指从源地址发送到目的地址的单程时间；也可能是双向的，即从源地址发送到目的地址，然后又从目的地址发回响应，这个往返全程所用的时间。\n通常，我们更常用的是双向的往返通信延迟，比如 ping 测试的结果，就是往返延时 RTT（Round-Trip Time）。\n应用程序延迟，它是指，从应用程序接收到请求，再到发回响应，全程所用的时间。通常，应用程序延迟也指的是往返延迟，是网络数据传输时间加上数据处理时间的和。\n可以用 ping 来测试网络延迟。ping 基于 ICMP 协议，它通过计算 ICMP 回显响应报文与 ICMP 回显请求报文的时间差，来获得往返延时。这个过程并不需要特殊认证，常被很多网络攻击利用，比如端口扫描工具 nmap、组包工具 hping3 等等。\n为了避免这些问题，很多网络服务会把 ICMP 禁止掉，这也就导致我们无法用 ping ，来测试网络服务的可用性和往返延时。这时，你可以用 traceroute 或 hping3 的 TCP 和 UDP 模式，来获取网络延迟。\n# -c表示发送3次请求，-S表示设置TCP SYN，-p表示端口号为80 $ hping3 -c 3 -S -p 80 baidu.com HPING baidu.com (eth0 123.125.115.110): S set, 40 headers + 0 data bytes len=46 ip=123.125.115.110 ttl=51 id=47908 sport=80 flags=SA seq=0 win=8192 rtt=20.9 ms len=46 ip=123.125.115.110 ttl=51 id=6788 sport=80 flags=SA seq=1 win=8192 rtt=20.9 ms len=46 ip=123.125.115.110 ttl=51 id=37699 sport=80 flags=SA seq=2 win=8192 rtt=20.9 ms --- baidu.com hping statistic --- 3 packets transmitted, 3 packets received, 0% packet loss round-trip min/avg/max = 20.9/20.9/20.9 ms 从 hping3 的结果中，你可以看到，往返延迟 RTT 为 20.9ms。\n用 traceroute ，也可以得到类似结果：\n# --tcp表示使用TCP协议，-p表示端口号，-n表示不对结果中的IP地址执行反向域名解析 $ traceroute --tcp -p 80 -n baidu.com traceroute to baidu.com (123.125.115.110), 30 hops max, 60 byte packets 1 * * * 2 * * * 3 * * * 4 * * * 5 * * * 6 * * * 7 * * * 8 * * * 9 * * * 10 * * * 11 * * * 12 * * * 13 * * * 14 123.125.115.110 20.684 ms * 20.798 ms traceroute 会在路由的每一跳发送三个包，并在收到响应后，输出往返延时。如果无响应或者响应超时（默认 5s），就会输出一个星号。\n小结 在发现网络延迟增大后，你可以用 traceroute、hping3、tcpdump、Wireshark、strace 等多种工具，来定位网络中的潜在问题。比如，\n使用 hping3 以及 wrk 等工具，确认单次请求和并发请求情况的网络延迟是否正常。 使用 traceroute，确认路由是否正确，并查看路由中每一跳网关的延迟。 使用 tcpdump 和 Wireshark，确认网络包的收发是否正常。 使用 strace 等，观察应用程序对网络套接字的调用情况是否正常。 ","description":"除了 DDoS 会带来网络延迟增大外，我想，你肯定见到过不少其他原因导致的网络延迟，比如\n网络传输慢，导致延迟； Linux 内核协议栈报文处理慢，导致延迟； 应用程序数据处理慢，导致延迟等等。 网络延迟 网络数据传输所用的时间。不过要注意，这个时间可能是单向的，指从源地址发送到目的地址的单程时间；也可能是双向的，即从源地址发送到目的地址，然后又从目的地址发回响应，这个往返全程所用的时间。\n通常，我们更常用的是双向的往返通信延迟，比如 ping 测试的结果，就是往返延时 RTT（Round-Trip Time）。"},{"id":51,"href":"/post/41%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96-NAT-%E6%80%A7%E8%83%BD%E4%B8%8A/","title":"41|案例篇：如何优化 NAT 性能？（上）","parent":"Linux性能优化","content":"另一个可能导致网络延迟的因素，即网络地址转换（Network Address Translation），缩写为 NAT。\nNAT 原理 NAT 技术可以重写 IP 数据包的源 IP 或者目的 IP，被普遍地用来解决公网 IP 地址短缺的问题。它的主要原理就是，网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，自然也就为局域网中的机器提供了安全隔离。\n既可以在支持网络地址转换的路由器（称为 NAT 网关）中配置 NAT，也可以在 Linux 服务器中配置 NAT。如果采用第二种方式，Linux 服务器实际上充当的是“软”路由器的角色。\nNAT 的主要目的，是实现地址转换。根据实现方式的不同，NAT 可以分为三类：\n静态 NAT，即内网 IP 与公网 IP 是一对一的永久映射关系； 动态 NAT，即内网 IP 从公网 IP 池中，动态选择一个进行映射； 网络地址端口转换 NAPT（Network Address and Port Translation），即把内网 IP 映射到公网 IP 的不同端口上，让多个内网 IP 可以共享同一个公网 IP 地址。 NAPT 是目前最流行的 NAT 类型，我们在 Linux 中配置的 NAT 也是这种类型。而根据转换方式的不同，我们又可以把 NAPT 分为三类。\n第一类是源地址转换 SNAT，即目的地址不变，只替换源 IP 或源端口。SNAT 主要用于，多个内网 IP 共享同一个公网 IP ，来访问外网资源的场景。 第二类是目的地址转换 DNAT，即源 IP 保持不变，只替换目的 IP 或者目的端口。DNAT 主要通过公网 IP 的不同端口号，来访问内网的多种服务，同时会隐藏后端服务器的真实 IP 地址。 第三类是双向地址转换，即同时使用 SNAT 和 DNAT。当接收到网络包时，执行 DNAT，把目的 IP 转换为内网 IP；而在发送网络包时，执行 SNAT，把源 IP 替换为外部 IP。 双向地址转换，其实就是外网 IP 与内网 IP 的一对一映射关系，所以常用在虚拟化环境中，为虚拟机分配浮动的公网 IP 地址。\n为了帮你理解 NAPT，我画了一张图。我们假设：\n本地服务器的内网 IP 地址为 192.168.0.2； NAT 网关中的公网 IP 地址为 100.100.100.100； 要访问的目的服务器 baidu.com 的地址为 123.125.115.110。 那么 SNAT 和 DNAT 的过程，就如下图所示： 从图中，你可以发现：\n当服务器访问 baidu.com 时，NAT 网关会把源地址，从服务器的内网 IP 192.168.0.2 替换成公网 IP 地址 100.100.100.100，然后才发送给 baidu.com； 当 baidu.com 发回响应包时，NAT 网关又会把目的地址，从公网 IP 地址 100.100.100.100 替换成服务器内网 IP 192.168.0.2，然后再发送给内网中的服务器。 iptables 与 NAT Linux 内核提供的 Netfilter 框架，允许对网络数据包进行修改（比如 NAT）和过滤（比如防火墙）。在这个基础上，iptables、ip6tables、ebtables 等工具，又提供了更易用的命令行接口，以便系统管理员配置和管理 NAT、防火墙的规则。\n其中，iptables 就是最常用的一种配置工具。要掌握 iptables 的原理和使用方法，最核心的就是弄清楚，网络数据包通过 Netfilter 时的工作流向，下面这张图就展示了这一过程。\n在这张图中，绿色背景的方框，表示表（table），用来管理链。Linux 支持 4 种表，包括 filter（用于过滤）、nat（用于 NAT）、mangle（用于修改分组数据） 和 raw（用于原始数据包）等。\n跟 table 一起的白色背景方框，则表示链（chain），用来管理具体的 iptables 规则。每个表中可以包含多条链，比如：\nfilter 表中，内置 INPUT、OUTPUT 和 FORWARD 链； nat 表中，内置 PREROUTING、POSTROUTING、OUTPUT 等。 灰色的 conntrack，表示连接跟踪模块。它通过内核中的连接跟踪表（也就是哈希表），记录网络连接的状态，是 iptables 状态过滤（-m state）和 NAT 的实现基础。\niptables 的所有规则，就会放到这些表和链中，并按照图中顺序和规则的优先级顺序来执行。\nat 表内置了三个链：\nPREROUTING，用于路由判断前所执行的规则，比如，对接收到的数据包进行 DNAT。 POSTROUTING，用于路由判断后所执行的规则，比如，对发送或转发的数据包进行 SNAT 或 MASQUERADE。 OUTPUT，类似于 PREROUTING，但只处理从本机发送出去的包。 SNAT SNAT 需要在 nat 表的 POSTROUTING 链中配置。我们常用两种方式来配置它。\n第一种方法，是为一个子网统一配置 SNAT，并由 Linux 选择默认的出口 IP。这实际上就是经常说的 MASQUERADE：\niptables -t nat -A POSTROUTING -s 192.168.0.0/16 -j MASQUERADE 第二种方法，是为具体的 IP 地址配置 SNAT，并指定转换后的源地址：\niptables -t nat -A POSTROUTING -s 192.168.0.2 -j SNAT --to-source 100.100.100.100 DNAT DNAT 需要在 nat 表的 PREROUTING 或者 OUTPUT 链中配置，其中， PREROUTING 链更常用一些（因为它还可以用于转发的包）。\niptables -t nat -A PREROUTING -d 100.100.100.100 -j DNAT --to-destination 192.168.0.2 双向地址转换 双向地址转换，就是同时添加 SNAT 和 DNAT 规则，为公网 IP 和内网 IP 实现一对一的映射关系，即：\niptables -t nat -A POSTROUTING -s 192.168.0.2 -j SNAT --to-source 100.100.100.100 iptables -t nat -A PREROUTING -d 100.100.100.100 -j DNAT --to-destination 192.168.0.2 使用 iptables 配置 NAT 规则时，Linux 需要转发来自其他 IP 的网络包，所以你千万不要忘记开启 Linux 的 IP 转发功能。\n可以执行下面的命令，查看这一功能是否开启。如果输出的结果是 1，就表示已经开启了 IP 转发：\n$ sysctl net.ipv4.ip_forward net.ipv4.ip_forward = 1 如果还没开启，你可以执行下面的命令，手动开启：\n$ sysctl -w net.ipv4.ip_forward=1 net.ipv4.ip_forward = 1 为了避免重启后配置丢失，不要忘记将配置写入 /etc/sysctl.conf 文件中：\n$ cat /etc/sysctl.conf | grep ip_forward net.ipv4.ip_forward=1 小结 NAT 技术能够重写 IP 数据包的源 IP 或目的 IP，所以普遍用来解决公网 IP 地址短缺的问题。它可以让网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，也为局域网中机器起到安全隔离的作用。\nLinux 中的 NAT ，基于内核的连接跟踪模块实现。所以，它维护每个连接状态的同时，也会带来很高的性能成本。\n","description":"另一个可能导致网络延迟的因素，即网络地址转换（Network Address Translation），缩写为 NAT。\nNAT 原理 NAT 技术可以重写 IP 数据包的源 IP 或者目的 IP，被普遍地用来解决公网 IP 地址短缺的问题。它的主要原理就是，网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，自然也就为局域网中的机器提供了安全隔离。"},{"id":52,"href":"/post/42%E6%A1%88%E4%BE%8B%E7%AF%87%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96-NAT-%E6%80%A7%E8%83%BD%E4%B8%8B/","title":"42|案例篇：如何优化 NAT 性能？（下）","parent":"Linux性能优化","content":"NAT 技术能够重写 IP 数据包的源 IP 或目的 IP，所以普遍用来解决公网 IP 地址短缺的问题。它可以让网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，也为局域网中机器起到安全隔离的作用。\nLinux 中的 NAT ，基于内核的连接跟踪模块实现。所以，它维护每个连接状态的同时，也对网络性能有一定影响。\n由于 NAT 基于 Linux 内核的连接跟踪机制来实现。所以，在分析 NAT 性能问题时，我们可以先从 conntrack 角度来分析，比如用 systemtap、perf 等，分析内核中 conntrack 的行文；然后，通过调整 netfilter 内核选项的参数，来进行优化。\n其实，Linux 这种通过连接跟踪机制实现的 NAT，也常被称为有状态的 NAT，而维护状态，也带来了很高的性能成本。\n所以，除了调整内核行为外，在不需要状态跟踪的场景下（比如只需要按预定的 IP 和端口进行映射，而不需要动态映射），我们也可以使用无状态的 NAT （比如用 tc 或基于 DPDK 开发），来进一步提升性能。\n","description":"NAT 技术能够重写 IP 数据包的源 IP 或目的 IP，所以普遍用来解决公网 IP 地址短缺的问题。它可以让网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，也为局域网中机器起到安全隔离的作用。"},{"id":53,"href":"/post/43%E5%A5%97%E8%B7%AF%E7%AF%87%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%E4%B8%8A/","title":"43|套路篇：网络性能优化的几个思路（上）","parent":"Linux性能优化","content":"NAT 基于 Linux 内核的连接跟踪机制，实现了 IP 地址及端口号重写的功能，主要被用来解决公网 IP 地址短缺的问题。\n在分析 NAT 性能问题时，可以先从内核连接跟踪模块 conntrack 角度来分析，比如用 systemtap、perf、netstat 等工具，以及 proc 文件系统中的内核选项，来分析网络协议栈的行为；然后，通过内核选项调优、切换到无状态 NAT、使用 DPDK 等方式，进行实际优化。\n确定优化目标 优化前，我会先问问自己，网络性能优化的目标是什么？换句话说，我们观察到的网络性能指标，要达到多少才合适呢？\n在进行基准测试时，我们就可以按照协议栈的每一层来测试。由于底层是其上方各层的基础，底层性能也就决定了高层性能。所以我们要清楚，底层性能指标，其实就是对应高层的极限性能。我们从下到上来理解这一点。\n首先是网络接口层和网络层，它们主要负责网络包的封装、寻址、路由，以及发送和接收。每秒可处理的网络包数 PPS，就是它们最重要的性能指标（特别是在小包的情况下）。你可以用内核自带的发包工具 pktgen ，来测试 PPS 的性能。\n再向上到传输层的 TCP 和 UDP，它们主要负责网络传输。对它们而言，吞吐量（BPS）、连接数以及延迟，就是最重要的性能指标。你可以用 iperf 或 netperf ，来测试传输层的性能。\n不过要注意，网络包的大小，会直接影响这些指标的值。所以，通常，你需要测试一系列不同大小网络包的性能。\n最后，再往上到了应用层，最需要关注的是吞吐量（BPS）、每秒请求数以及延迟等指标。你可以用 wrk、ab 等工具，来测试应用程序的性能。\n网络性能工具 第一个维度，从网络性能指标出发，你更容易把性能工具同系统工作原理关联起来，对性能问题有宏观的认识和把握。这样，当你想查看某个性能指标时，就能清楚知道，可以用哪些工具。\n第二个维度，从性能工具出发。这可以让你更快上手使用工具，迅速找出想要观察的性能指标。特别是在工具有限的情况下，我们更要充分利用好手头的每一个工具，用少量工具也要尽力挖掘出大量信息。\n网络性能优化 先要获得网络基准测试报告，然后通过相关性能工具，定位出网络性能瓶颈。再接下来的优化工作，就是水到渠成的事情了。\n可以从应用程序、套接字、传输层、网络层以及链路层等几个角度，分别来看网络性能优化的基本思路。\n应用程序 应用程序的优化，主要就是对网络 I/O 和进程自身的工作模型的优化。\n从网络 I/O 的角度来说，主要有下面两种优化思路。\n第一种是最常用的 I/O 多路复用技术 epoll，主要用来取代 select 和 poll。这其实是解决 C10K 问题的关键，也是目前很多网络应用默认使用的机制。 第二种是使用异步 I/O（Asynchronous I/O，AIO）。AIO 允许应用程序同时发起很多 I/O 操作，而不用等待这些操作完成。等到 I/O 完成后，系统会用事件通知的方式，告诉应用程序结果。不过，AIO 的使用比较复杂，你需要小心处理很多边缘情况。 而从进程的工作模型来说，也有两种不同的模型用来优化。\n第一种，主进程 + 多个 worker 子进程。其中，主进程负责管理网络连接，而子进程负责实际的业务处理。这也是最常用的一种模型。 第二种，监听到相同端口的多进程模型。在这种模型下，所有进程都会监听相同接口，并且开启 SO_REUSEPORT 选项，由内核负责，把请求负载均衡到这些监听进程中去。 除了网络 I/O 和进程的工作模型外，应用层的网络协议优化，也是至关重要的一点。我总结了常见的几种优化方法。\n使用长连接取代短连接，可以显著降低 TCP 建立连接的成本。在每秒请求次数较多时，这样做的效果非常明显。 使用内存等方式，来缓存不常变化的数据，可以降低网络 I/O 次数，同时加快应用程序的响应速度。 使用 Protocol Buffer 等序列化的方式，压缩网络 I/O 的数据量，可以提高应用程序的吞吐。 使用 DNS 缓存、预取、HTTPDNS 等方式，减少 DNS 解析的延迟，也可以提升网络 I/O 的整体速度。 套接字 套接字可以屏蔽掉 Linux 内核中不同协议的差异，为应用程序提供统一的访问接口。每个套接字，都有一个读写缓冲区。\n读缓冲区，缓存了远端发过来的数据。如果读缓冲区已满，就不能再接收新的数据。 写缓冲区，缓存了要发出去的数据。如果写缓冲区已满，应用程序的写操作就会被阻塞。 为了提高网络的吞吐量，你通常需要调整这些缓冲区的大小。比如：\n增大每个套接字的缓冲区大小 net.core.optmem_max； 增大套接字接收缓冲区大小 net.core.rmem_max 和发送缓冲区大小 net.core.wmem_max； 增大 TCP 接收缓冲区大小 net.ipv4.tcp_rmem 和发送缓冲区大小 net.ipv4.tcp_wmem。 几点需要注意:\ncp_rmem 和 tcp_wmem 的三个数值分别是 min，default，max，系统会根据这些设置，自动调整 TCP 接收 / 发送缓冲区的大小。 udp_mem 的三个数值分别是 min，pressure，max，系统会根据这些设置，自动调整 UDP 发送缓冲区的大小。 当然，表格中的数值只提供参考价值，具体应该设置多少，还需要你根据实际的网络状况来确定。比如，发送缓冲区大小，理想数值是吞吐量 * 延迟，这样才可以达到最大网络利用率。\n除此之外，套接字接口还提供了一些配置选项，用来修改网络连接的行为：\n为 TCP 连接设置 TCP_NODELAY 后，就可以禁用 Nagle 算法； 为 TCP 连接开启 TCP_CORK 后，可以让小包聚合成大包后再发送（注意会阻塞小包的发送）； 使用 SO_SNDBUF 和 SO_RCVBUF ，可以分别调整套接字发送缓冲区和接收缓冲区的大小。 小结 在应用程序中，主要优化 I/O 模型、工作模型以及应用层的网络协议； 在套接字层中，主要优化套接字的缓冲区大小。\n","description":"NAT 基于 Linux 内核的连接跟踪机制，实现了 IP 地址及端口号重写的功能，主要被用来解决公网 IP 地址短缺的问题。\n在分析 NAT 性能问题时，可以先从内核连接跟踪模块 conntrack 角度来分析，比如用 systemtap、perf、netstat 等工具，以及 proc 文件系统中的内核选项，来分析网络协议栈的行为；然后，通过内核选项调优、切换到无状态 NAT、使用 DPDK 等方式，进行实际优化。"},{"id":54,"href":"/post/44%E5%A5%97%E8%B7%AF%E7%AF%87%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%E4%B8%8B/","title":"44|套路篇：网络性能优化的几个思路（下）","parent":"Linux性能优化","content":" 网络性能优化 传输层 TCP 提供了面向连接的可靠传输服务。要优化 TCP，我们首先要掌握 TCP 协议的基本原理，比如流量控制、慢启动、拥塞避免、延迟确认以及状态流图（如下图所示）等。\n第一类，在请求数比较大的场景下，你可能会看到大量处于 TIME_WAIT 状态的连接，它们会占用大量内存和端口资源。这时，我们可以优化与 TIME_WAIT 状态相关的内核选项，比如采取下面几种措施。\n增大处于 TIME_WAIT 状态的连接数量 net.ipv4.tcp_max_tw_buckets ，并增大连接跟踪表的大小 net.netfilter.nf_conntrack_max。 减小 net.ipv4.tcp_fin_timeout 和 net.netfilter.nf_conntrack_tcp_timeout_time_wait ，让系统尽快释放它们所占用的资源。开启端口复用 net.ipv4.tcp_tw_reuse。这样，被 TIME_WAIT 状态占用的端口，还能用到新建的连接中。 增大本地端口的范围 net.ipv4.ip_local_port_range 。这样就可以支持更多连接，提高整体的并发能力。 增加最大文件描述符的数量。你可以使用 fs.nr_open 和 fs.file-max ，分别增大进程和系统的最大文件描述符数；或在应用程序的 systemd 配置文件中，配置 LimitNOFILE ，设置应用程序的最大文件描述符数。 第二类，为了缓解 SYN FLOOD 等，利用 TCP 协议特点进行攻击而引发的性能问题，你可以考虑优化与 SYN 状态相关的内核选项，比如采取下面几种措施。\n增大 TCP 半连接的最大数量 net.ipv4.tcp_max_syn_backlog ，或者开启 TCP SYN Cookies net.ipv4.tcp_syncookies ，来绕开半连接数量限制的问题（注意，这两个选项不可同时使用）。 减少 SYN_RECV 状态的连接重传 SYN+ACK 包的次数 net.ipv4.tcp_synack_retries。 第三类，在长连接的场景中，通常使用 Keepalive 来检测 TCP 连接的状态，以便对端连接断开后，可以自动回收。但是，系统默认的 Keepalive 探测间隔和重试次数，一般都无法满足应用程序的性能要求。所以，这时候你需要优化与 Keepalive 相关的内核选项，比如：\n缩短最后一次数据包到 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_time； 缩短发送 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_intvl； 减少 Keepalive 探测失败后，一直到通知应用程序前的重试次数 net.ipv4.tcp_keepalive_probes。 UDP 提供了面向数据报的网络协议，它不需要网络连接，也不提供可靠性保障。所以，UDP 优化，相对于 TCP 来说，要简单得多。这里我也总结了常见的几种优化方案。\n跟上篇套接字部分提到的一样，增大套接字缓冲区大小以及 UDP 缓冲区范围； 跟前面 TCP 部分提到的一样，增大本地端口号的范围； 根据 MTU 大小，调整 UDP 数据包的大小，减少或者避免分片的发生。 网络层 网络层，负责网络包的封装、寻址和路由，包括 IP、ICMP 等常见协议。在网络层，最主要的优化，其实就是对路由、 IP 分片以及 ICMP 等进行调优。\n第一种，从路由和转发的角度出发，你可以调整下面的内核选项。\n在需要转发的服务器中，比如用作 NAT 网关的服务器或者使用 Docker 容器时，开启 IP 转发，即设置 net.ipv4.ip_forward = 1。 调整数据包的生存周期 TTL，比如设置 net.ipv4.ip_default_ttl = 64。注意，增大该值会降低系统性能。 开启数据包的反向地址校验，比如设置 net.ipv4.conf.eth0.rp_filter = 1。这样可以防止 IP 欺骗，并减少伪造 IP 带来的 DDoS 问题。 第二种，从分片的角度出发，最主要的是调整 MTU（Maximum Transmission Unit）的大小。\n通常，MTU 的大小应该根据以太网的标准来设置。以太网标准规定，一个网络帧最大为 1518B，那么去掉以太网头部的 18B 后，剩余的 1500 就是以太网 MTU 的大小。在使用 VXLAN、GRE 等叠加网络技术时，要注意，网络叠加会使原来的网络包变大，导致 MTU 也需要调整。比如，就以 VXLAN 为例，它在原来报文的基础上，增加了 14B 的以太网头部、 8B 的 VXLAN 头部、8B 的 UDP 头部以及 20B 的 IP 头部。换句话说，每个包比原来增大了 50B。所以，我们就需要把交换机、路由器等的 MTU，增大到 1550， 或者把 VXLAN 封包前（比如虚拟化环境中的虚拟网卡）的 MTU 减小为 1450。另外，现在很多网络设备都支持巨帧，如果是这种环境，你还可以把 MTU 调大为 9000，以提高网络吞吐量。\n第三种，从 ICMP 的角度出发，为了避免 ICMP 主机探测、ICMP Flood 等各种网络问题，你可以通过内核选项，来限制 ICMP 的行为。比如，\n你可以禁止 ICMP 协议，即设置 net.ipv4.icmp_echo_ignore_all = 1。这样，外部主机就无法通过 ICMP 来探测主机。 或者，你还可以禁止广播 ICMP，即设置 net.ipv4.icmp_echo_ignore_broadcasts = 1。 链路层 链路层负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。自然，链路层的优化，也是围绕这些基本功能进行的。接下来，我们从不同的几个方面分别来看。\n由于网卡收包后调用的中断处理程序（特别是软中断），需要消耗大量的 CPU。所以，将这些中断处理程序调度到不同的 CPU 上执行，就可以显著提高网络吞吐量。这通常可以采用下面两种方法。\n比如，你可以为网卡硬中断配置 CPU 亲和性（smp_affinity），或者开启 irqbalance 服务。 再如，你可以开启 RPS（Receive Packet Steering）和 RFS（Receive Flow Steering），将应用程序和软中断的处理，调度到相同 CPU 上，这样就可以增加 CPU 缓存命中率，减少网络延迟。 现在的网卡都有很丰富的功能，原来在内核中通过软件处理的功能，可以卸载到网卡中，通过硬件来执行。\nTSO（TCP Segmentation Offload）和 UFO（UDP Fragmentation Offload）：在 TCP/UDP 协议中直接发送大包；而 TCP 包的分段（按照 MSS 分段）和 UDP 的分片（按照 MTU 分片）功能，由网卡来完成 。 GSO（Generic Segmentation Offload）：在网卡不支持 TSO/UFO 时，将 TCP/UDP 包的分段，延迟到进入网卡前再执行。这样，不仅可以减少 CPU 的消耗，还可以在发生丢包时只重传分段后的包。 LRO（Large Receive Offload）：在接收 TCP 分段包时，由网卡将其组装合并后，再交给上层网络处理。不过要注意，在需要 IP 转发的情况下，不能开启 LRO，因为如果多个包的头部信息不一致，LRO 合并会导致网络包的校验错误。 GRO（Generic Receive Offload）：GRO 修复了 LRO 的缺陷，并且更为通用，同时支持 TCP 和 UDP。 RSS（Receive Side Scaling）：也称为多队列接收，它基于硬件的多个接收队列，来分配网络接收进程，这样可以让多个 CPU 来处理接收到的网络包。 VXLAN 卸载：也就是让网卡来完成 VXLAN 的组包功能。 对于网络接口本身，也有很多方法，可以优化网络的吞吐量。比如，\n你可以开启网络接口的多队列功能。这样，每个队列就可以用不同的中断号，调度到不同 CPU 上执行，从而提升网络的吞吐量。 再如，你可以增大网络接口的缓冲区大小，以及队列长度等，提升网络传输的吞吐量（注意，这可能导致延迟增大）。 你还可以使用 Traffic Control 工具，为不同网络流量配置 QoS。 小结 我们分析和定位网络瓶颈，也是基于这些网络层进行的。而定位出网络性能瓶颈后，我们就可以根据瓶颈所在的协议层，进行优化。具体而言：\n在应用程序中，主要是优化 I/O 模型、工作模型以及应用层的网络协议； 在套接字层中，主要是优化套接字的缓冲区大小； 在传输层中，主要是优化 TCP 和 UDP 协议； 在网络层中，主要是优化路由、转发、分片以及 ICMP 协议； 最后，在链路层中，主要是优化网络包的收发、网络功能卸载以及网卡选项。 ","description":"网络性能优化 传输层 TCP 提供了面向连接的可靠传输服务。要优化 TCP，我们首先要掌握 TCP 协议的基本原理，比如流量控制、慢启动、拥塞避免、延迟确认以及状态流图（如下图所示）等。\n第一类，在请求数比较大的场景下，你可能会看到大量处于 TIME_WAIT 状态的连接，它们会占用大量内存和端口资源。这时，我们可以优化与 TIME_WAIT 状态相关的内核选项，比如采取下面几种措施。"},{"id":55,"href":"/post/45%E7%AD%94%E7%96%91%E4%BA%94%E7%BD%91%E7%BB%9C%E6%94%B6%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%BC%93%E5%86%B2%E5%8C%BA%E4%BD%8D%E7%BD%AE%E5%9C%A8%E5%93%AA%E9%87%8C/","title":"45|答疑（五）：网络收发过程中，缓冲区位置在哪里？","parent":"Linux性能优化","content":" 问题 1：网络收发过程中缓冲区的位置 第一点，是网络收发过程中，收发队列和缓冲区位置的疑问。\n网卡收发网络包时，通过 DMA 方式交互的环形缓冲区； 网卡中断处理程序为网络帧分配的，内核数据结构 sk_buff 缓冲区； 应用程序通过套接字接口，与网络协议栈交互时的套接字缓冲区。 其中，环形缓冲区，由于需要 DMA 与网卡交互，理应属于网卡设备驱动的范围。\nsk_buff 缓冲区，是一个维护网络帧结构的双向链表，链表中的每一个元素都是一个网络帧（Packet）。虽然 TCP/IP 协议栈分了好几层，但上下不同层之间的传递，实际上只需要操作这个数据结构中的指针，而无需进行数据复制。\n套接字缓冲区，则允许应用程序，给每个套接字配置不同大小的接收或发送缓冲区。应用程序发送数据，实际上就是将数据写入缓冲区；而接收数据，其实就是从缓冲区中读取。至于缓冲区中数据的进一步处理，则由传输层的 TCP 或 UDP 协议来完成。\n问题 2：内核协议栈，是通过一个内核线程的方式来运行的吗 说到网络收发，在中断处理文章中我曾讲过，其中的软中断处理，就有专门的内核线程 ksoftirqd。每个 CPU 都会绑定一个 ksoftirqd 内核线程，比如， 2 个 CPU 时，就会有 ksoftirqd/0 和 ksoftirqd/1 这两个内核线程。不过要注意，并非所有网络功能，都在软中断内核线程中处理。内核中还有很多其他机制（比如硬中断、kworker、slab 等），这些机制一起协同工作，才能保证整个网络协议栈的正常运行。关于内核中网络协议栈的工作原理，以及如何动态跟踪内核的执行流程，专栏后续还有专门的文章来讲。如果对这部分感兴趣，你可以先用我们提到过的 perf、systemtap、bcc-tools 等，试着来分析一下。\n问题 3：最大连接数是不是受限于 65535 个端口 无论 TCP 还是 UDP，端口号都只占 16 位，也就说其最大值也只有 65535。那是不是说，如果使用 TCP 协议，在单台机器、单个 IP 地址时，并发连接数最大也只有 65535 呢？\n对于这个问题，首先你要知道，Linux 协议栈，通过五元组来标志一个连接（即协议，源 IP、源端口、目的 IP、目的端口)。\n对客户端来说，每次发起 TCP 连接请求时，都需要分配一个空闲的本地端口，去连接远端的服务器。由于这个本地端口是独占的，所以客户端最多只能发起 65535 个连接。\n对服务器端来说，其通常监听在固定端口上（比如 80 端口），等待客户端的连接。根据五元组结构，我们知道，客户端的 IP 和端口都是可变的。如果不考虑 IP 地址分类以及资源限制，服务器端的理论最大连接数，可以达到 2 的 48 次方（IP 为 32 位，端口号为 16 位），远大于 65535。\n综合来看，客户端最大支持 65535 个连接，而服务器端可支持的连接数是海量的。当然，由于 Linux 协议栈本身的性能，以及各种物理和软件的资源限制等，这么大的连接数，还是远远达不到的（实际上，C10M 就已经很难了）。\n问题 4： “如何优化 NAT 性能”课后思考 ","description":"问题 1：网络收发过程中缓冲区的位置 第一点，是网络收发过程中，收发队列和缓冲区位置的疑问。\n网卡收发网络包时，通过 DMA 方式交互的环形缓冲区； 网卡中断处理程序为网络帧分配的，内核数据结构 sk_buff 缓冲区； 应用程序通过套接字接口，与网络协议栈交互时的套接字缓冲区。 其中，环形缓冲区，由于需要 DMA 与网卡交互，理应属于网卡设备驱动的范围。"},{"id":56,"href":"/post/46%E6%A1%88%E4%BE%8B%E7%AF%87%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8%E5%8C%96%E5%90%8E%E5%90%AF%E5%8A%A8%E6%85%A2%E4%BA%86%E5%BE%88%E5%A4%9A/","title":"46|案例篇：为什么应用容器化后，启动慢了很多？","parent":"Linux性能优化","content":"随着 Kubernetes、Docker 等技术的普及，越来越多的企业，都已经走上了应用程序容器化的道路。我相信，你在了解学习这些技术的同时，一定也听说过不少，基于 Docker 的微服务架构带来的各种优势，比如：\n使用 Docker ，把应用程序以及相关依赖打包到镜像中后，部署和升级更快捷； 把传统的单体应用拆分成多个更小的微服务应用后，每个微服务的功能都更简单，并且可以单独管理和维护； 每个微服务都可以根据需求横向扩展。即使发生故障，也只是局部服务不可用，而不像以前那样，导致整个服务不可用。 案例 docker 启动 Tomat 应用：\n# -m表示设置内存为512MB $ docker run --name tomcat --cpus 0.1 -m 512M -p 8080:8080 -itd feisky/tomcat:8 Unable to find image \u0026#39;feisky/tomcat:8\u0026#39; locally 8: Pulling from feisky/tomcat 741437d97401: Pull complete ... 22cd96a25579: Pull complete Digest: sha256:71871cff17b9043842c2ec99f370cc9f1de7bc121cd2c02d8e2092c6e268f7e2 Status: Downloaded newer image for feisky/tomcat:8 WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap. 2df259b752db334d96da26f19166d662a82283057411f6332f3cbdbcab452249 docker pull 命令，下载镜像：\n$ docker pull feisky/tomcat:8 8: Pulling from feisky/tomcat Digest: sha256:71871cff17b9043842c2ec99f370cc9f1de7bc121cd2c02d8e2092c6e268f7e2 Status: Image is up to date for feisky/tomcat:8 访问 Tomcat 监听的 8080 端口，确认案例已经正常启动：\n$ curl localhost:8080 curl: (56) Recv failure: Connection reset by peer 执行 docker logs 命令，查看容器的日志。这里注意，需要加上 -f 参数，表示跟踪容器的最新日志输出：\n$ docker logs -f tomcat Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /docker-java-home/jre Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar 执行下面的命令，查看容器的状态：\n$ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0f2b3fcdd257 feisky/tomcat:8 \u0026#34;catalina.sh run\u0026#34; 2 minutes ago Exited (137) About a minute ago tomcat 可以调用 Docker 的 API，查询容器的状态、退出码以及错误信息，然后确定容器退出的原因。这些可以通过 docker inspect 命令来完成，比如，你可以继续执行下面的命令，通过 -f 选项设置只输出容器的状态：\n# 显示容器状态，jq用来格式化json输出 $ docker inspect tomcat -f \u0026#39;{{json .State}}\u0026#39; | jq { \u0026#34;Status\u0026#34;: \u0026#34;exited\u0026#34;, \u0026#34;Running\u0026#34;: false, \u0026#34;Paused\u0026#34;: false, \u0026#34;Restarting\u0026#34;: false, \u0026#34;OOMKilled\u0026#34;: true, \u0026#34;Dead\u0026#34;: false, \u0026#34;Pid\u0026#34;: 0, \u0026#34;ExitCode\u0026#34;: 137, \u0026#34;Error\u0026#34;: \u0026#34;\u0026#34;, ... } 执行下面的命令，重新启动 tomcat 容器，并调用 java 命令行来查看堆内存大小：\n# 重新启动容器 $ docker rm -f tomcat $ docker run --name tomcat --cpus 0.1 -m 512M -p 8080:8080 -itd feisky/tomcat:8 # 查看堆内存，注意单位是字节 $ docker exec tomcat java -XX:+PrintFlagsFinal -version | grep HeapSize uintx ErgoHeapSizeLimit = 0 {product} uintx HeapSizePerGCThread = 87241520 {product} uintx InitialHeapSize := 132120576 {product} uintx LargePageHeapSizeThreshold = 134217728 {product} uintx MaxHeapSize := 2092957696 {product} 小结 容器本身通过 cgroups 进行资源隔离，所以，在分析时要考虑 cgroups 对应用程序的影响。 容器的文件系统、网络协议栈等跟主机隔离。虽然在容器外面，我们也可以分析容器的行为，不过有时候，进入容器的命名空间内部，可能更为方便。 容器的运行可能还会依赖于其他组件，比如各种网络插件（比如 CNI）、存储插件（比如 CSI）、设备插件（比如 GPU）等，让容器的性能分析更加复杂。如果你需要分析容器性能，别忘了考虑它们对性能的影响。 ","description":"随着 Kubernetes、Docker 等技术的普及，越来越多的企业，都已经走上了应用程序容器化的道路。我相信，你在了解学习这些技术的同时，一定也听说过不少，基于 Docker 的微服务架构带来的各种优势，比如：\n使用 Docker ，把应用程序以及相关依赖打包到镜像中后，部署和升级更快捷； 把传统的单体应用拆分成多个更小的微服务应用后，每个微服务的功能都更简单，并且可以单独管理和维护； 每个微服务都可以根据需求横向扩展。即使发生故障，也只是局部服务不可用，而不像以前那样，导致整个服务不可用。 案例 docker 启动 Tomat 应用："},{"id":57,"href":"/post/47%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%BB%E6%98%AF%E6%97%B6%E4%B8%8D%E6%97%B6%E4%B8%A2%E5%8C%85%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8A/","title":"47|案例篇：服务器总是时不时丢包，我该怎么办？（上）","parent":"Linux性能优化","content":"执行 docker ps 命令，查询容器的状态：\n$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dae0202cc27e feisky/nginx:drop \u0026#34;/start.sh\u0026#34; 4 minutes ago Up 4 minutes 0.0.0.0:80-\u0026gt;80/tcp nginx 执行下面的 hping3 命令，进一步验证 Nginx 是不是真的可以正常访问了。注意，这里我没有使用 ping，是因为 ping 基于 ICMP 协议，而 Nginx 使用的是 TCP 协议。\n# -c表示发送10个请求，-S表示使用TCP SYN，-p指定端口为80 $ hping3 -c 10 -S -p 80 192.168.0.30 HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=3 win=5120 rtt=7.5 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=4 win=5120 rtt=7.4 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=5 win=5120 rtt=3.3 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=7 win=5120 rtt=3.0 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=6 win=5120 rtt=3027.2 ms --- 192.168.0.30 hping statistic --- 10 packets transmitted, 5 packets received, 50% packet loss round-trip min/avg/max = 3.0/609.7/3027.2 ms 从 hping3 的输出中，我们可以发现，发送了 10 个请求包，却只收到了 5 个回复，50% 的包都丢了。再观察每个请求的 RTT 可以发现，RTT 也有非常大的波动变化，小的时候只有 3ms，而大的时候则有 3s。根据这些输出，我们基本能判断，已经发生了丢包现象。可以猜测，3s 的 RTT ，很可能是因为丢包后重传导致的。那到底是哪里发生了丢包呢？\n从图中你可以看出，可能发生丢包的位置，实际上贯穿了整个网络协议栈。换句话说，全程都有丢包的可能。比如我们从下往上看：\n在两台 VM 连接之间，可能会发生传输失败的错误，比如网络拥塞、线路错误等； 在网卡收包后，环形缓冲区可能会因为溢出而丢包； 在链路层，可能会因为网络帧校验失败、QoS 等而丢包； 在 IP 层，可能会因为路由失败、组包大小超过 MTU 等而丢包； 在传输层，可能会因为端口未监听、资源占用超过内核限制等而丢包； 在套接字层，可能会因为套接字缓冲区溢出而丢包； 在应用层，可能会因为应用程序异常而丢包； 此外，如果配置了 iptables 规则，这些网络包也可能因为 iptables 过滤规则而丢包。 执行下面的命令，进入容器的终端中：\n$ docker exec -it nginx bash root@nginx:/# 链路层 首先，来看最底下的链路层。当缓冲区溢出等原因导致网卡丢包时，Linux 会在网卡收发数据的统计信息中，记录下收发错误的次数。\n可以通过 ethtool 或者 netstat ，来查看网卡的丢包记录。比如，可以在容器中执行下面的命令，查看丢包情况：\nroot@nginx:/# netstat -i Kernel Interface table Iface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 100 31 0 0 0 8 0 0 0 BMRU lo 65536 0 0 0 0 0 0 0 0 LRU 输出中的 RX-OK、RX-ERR、RX-DRP、RX-OVR ，分别表示接收时的总包数、总错误数、进入 Ring Buffer 后因其他原因（如内存不足）导致的丢包数以及 Ring Buffer 溢出导致的丢包数。 TX-OK、TX-ERR、TX-DRP、TX-OVR 也代表类似的含义，只不过是指发送时对应的各个指标。\n注意，由于 Docker 容器的虚拟网卡，实际上是一对 veth pair，一端接入容器中用作 eth0，另一端在主机中接入 docker0 网桥中。veth 驱动并没有实现网络统计的功能，所以使用 ethtool -S 命令，无法得到网卡收发数据的汇总信息。\n容器终端中，执行下面的 tc 命令，不过这次注意添加 -s 选项，以输出统计信息：\nroot@nginx:/# tc -s qdisc show dev eth0 qdisc netem 800d: root refcnt 2 limit 1000 loss 30% Sent 432 bytes 8 pkt (dropped 4, overlimits 0 requeues 0) backlog 0b 0p requeues 0 网络层和传输层 在网络层和传输层中，引发丢包的因素非常多。不过，其实想确认是否丢包，是非常简单的事，因为 Linux 已经为我们提供了各个协议的收发汇总情况。\n执行下面的 netstat -s 命令，就可以看到协议的收发汇总，以及错误信息了：\nroot@nginx:/# netstat -s Ip: Forwarding: 1 //开启转发 31 total packets received //总收包数 0 forwarded //转发包数 0 incoming packets discarded //接收丢包数 25 incoming packets delivered //接收的数据包数 15 requests sent out //发出的数据包数 Icmp: 0 ICMP messages received //收到的ICMP包数 0 input ICMP message failed //收到ICMP失败数 ICMP input histogram: 0 ICMP messages sent //ICMP发送数 0 ICMP messages failed //ICMP失败数 ICMP output histogram: Tcp: 0 active connection openings //主动连接数 0 passive connection openings //被动连接数 11 failed connection attempts //失败连接尝试数 0 connection resets received //接收的连接重置数 0 connections established //建立连接数 25 segments received //已接收报文数 21 segments sent out //已发送报文数 4 segments retransmitted //重传报文数 0 bad segments received //错误报文数 0 resets sent //发出的连接重置数 Udp: 0 packets received ... TcpExt: 11 resets received for embryonic SYN_RECV sockets //半连接重置数 0 packet headers predicted TCPTimeouts: 7 //超时数 TCPSynRetrans: 4 //SYN重传数 ... netstat 汇总了 IP、ICMP、TCP、UDP 等各种协议的收发统计信息。不过，我们的目的是排查丢包问题，所以这里主要观察的是错误数、丢包数以及重传数。\n根据上面的输出，你可以看到，只有 TCP 协议发生了丢包和重传，分别是：\n11 次连接失败重试（11 failed connection attempts） 4 次重传（4 segments retransmitted） 11 次半连接重置（11 resets received for embryonic SYN_RECV sockets） 4 次 SYN 重传（TCPSynRetrans） 7 次超时（TCPTimeouts） 这个结果告诉我们，TCP 协议有多次超时和失败重试，并且主要错误是半连接重置。换句话说，主要的失败，都是三次握手失败。\n小结 网络丢包，通常会带来严重的性能下降，特别是对 TCP 来说，丢包通常意味着网络拥塞和重传，进一步还会导致网络延迟增大、吞吐降低。\n","description":"执行 docker ps 命令，查询容器的状态：\n$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dae0202cc27e feisky/nginx:drop \u0026#34;/start."},{"id":58,"href":"/post/48%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%BB%E6%98%AF%E6%97%B6%E4%B8%8D%E6%97%B6%E4%B8%A2%E5%8C%85%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E4%B8%8B/","title":"48|案例篇：服务器总是时不时丢包，我该怎么办？（下）","parent":"Linux性能优化","content":" iptables 更简单的方法，就是直接查询 DROP 和 REJECT 等规则的统计信息，看看是否为 0。如果统计值不是 0 ，再把相关的规则拎出来进行分析。\n可以通过 iptables -nvL 命令，查看各条规则的统计信息。比如，你可以执行下面的 docker exec 命令，进入容器终端；然后再执行下面的 iptables 命令，就可以看到 filter 表的统计数据了：\n# 在主机中执行 $ docker exec -it nginx bash # 在容器中执行 root@nginx:/# iptables -t filter -nvL Chain INPUT (policy ACCEPT 25 packets, 1000 bytes) pkts bytes target prot opt in out source destination 6 240 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 statistic mode random probability 0.29999999981 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 15 packets, 660 bytes) pkts bytes target prot opt in out source destination 6 264 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 statistic mode random probability 0.29999999981 从 iptables 的输出中，你可以看到，两条 DROP 规则的统计数值不是 0，它们分别在 INPUT 和 OUTPUT 链中。这两条规则实际上是一样的，指的是使用 statistic 模块，进行随机 30% 的丢包。\ntcpdump 在容器终端中，执行下面的 tcpdump 命令，抓取 80 端口的包：\nroot@nginx:/# tcpdump -i eth0 -nn port 80 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 切换到终端二中，再次执行前面的 curl 命令：\n$ curl --max-time 3 http://192.168.0.30/ curl: (28) Operation timed out after 3000 milliseconds with 0 bytes received 等到 curl 命令结束后，再次切换回终端一，查看 tcpdump 的输出：\n14:40:00.589235 IP 10.255.255.5.39058 \u0026gt; 172.17.0.2.80: Flags [S], seq 332257715, win 29200, options [mss 1418,sackOK,TS val 486800541 ecr 0,nop,wscale 7], length 0 14:40:00.589277 IP 172.17.0.2.80 \u0026gt; 10.255.255.5.39058: Flags [S.], seq 1630206251, ack 332257716, win 4880, options [mss 256,sackOK,TS val 2509376001 ecr 486800541,nop,wscale 7], length 0 14:40:00.589894 IP 10.255.255.5.39058 \u0026gt; 172.17.0.2.80: Flags [.], ack 1, win 229, options [nop,nop,TS val 486800541 ecr 2509376001], length 0 14:40:03.589352 IP 10.255.255.5.39058 \u0026gt; 172.17.0.2.80: Flags [F.], seq 76, ack 1, win 229, options [nop,nop,TS val 486803541 ecr 2509376001], length 0 14:40:03.589417 IP 172.17.0.2.80 \u0026gt; 10.255.255.5.39058: Flags [.], ack 1, win 40, options [nop,nop,TS val 2509379001 ecr 486800541,nop,nop,sack 1 {76:77}], length 0 从 tcpdump 的输出中，我们就可以看到：\n前三个包是正常的 TCP 三次握手，这没问题； 但第四个包却是在 3 秒以后了，并且还是客户端（VM2）发送过来的 FIN 包，也就说明，客户端的连接关闭了。 根据 curl 设置的 3 秒超时选项，你应该能猜到，这是因为 curl 命令超时后退出了。\nhping3 实际上只发送了 SYN 包； 而 curl 在发送 SYN 包后，还会发送 HTTP GET 请求。 HTTP GET ，本质上也是一个 TCP 包，但跟 SYN 包相比，它还携带了 HTTP GET 的数据。\nMTU 问题是很好解决的，把它改成 1500 就可以了。我们继续在容器终端中，执行下面的命令，把容器 eth0 的 MTU 改成 1500：\nroot@nginx:/# ifconfig eth0 mtu 1500 ","description":"iptables 更简单的方法，就是直接查询 DROP 和 REJECT 等规则的统计信息，看看是否为 0。如果统计值不是 0 ，再把相关的规则拎出来进行分析。"},{"id":59,"href":"/post/49%E6%A1%88%E4%BE%8B%E7%AF%87%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B-CPU-%E5%88%A9%E7%94%A8%E7%8E%87%E5%A4%AA%E9%AB%98%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E/","title":"49|案例篇：内核线程 CPU 利用率太高，我该怎么办？","parent":"Linux性能优化","content":" 内核线程 在 Linux 中，用户态进程的“祖先”，都是 PID 号为 1 的 init 进程。比如，现在主流的 Linux 发行版中，init 都是 systemd 进程；而其他的用户态进程，会通过 systemd 来进行管理。\n实际上，Linux 在启动过程中，有三个特殊的进程，也就是 PID 号最小的三个进程。\n0 号进程为 idle 进程，这也是系统创建的第一个进程，它在初始化 1 号和 2 号进程后，演变为空闲任务。当 CPU 上没有其他任务执行时，就会运行它。 1 号进程为 init 进程，通常是 systemd 进程，在用户态运行，用来管理其他用户态进程。 2 号进程为 kthreadd 进程，在内核态运行，用来管理内核线程。 所以，要查找内核线程，我们只需要从 2 号进程开始，查找它的子孙进程即可。比如，你可以使用 ps 命令，来查找 kthreadd 的子进程：\n$ ps -f --ppid 2 -p 2 UID PID PPID C STIME TTY TIME CMD root 2 0 0 12:02 ? 00:00:01 [kthreadd] root 9 2 0 12:02 ? 00:00:21 [ksoftirqd/0] root 10 2 0 12:02 ? 00:11:47 [rcu_sched] root 11 2 0 12:02 ? 00:00:18 [migration/0] ... root 11094 2 0 14:20 ? 00:00:00 [kworker/1:0-eve] root 11647 2 0 14:27 ? 00:00:00 [kworker/0:2-cgr] 内核线程的名称（CMD）都在中括号里。所以，更简单的方法，就是直接查找名称包含中括号的进程。比如：\n$ ps -ef | grep \u0026#34;\\[.*\\]\u0026#34; root 2 0 0 08:14 ? 00:00:00 [kthreadd] root 3 2 0 08:14 ? 00:00:00 [rcu_gp] root 4 2 0 08:14 ? 00:00:00 [rcu_par_gp] ... 了解内核线程的基本功能，对我们排查问题有非常大的帮助。比如，我们曾经在软中断案例中提到过 ksoftirqd。它是一个用来处理软中断的内核线程，并且每个 CPU 上都有一个。\n如果你知道了这一点，那么，以后遇到 ksoftirqd 的 CPU 使用高的情况，就会首先怀疑是软中断的问题，然后从软中断的角度来进一步分析。\n其实，除了刚才看到的 kthreadd 和 ksoftirqd 外，还有很多常见的内核线程，我们在性能分析中都经常会碰到，比如下面这几个内核线程。\nkswapd0：用于内存回收。在 Swap 变高 案例中，我曾介绍过它的工作原理。 kworker：用于执行内核工作队列，分为绑定 CPU （名称格式为 kworker/CPU86330）和未绑定 CPU（名称格式为 kworker/uPOOL86330）两类。 migration：在负载均衡过程中，把进程迁移到 CPU 上。每个 CPU 都有一个 migration 内核线程。 jbd2/sda1-8：jbd 是 Journaling Block Device 的缩写，用来为文件系统提供日志功能，以保证数据的完整性；名称中的 sda1-8，表示磁盘分区名称和设备号。每个使用了 ext4 文件系统的磁盘分区，都会有一个 jbd2 内核线程。 pdflush：用于将内存中的脏页（被修改过，但还未写入磁盘的文件页）写入磁盘（已经在 3.10 中合并入了 kworker 中）。 这张图看起来像是跳动的火焰，因此也就被称为火焰图。要理解火焰图，我们最重要的是区分清楚横轴和纵轴的含义。\n横轴表示采样数和采样比例。一个函数占用的横轴越宽，就代表它的执行时间越长。同一层的多个函数，则是按照字母来排序。 纵轴表示调用栈，由下往上根据调用关系逐个展开。换句话说，上下相邻的两个函数中，下面的函数，是上面函数的父函数。这样，调用栈越深，纵轴就越高。 要注意图中的颜色，并没有特殊含义，只是用来区分不同的函数。\n火焰图是动态的矢量图格式，所以它还支持一些动态特性。比如，鼠标悬停到某个函数上时，就会自动显示这个函数的采样数和采样比例。而当你用鼠标点击函数时，火焰图就会把该层及其上的各层放大，方便你观察这些处于火焰图顶部的调用栈的细节。\n上面 mysql 火焰图的示例，就表示了 CPU 的繁忙情况，这种火焰图也被称为 on-CPU 火焰图。如果我们根据性能分析的目标来划分，火焰图可以分为下面这几种。\non-CPU 火焰图：表示 CPU 的繁忙情况，用在 CPU 使用率比较高的场景中。 off-CPU 火焰图：表示 CPU 等待 I/O、锁等各种资源的阻塞情况。 内存火焰图：表示内存的分配和释放情况。 热 / 冷火焰图：表示将 on-CPU 和 off-CPU 结合在一起综合展示。 差分火焰图：表示两个火焰图的差分情况，红色表示增长，蓝色表示衰减。差分火焰图常用来比较不同场景和不同时期的火焰图，以便分析系统变化前后对性能的影响情况。 火焰图分析 首先，我们需要生成火焰图。我们先下载几个能从 perf record 记录生成火焰图的工具，这些工具都放在 https://github.com/brendangregg/FlameGraph 上面。你可以执行下面的命令来下载：\n$ git clone https://github.com/brendangregg/FlameGraph $ cd FlameGraph 安装好工具后，要生成火焰图，其实主要需要三个步骤：\n执行 perf script ，将 perf record 的记录转换成可读的采样记录； 执行 stackcollapse-perf.pl 脚本，合并调用栈信息； 执行 flamegraph.pl 脚本，生成火焰图。 不过，在 Linux 中，我们可以使用管道，来简化这三个步骤的执行过程。假设刚才用 perf record 生成的文件路径为 /root/perf.data，执行下面的命令，你就可以直接生成火焰图：\n$ perf script -i /root/perf.data | ./stackcollapse-perf.pl --all | ./flamegraph.pl \u0026gt; ksoftirqd.svg 执行成功后，使用浏览器打开 ksoftirqd.svg ，你就可以看到生成的火焰图了。如下图所示：\n根据刚刚讲过的火焰图原理，这个图应该从下往上看，沿着调用栈中最宽的函数来分析执行次数最多的函数。这儿看到的结果，其实跟刚才的 perf report 类似，但直观了很多，中间这一团火，很明显就是最需要我们关注的地方。\n我们顺着调用栈由下往上看（顺着图中蓝色箭头），就可以得到跟刚才 perf report 中一样的结果：\n最开始，还是 net_rx_action 到 netif_receive_skb 处理网络收包； 然后， br_handle_frame 到 br_nf_pre_routing ，在网桥中接收并执行 netfilter 钩子函数； 再向上， br_pass_frame_up 到 netif_receive_skb ，从网桥转到其他网络设备又一次接收。 不过最后，到了 ip_forward 这里，已经看不清函数名称了。所以我们需要点击 ip_forward，展开最上面这一块调用栈：\n小结 从软中断 CPU 使用率的角度入手，用网络抓包的方法找出了瓶颈来源，确认是测试机器发送的大量 SYN 包导致的。而通过今天的 perf 和火焰图方法，我们进一步找出了软中断内核线程的热点函数，其实也就找出了潜在的瓶颈和优化方向。\n其实，如果遇到的是内核线程的资源使用异常，很多常用的进程级性能工具并不能帮上忙。这时，你就可以用内核自带的 perf 来观察它们的行为，找出热点函数，进一步定位性能瓶。当然，perf 产生的汇总报告并不够直观，所以我也推荐你用火焰图来协助排查。\n实际上，火焰图方法同样适用于普通进程。比如，在分析 Nginx、MySQL 等各种应用场景的性能问题时，火焰图也能帮你更快定位热点函数，找出潜在性能问题。\n","description":"内核线程 在 Linux 中，用户态进程的“祖先”，都是 PID 号为 1 的 init 进程。比如，现在主流的 Linux 发行版中，init 都是 systemd 进程；而其他的用户态进程，会通过 systemd 来进行管理。"},{"id":60,"href":"/post/50%E6%A1%88%E4%BE%8B%E7%AF%87%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%E6%80%8E%E4%B9%88%E7%94%A8%E4%B8%8A/","title":"50|案例篇：动态追踪怎么用？（上）","parent":"Linux性能优化","content":"动态追踪技术，通过探针机制，来采集内核或者应用程序的运行信息，从而可以不用修改内核和应用程序的代码，就获得丰富的信息，帮你分析、定位想要排查的问题。\n以往，在排查和调试性能问题时，我们往往需要先为应用程序设置一系列的断点（比如使用 GDB），然后以手动或者脚本（比如 GDB 的 Python 扩展）的方式，在这些断点处分析应用程序的状态。或者，增加一系列的日志，从日志中寻找线索。\n相比以往的进程级跟踪方法（比如 ptrace），动态追踪往往只会带来很小的性能损耗（通常在 5% 或者更少）。\n动态追踪 说到动态追踪（Dynamic Tracing），就不得不提源于 Solaris 系统的 DTrace。DTrace 是动态追踪技术的鼻祖，它提供了一个通用的观测框架，并可以使用 D 语言进行自由扩展。\nDTrace 的工作原理如下图所示。它的运行常驻在内核中，用户可以通过 dtrace 命令，把 D 语言编写的追踪脚本，提交到内核中的运行时来执行。DTrace 可以跟踪用户态和内核态的所有事件，并通过一些列的优化措施，保证最小的性能开销。\n虽然直到今天，DTrace 本身依然无法在 Linux 中运行，但它同样对 Linux 动态追踪产生了巨大的影响。很多工程师都尝试过把 DTrace 移植到 Linux 中，这其中，最著名的就是 RedHat 主推的 SystemTap。\n同 DTrace 一样，SystemTap 也定义了一种类似的脚本语言，方便用户根据需要自由扩展。不过，不同于 DTrace，SystemTap 并没有常驻内核的运行时，它需要先把脚本编译为内核模块，然后再插入到内核中执行。这也导致 SystemTap 启动比较缓慢，并且依赖于完整的调试符号表。\n总的来说，为了追踪内核或用户空间的事件，Dtrace 和 SystemTap 都会把用户传入的追踪处理函数（一般称为 Action），关联到被称为探针的检测点上。这些探针，实际上也就是各种动态追踪技术所依赖的事件源。\n动态追踪的事件源 根据事件类型的不同，动态追踪所使用的事件源，可以分为静态探针、动态探针以及硬件事件等三类。它们的关系如下图所示：\n其中，硬件事件通常由性能监控计数器 PMC（Performance Monitoring Counter）产生，包括了各种硬件的性能情况，比如 CPU 的缓存、指令周期、分支预测等等。\n静态探针，是指事先在代码中定义好，并编译到应用程序或者内核中的探针。这些探针只有在开启探测功能时，才会被执行到；未开启时并不会执行。常见的静态探针包括内核中的跟踪点（tracepoints）和 USDT（Userland Statically Defined Tracing）探针。\n跟踪点（tracepoints），实际上就是在源码中插入的一些带有控制条件的探测点，这些探测点允许事后再添加处理函数。比如在内核中，最常见的静态跟踪方法就是 printk，即输出日志。Linux 内核定义了大量的跟踪点，可以通过内核编译选项，来开启或者关闭。 USDT 探针，全称是用户级静态定义跟踪，需要在源码中插入 DTRACE_PROBE() 代码，并编译到应用程序中。不过，也有很多应用程序内置了 USDT 探针，比如 MySQL、PostgreSQL 等。 动态探针，则是指没有事先在代码中定义，但却可以在运行时动态添加的探针，比如函数的调用和返回等。动态探针支持按需在内核或者应用程序中添加探测点，具有更高的灵活性。常见的动态探针有两种，即用于内核态的 kprobes 和用于用户态的 uprobes。\nkprobes 用来跟踪内核态的函数，包括用于函数调用的 kprobe 和用于函数返回的 kretprobe。 uprobes 用来跟踪用户态的函数，包括用于函数调用的 uprobe 和用于函数返回的 uretprobe。 注意，kprobes 需要内核编译时开启 CONFIG_KPROBE_EVENTS；而 uprobes 则需要内核编译时开启 CONFIG_UPROBE_EVENTS。\n动态追踪机制 ftrace 最早用于函数跟踪，后来又扩展支持了各种事件跟踪功能。ftrace 的使用接口跟我们之前提到的 procfs 类似，它通过 debugfs（4.1 以后也支持 tracefs），以普通文件的形式，向用户空间提供访问接口。\n这样，不需要额外的工具，你就可以通过挂载点（通常为 /sys/kernel/debug/tracing 目录）内的文件读写，来跟 ftrace 交互，跟踪内核或者应用程序的运行事件。\nperf 是我们的老朋友了，我们在前面的好多案例中，都使用了它的事件记录和分析功能，这实际上只是一种最简单的静态跟踪机制。你也可以通过 perf ，来自定义动态事件（perf probe），只关注真正感兴趣的事件。\neBPF 则在 BPF（Berkeley Packet Filter）的基础上扩展而来，不仅支持事件跟踪机制，还可以通过自定义的 BPF 代码（使用 C 语言）来自由扩展。所以，eBPF 实际上就是常驻于内核的运行时，可以说就是 Linux 版的 DTrace。\n而在分析大量事件时，使用我们上节课提到的火焰图，可以将大量数据可视化展示，让你更直观发现潜在的问题。\nftrace ftrace 通过 debugfs（或者 tracefs），为用户空间提供接口。所以使用 ftrace，往往是从切换到 debugfs 的挂载点开始。\n$ cd /sys/kernel/debug/tracing $ ls README instances set_ftrace_notrace trace_marker_raw available_events kprobe_events set_ftrace_pid trace_options ... 如果这个目录不存在，则说明你的系统还没有挂载 debugfs，你可以执行下面的命令来挂载它：\n$ mount -t debugfs nodev /sys/kernel/debug ftrace 提供了多个跟踪器，用于跟踪不同类型的信息，比如函数调用、中断关闭、进程调度等。具体支持的跟踪器取决于系统配置，你可以执行下面的命令，来查询所有支持的跟踪器：\n$ cat available_tracers hwlat blk mmiotrace function_graph wakeup_dl wakeup_rt wakeup function nop 这其中，function 表示跟踪函数的执行，function_graph 则是跟踪函数的调用关系，也就是生成直观的调用关系图。这便是最常用的两种跟踪器。\n除了跟踪器外，使用 ftrace 前，还需要确认跟踪目标，包括内核函数和内核事件。其中，\n函数就是内核中的函数名。 而事件，则是内核源码中预先定义的跟踪点。 同样地，你可以执行下面的命令，来查询支持的函数和事件：\n$ cat available_filter_functions $ cat available_events 为了列出文件，ls 命令会通过 open 系统调用打开目录文件，而 open 在内核中对应的函数名为 do_sys_open。 所以，我们要做的第一步，就是把要跟踪的函数设置为 do_sys_open：\n$ echo do_sys_open \u0026gt; set_graph_function 接下来，第二步，配置跟踪选项，开启函数调用跟踪，并跟踪调用进程：\n$ echo function_graph \u0026gt; current_tracer $ echo funcgraph-proc \u0026gt; trace_options 接着，第三步，也就是开启跟踪：\n$ echo 1 \u0026gt; tracing_on 第四步，执行一个 ls 命令后，再关闭跟踪：\n$ ls $ echo 0 \u0026gt; tracing_on 第五步，也是最后一步，查看跟踪结果：\n$ cat trace # tracer: function_graph # # CPU TASK/PID DURATION FUNCTION CALLS # | | | | | | | | | 0) ls-12276 | | do_sys_open() { 0) ls-12276 | | getname() { 0) ls-12276 | | getname_flags() { 0) ls-12276 | | kmem_cache_alloc() { 0) ls-12276 | | _cond_resched() { 0) ls-12276 | 0.049 us | rcu_all_qs(); 0) ls-12276 | 0.791 us | } 0) ls-12276 | 0.041 us | should_failslab(); 0) ls-12276 | 0.040 us | prefetch_freepointer(); 0) ls-12276 | 0.039 us | memcg_kmem_put_cache(); 0) ls-12276 | 2.895 us | } 0) ls-12276 | | __check_object_size() { 0) ls-12276 | 0.067 us | __virt_addr_valid(); 0) ls-12276 | 0.044 us | __check_heap_object(); 0) ls-12276 | 0.039 us | check_stack_object(); 0) ls-12276 | 1.570 us | } 0) ls-12276 | 5.790 us | } 0) ls-12276 | 6.325 us | } ... 在最后得到的输出中：\n第一列表示运行的 CPU； 第二列是任务名称和进程 PID； 第三列是函数执行延迟； 最后一列，则是函数调用关系图。 当然，我想你应该也发现了 ftrace 的使用缺点——五个步骤实在是麻烦，用起来并不方便。不过，不用担心， trace-cmd 已经帮你把这些步骤给包装了起来。这样，你就可以在同一个命令行工具里，完成上述所有过程。你可以执行下面的命令，来安装 trace-cmd ：\n# Ubuntu $ apt-get install trace-cmd # CentOS $ yum install trace-cmd 安装好后，原本的五步跟踪过程，就可以简化为下面这两步：\n$ trace-cmd record -p function_graph -g do_sys_open -O funcgraph-proc ls $ trace-cmd report ... ls-12418 [000] 85558.075341: funcgraph_entry: | do_sys_open() { ls-12418 [000] 85558.075363: funcgraph_entry: | getname() { ls-12418 [000] 85558.075364: funcgraph_entry: | getname_flags() { ls-12418 [000] 85558.075364: funcgraph_entry: | kmem_cache_alloc() { ls-12418 [000] 85558.075365: funcgraph_entry: | _cond_resched() { ls-12418 [000] 85558.075365: funcgraph_entry: 0.074 us | rcu_all_qs(); ls-12418 [000] 85558.075366: funcgraph_exit: 1.143 us | } ls-12418 [000] 85558.075366: funcgraph_entry: 0.064 us | should_failslab(); ls-12418 [000] 85558.075367: funcgraph_entry: 0.075 us | prefetch_freepointer(); ls-12418 [000] 85558.075368: funcgraph_entry: 0.085 us | memcg_kmem_put_cache(); ls-12418 [000] 85558.075369: funcgraph_exit: 4.447 us | } ls-12418 [000] 85558.075369: funcgraph_entry: | __check_object_size() { ls-12418 [000] 85558.075370: funcgraph_entry: 0.132 us | __virt_addr_valid(); ls-12418 [000] 85558.075370: funcgraph_entry: 0.093 us | __check_heap_object(); ls-12418 [000] 85558.075371: funcgraph_entry: 0.059 us | check_stack_object(); ls-12418 [000] 85558.075372: funcgraph_exit: 2.323 us | } ls-12418 [000] 85558.075372: funcgraph_exit: 8.411 us | } ls-12418 [000] 85558.075373: funcgraph_exit: 9.195 us | } ... 小结 所谓动态追踪，就是在系统或应用程序正常运行时，通过内核中提供的探针来动态追踪它们的行为，从而辅助排查出性能瓶颈。\n而在 Linux 系统中，常见的动态追踪方法包括 ftrace、perf、eBPF 以及 SystemTap 等。当你已经定位了某个内核函数，但不清楚它的实现原理时，就可以用 ftrace 来跟踪它的执行过程。\n","description":"动态追踪技术，通过探针机制，来采集内核或者应用程序的运行信息，从而可以不用修改内核和应用程序的代码，就获得丰富的信息，帮你分析、定位想要排查的问题。\n以往，在排查和调试性能问题时，我们往往需要先为应用程序设置一系列的断点（比如使用 GDB），然后以手动或者脚本（比如 GDB 的 Python 扩展）的方式，在这些断点处分析应用程序的状态。或者，增加一系列的日志，从日志中寻找线索。\n相比以往的进程级跟踪方法（比如 ptrace），动态追踪往往只会带来很小的性能损耗（通常在 5% 或者更少）。"},{"id":61,"href":"/post/51%E6%A1%88%E4%BE%8B%E7%AF%87%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%E6%80%8E%E4%B9%88%E7%94%A8%E4%B8%8B/","title":"51|案例篇：动态追踪怎么用？（下）","parent":"Linux性能优化","content":"在 Linux 系统中，常见的动态追踪方法包括 ftrace、perf、eBPF 以及 SystemTap 等。上节课，我们具体学习了 ftrace 的使用方法。\nperf 我们前面使用 perf record/top 时，都是先对事件进行采样，然后再根据采样数，评估各个函数的调用频率。实际上，perf 的功能远不止于此。比如，\nperf 可以用来分析 CPU cache、CPU 迁移、分支预测、指令周期等各种硬件事件； perf 也可以只对感兴趣的事件进行动态追踪。 同 ftrace 一样，你也可以通过 perf list ，查询所有支持的事件：\n$ perf list 我们先来看第一个 perf 示例，内核函数 do_sys_open 的例子。你可以执行 perf probe 命令，添加 do_sys_open 探针：\n$ perf probe --add do_sys_open Added new event: probe:do_sys_open (on do_sys_open) You can now use it in all perf tools, such as: perf record -e probe:do_sys_open -aR sleep 1 探针添加成功后，就可以在所有的 perf 子命令中使用。比如，上述输出就是一个 perf record 的示例，执行它就可以对 10s 内的 do_sys_open 进行采样：\n$ perf record -e probe:do_sys_open -aR sleep 10 [ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.148 MB perf.data (19 samples) ] 而采样成功后，就可以执行 perf script ，来查看采样结果了：\n$ perf script perf 12886 [000] 89565.879875: probe:do_sys_open: (ffffffffa807b290) sleep 12889 [000] 89565.880362: probe:do_sys_open: (ffffffffa807b290) sleep 12889 [000] 89565.880382: probe:do_sys_open: (ffffffffa807b290) sleep 12889 [000] 89565.880635: probe:do_sys_open: (ffffffffa807b290) sleep 12889 [000] 89565.880669: probe:do_sys_open: (ffffffffa807b290) strace 基于系统调用 ptrace 实现\n由于 ptrace 是系统调用，就需要在内核态和用户态切换。当事件数量比较多时，繁忙的切换必然会影响原有服务的性能； ptrace 需要借助 SIGSTOP 信号挂起目标进程。这种信号控制和进程挂起，会影响目标进程的行为。 所以，在性能敏感的应用（比如数据库）中，我并不推荐你用 strace （或者其他基于 ptrace 的性能工具）去排查和调试。\n在 strace 的启发下，结合内核中的 utrace 机制， perf 也提供了一个 trace 子命令，是取代 strace 的首选工具。相对于 ptrace 机制来说，perf trace 基于内核事件，自然要比进程跟踪的性能好很多。perf trace 的使用方法如下所示，跟 strace 其实很像：\n$ perf trace ls ? ( ): ls/14234 ... [continued]: execve()) = 0 0.177 ( 0.013 ms): ls/14234 brk( ) = 0x555d96be7000 0.224 ( 0.014 ms): ls/14234 access(filename: 0xad98082 ) = -1 ENOENT No such file or directory 0.248 ( 0.009 ms): ls/14234 access(filename: 0xad9add0, mode: R ) = -1 ENOENT No such file or directory 0.267 ( 0.012 ms): ls/14234 openat(dfd: CWD, filename: 0xad98428, flags: CLOEXEC ) = 3 0.288 ( 0.009 ms): ls/14234 fstat(fd: 3\u0026lt;/usr/lib/locale/C.UTF-8/LC_NAME\u0026gt;, statbuf: 0x7ffd2015f230 ) = 0 0.305 ( 0.011 ms): ls/14234 mmap(len: 45560, prot: READ, flags: PRIVATE, fd: 3 ) = 0x7efe0af92000 0.324 Dockerfile test.sh ( 0.008 ms): ls/14234 close(fd: 3\u0026lt;/usr/lib/locale/C.UTF-8/LC_NAME\u0026gt; ) = 0 ... eBPF 和 BCC ftrace 和 perf 的功能已经比较丰富了，不过，它们有一个共同的缺陷，那就是不够灵活，没法像 DTrace 那样通过脚本自由扩展。\n而 eBPF 就是 Linux 版的 DTrace，可以通过 C 语言自由扩展（这些扩展通过 LLVM 转换为 BPF 字节码后，加载到内核中执行）。下面这张图，就表示了 eBPF 追踪的工作原理：\n实际上，在 eBPF 执行过程中，编译、加载还有 maps 等操作，对所有的跟踪程序来说都是通用的。把这些过程通过 Python 抽象起来，也就诞生了 BCC（BPF Compiler Collection）。\nBCC 把 eBPF 中的各种事件源（比如 kprobe、uprobe、tracepoint 等）和数据操作（称为 Maps），也都转换成了 Python 接口（也支持 lua）。这样，使用 BCC 进行动态追踪时，编写简单的脚本就可以了。\n不过要注意，因为需要跟内核中的数据结构交互，真正核心的事件处理逻辑，还是需要我们用 C 语言来编写。\n至于 BCC 的安装方法，在内存模块的缓存案例中，我就已经介绍过了。如果你还没有安装过，可以执行下面的命令来安装（其他系统的安装请参考这里）：\n# Ubuntu sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD echo \u0026#34;deb https://repo.iovisor.org/apt/$(lsb_release -cs) $(lsb_release -cs) main\u0026#34; | sudo tee /etc/apt/sources.list.d/iovisor.list sudo apt-get update sudo apt-get install bcc-tools libbcc-examples linux-headers-$(uname -r) # REHL 7.6 yum install bcc-tools 安装后，BCC 会把所有示例（包括 Python 和 lua），放到 /usr/share/bcc/examples 目录中：\n$ ls /usr/share/bcc/examples hello_world.py lua networking tracing 当然，BCC 软件包也内置了很多已经开发好的实用工具，默认安装到 /usr/share/bcc/tools/ 目录中，它们的使用场景如下图所示：\n这些工具，一般都可以直接拿来用。而在编写其他的动态追踪脚本时，它们也是最好的参考资料。不过，有一点需要你特别注意，很多 eBPF 的新特性，都需要比较新的内核版本（如下图所示）。如果某些工具无法运行，很可能就是因为使用了当前内核不支持的特性。\nSystemTap 和 sysdig SystemTap 也是一种可以通过脚本进行自由扩展的动态追踪技术。在 eBPF 出现之前，SystemTap 是 Linux 系统中，功能最接近 DTrace 的动态追踪机制。不过要注意，SystemTap 在很长时间以来都游离于内核之外（而 eBPF 自诞生以来，一直根植在内核中）。\n所以，从稳定性上来说，SystemTap 只在 RHEL 系统中好用，在其他系统中则容易出现各种异常问题。当然，反过来说，支持 3.x 等旧版本的内核，也是 SystemTap 相对于 eBPF 的一个巨大优势。\nsysdig 则是随着容器技术的普及而诞生的，主要用于容器的动态追踪。sysdig 汇集了一些列性能工具的优势，可以说是集百家之所长。我习惯用这个公式来表示 sysdig 的特点： sysdig = strace + tcpdump + htop + iftop + lsof + docker inspect。而在最新的版本中（内核版本 \u0026gt;= 4.14），sysdig 还可以通过 eBPF 来进行扩展，所以，也可以用来追踪内核中的各种函数和事件。\n如何选择追踪工具 可以先自己思考区分一下，不同场景的工具选择问题。比如：\n在不需要很高灵活性的场景中，使用 perf 对性能事件进行采样，然后再配合火焰图辅助分析，就是最常用的一种方法； 而需要对事件或函数调用进行统计分析（比如观察不同大小的 I/O 分布）时，就要用 SystemTap 或者 eBPF，通过一些自定义的脚本来进行数据处理。 小结 在新版的内核中，eBPF 和 BCC 是最灵活的动态追踪方法； 而在旧版本内核中，特别是在 RHEL 系统中，由于 eBPF 支持受限，SystemTap 往往是更好的选择。 ","description":"在 Linux 系统中，常见的动态追踪方法包括 ftrace、perf、eBPF 以及 SystemTap 等。上节课，我们具体学习了 ftrace 的使用方法。\nperf 我们前面使用 perf record/top 时，都是先对事件进行采样，然后再根据采样数，评估各个函数的调用频率。实际上，perf 的功能远不止于此。比如，"},{"id":62,"href":"/post/52%E6%A1%88%E4%BE%8B%E7%AF%87%E6%9C%8D%E5%8A%A1%E5%90%9E%E5%90%90%E9%87%8F%E4%B8%8B%E9%99%8D%E5%BE%88%E5%8E%89%E5%AE%B3%E6%80%8E%E4%B9%88%E5%88%86%E6%9E%90/","title":"52|案例篇：服务吞吐量下降很厉害，怎么分析？","parent":"Linux性能优化","content":" 使用 perf 配合火焰图寻找热点函数，是一个比较通用的性能定位方法，在很多场景中都可以使用。 如果这仍满足不了你的要求，那么在新版的内核中，eBPF 和 BCC 是最灵活的动态追踪方法。 而在旧版本内核，特别是在 RHEL 系统中，由于 eBPF 支持受限，SystemTap 和 ftrace 往往是更好的选择。 连接数优化 要查看 TCP 连接数的汇总情况，首选工具自然是 ss 命令。\n工作进程优化 执行下面的 docker 命令，查询 Nginx 容器日志就知道了：\n$ docker logs nginx --tail 3 192.168.0.2 - - [15/Mar/2019:2243:27 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 499 0 \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; 192.168.0.2 - - [15/Mar/2019:22:43:27 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 499 0 \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; 192.168.0.2 - - [15/Mar/2019:22:43:27 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 499 0 \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; 套接字优化 然后回到终端一中，观察有没有发生套接字的丢包现象：\n# 只关注套接字统计 $ netstat -s | grep socket 73 resets received for embryonic SYN_RECV sockets 308582 TCP sockets finished time wait in fast timer 8 delayed acks further delayed because of locked socket 290566 times the listen queue of a socket overflowed 290566 SYNs to LISTEN sockets dropped # 稍等一会，再次运行 $ netstat -s | grep socket 73 resets received for embryonic SYN_RECV sockets 314722 TCP sockets finished time wait in fast timer 8 delayed acks further delayed because of locked socket 344440 times the listen queue of a socket overflowed 344440 SYNs to LISTEN sockets dropped 可以执行下面的命令，查看套接字的队列大小：\n$ ss -ltnp State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 10 10 0.0.0.0:80 0.0.0.0:* users:((\u0026#34;nginx\u0026#34;,pid=10491,fd=6),(\u0026#34;nginx\u0026#34;,pid=10490,fd=6),(\u0026#34;nginx\u0026#34;,pid=10487,fd=6)) LISTEN 7 10 *:9000 *:* users:((\u0026#34;php-fpm\u0026#34;,pid=11084,fd=9),...,(\u0026#34;php-fpm\u0026#34;,pid=10529,fd=7)) 执行下面的命令，分别查询 Nginx 和内核选项对监听队列长度的配置：\n# 查询nginx监听队列长度配置 $ docker exec nginx cat /etc/nginx/nginx.conf | grep backlog listen 80 backlog=10; # 查询php-fpm监听队列长度 $ docker exec phpfpm cat /opt/bitnami/php/etc/php-fpm.d/www.conf | grep backlog ; Set listen(2) backlog. ;listen.backlog = 511 # somaxconn是系统级套接字监听队列上限 $ sysctl net.core.somaxconn net.core.somaxconn = 10 端口号优化 执行下面的命令，就可以查询系统配置的临时端口号范围：\n$ sysctl net.ipv4.ip_local_port_range net.ipv4.ip_local_port_range=20000 20050 火焰图 执行 perf 和 flamegraph 脚本，生成火焰图：\n# 执行perf记录事件 $ perf record -g # 切换到FlameGraph安装路径执行下面的命令生成火焰图 $ perf script -i ~/perf.data | ./stackcollapse-perf.pl --all | ./flamegraph.pl \u0026gt; nginx.svg 小结 实际上，分析性能瓶颈，最核心的也正是掌握运用这些原理。\n首先，利用各种性能工具，收集想要的性能指标，从而清楚系统和应用程序的运行状态； 其次，拿目前状态跟系统原理进行比较，不一致的地方，就是我们要重点分析的对象。 从这个角度出发，再进一步借助 perf、火焰图、bcc 等动态追踪工具，找出热点函数，就可以定位瓶颈的来源，确定相应的优化方法。\n","description":"使用 perf 配合火焰图寻找热点函数，是一个比较通用的性能定位方法，在很多场景中都可以使用。 如果这仍满足不了你的要求，那么在新版的内核中，eBPF 和 BCC 是最灵活的动态追踪方法。 而在旧版本内核，特别是在 RHEL 系统中，由于 eBPF 支持受限，SystemTap 和 ftrace 往往是更好的选择。 连接数优化 要查看 TCP 连接数的汇总情况，首选工具自然是 ss 命令。"},{"id":63,"href":"/post/53%E5%A5%97%E8%B7%AF%E7%AF%87%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E7%9A%84%E7%BB%BC%E5%90%88%E6%80%9D%E8%B7%AF/","title":"53|套路篇：系统监控的综合思路","parent":"Linux性能优化","content":"要做好监控，最核心的就是全面的、可量化的指标，这包括系统和应用两个方面。\nUSE 法 为你介绍一种专门用于性能监控的 USE（Utilization Saturation and Errors）法。USE 法把系统资源的性能指标，简化成了三个类别，即使用率、饱和度以及错误数。\n使用率，表示资源用于服务的时间或容量百分比。100% 的使用率，表示容量已经用尽或者全部时间都用于服务。 饱和度，表示资源的繁忙程度，通常与等待队列的长度相关。100% 的饱和度，表示资源无法接受更多的请求。错误数表示发生错误的事件个数。 错误数越多，表明系统的问题越严重。 这三个类别的指标，涵盖了系统资源的常见性能瓶颈，所以常被用来快速定位系统资源的性能瓶颈。这样，无论是对 CPU、内存、磁盘和文件系统、网络等硬件资源，还是对文件描述符数、连接数、连接跟踪数等软件资源，USE 方法都可以帮你快速定位出，是哪一种系统资源出现了性能瓶颈。\n监控系统 一个完整的监控系统通常由数据采集、数据存储、数据查询和处理、告警以及可视化展示等多个模块组成。所以，要从头搭建一个监控系统，其实也是一个很大的系统工程。\n现在已经有很多开源的监控工具可以直接使用，比如最常见的 Zabbix、Nagios、Prometheus 等等。\n就以 Prometheus 为例，为你介绍这几个组件的基本原理。如下图所示，就是 Prometheus 的基本架构：\n先看数据采集模块。最左边的 Prometheus targets 就是数据采集的对象，而 Retrieval 则负责采集这些数据。从图中你也可以看到，Prometheus 同时支持 Push 和 Pull 两种数据采集模式。\nPull 模式，由服务器端的采集模块来触发采集。只要采集目标提供了 HTTP 接口，就可以自由接入（这也是最常用的采集模式）。 Push 模式，则是由各个采集目标主动向 Push Gateway（用于防止数据丢失）推送指标，再由服务器端从 Gateway 中拉取过去（这是移动应用中最常用的采集模式）。 由于需要监控的对象通常都是动态变化的，Prometheus 还提供了服务发现的机制，可以自动根据预配置的规则，动态发现需要监控的对象。这在 Kubernetes 等容器平台中非常有效。\n第二个是数据存储模块。为了保持监控数据的持久化，图中的 TSDB（Time series database）模块，负责将采集到的数据持久化到 SSD 等磁盘设备中。TSDB 是专门为时间序列数据设计的一种数据库，特点是以时间为索引、数据量大并且以追加的方式写入。\n第三个是数据查询和处理模块。刚才提到的 TSDB，在存储数据的同时，其实还提供了数据查询和基本的数据处理功能，而这也就是 PromQL 语言。PromQL 提供了简洁的查询、过滤功能，并且支持基本的数据处理方法，是告警系统和可视化展示的基础。\n第四个是告警模块。右上角的 AlertManager 提供了告警的功能，包括基于 PromQL 语言的触发条件、告警规则的配置管理以及告警的发送等。不过，虽然告警是必要的，但过于频繁的告警显然也不可取。所以，AlertManager 还支持通过分组、抑制或者静默等多种方式来聚合同类告警，并减少告警数量。\n最后一个是可视化展示模块。Prometheus 的 web UI 提供了简单的可视化界面，用于执行 PromQL 查询语句，但结果的展示比较单调。不过，一旦配合 Grafana，就可以构建非常强大的图形界面了。\n以刚才提到的 USE 方法为例，我使用 Prometheus，可以收集 Linux 服务器的 CPU、内存、磁盘、网络等各类资源的使用率、饱和度和错误数指标。然后，通过 Grafana 以及 PromQL 查询语句，就可以把它们以图形界面的方式直观展示出来。\n小结 系统监控的核心是资源的使用情况，包括 CPU、内存、磁盘和文件系统、网络等硬件资源，以及文件描述符数、连接数、连接跟踪数等软件资源。而这些资源，都可以通过 USE 法来建立核心性能指标。\nUSE 法把系统资源的性能指标，简化成了三个类别，即使用率、饱和度以及错误数。 这三者任一类别过高时，都代表相对应的系统资源有可能存在性能瓶颈。\n基于 USE 法建立性能指标后，还需要通过一套完整的监控系统，把这些指标从采集、存储、查询、处理，再到告警和可视化展示等串联起来。你可以基于 Zabbix、Prometheus 等各种开源的监控产品，构建这套监控系统。这样，不仅可以将系统资源的瓶颈快速暴露出来，还可以借助监控的历史，事后追查定位问题。\n","description":"要做好监控，最核心的就是全面的、可量化的指标，这包括系统和应用两个方面。\nUSE 法 为你介绍一种专门用于性能监控的 USE（Utilization Saturation and Errors）法。USE 法把系统资源的性能指标，简化成了三个类别，即使用率、饱和度以及错误数。\n使用率，表示资源用于服务的时间或容量百分比。100% 的使用率，表示容量已经用尽或者全部时间都用于服务。 饱和度，表示资源的繁忙程度，通常与等待队列的长度相关。100% 的饱和度，表示资源无法接受更多的请求。错误数表示发生错误的事件个数。 错误数越多，表明系统的问题越严重。 这三个类别的指标，涵盖了系统资源的常见性能瓶颈，所以常被用来快速定位系统资源的性能瓶颈。这样，无论是对 CPU、内存、磁盘和文件系统、网络等硬件资源，还是对文件描述符数、连接数、连接跟踪数等软件资源，USE 方法都可以帮你快速定位出，是哪一种系统资源出现了性能瓶颈。"},{"id":64,"href":"/post/54%E5%A5%97%E8%B7%AF%E7%AF%87%E5%BA%94%E7%94%A8%E7%9B%91%E6%8E%A7%E7%9A%84%E4%B8%80%E8%88%AC%E6%80%9D%E8%B7%AF/","title":"54|套路篇：应用监控的一般思路","parent":"Linux性能优化","content":" 指标监控 应用程序的核心指标，不再是资源的使用情况，而是请求数、错误率和响应时间。\n第一个，是应用进程的资源使用情况，比如进程占用的 CPU、内存、磁盘 I/O、网络等。使用过多的系统资源，导致应用程序响应缓慢或者错误数升高，是一个最常见的性能问题。\n第二个，是应用程序之间调用情况，比如调用频率、错误数、延时等。由于应用程序并不是孤立的，如果其依赖的其他应用出现了性能问题，应用自身性能也会受到影响。\n第三个，是应用程序内部核心逻辑的运行情况，比如关键环节的耗时以及执行过程中的错误等。由于这是应用程序内部的状态，从外部通常无法直接获取到详细的性能数据。所以，应用程序在设计和开发时，就应该把这些指标提供出来，以便监控系统可以了解其内部运行状态。\n有了应用程序之间的调用指标，你可以迅速分析出一个请求处理的调用链中，到底哪个组件才是导致性能问题的罪魁祸首； 而有了应用程序内部核心逻辑的运行性能，你就可以更进一步，直接进入应用程序的内部，定位到底是哪个处理环节的函数导致了性能问题。 基于这些思路，我相信你就可以构建出，描述应用程序运行状态的性能指标。再将这些指标纳入我们上一期提到的监控系统（比如 Prometheus + Grafana）中，就可以跟系统监控一样，一方面通过告警系统，把问题及时汇报给相关团队处理；另一方面，通过直观的图形界面，动态展示应用程序的整体性能。\n除此之外，由于业务系统通常会涉及到一连串的多个服务，形成一个复杂的分布式调用链。为了迅速定位这类跨应用的性能瓶颈，你还可以使用 Zipkin、Jaeger、Pinpoint 等各类开源工具，来构建全链路跟踪系统。\n比如，下图就是一个 Jaeger 调用链跟踪的示例。\n日志监控 指标是特定时间段的数值型测量数据，通常以时间序列的方式处理，适合于实时监控。 而日志则完全不同，日志都是某个时间点的字符串消息，通常需要对搜索引擎进行索引后，才能进行查询和汇总分析。 对日志监控来说，最经典的方法，就是使用 ELK 技术栈，即使用 Elasticsearch、Logstash 和 Kibana 这三个组件的组合。\n这其中，\nLogstash 负责对从各个日志源采集日志，然后进行预处理，最后再把初步处理过的日志，发送给 Elasticsearch 进行索引。 Elasticsearch 负责对日志进行索引，并提供了一个完整的全文搜索引擎，这样就可以方便你从日志中检索需要的数据。 Kibana 则负责对日志进行可视化分析，包括日志搜索、处理以及绚丽的仪表板展示等。 下面这张图，就是一个 Kibana 仪表板的示例，它直观展示了 Apache 的访问概况。\n值得注意的是，ELK 技术栈中的 Logstash 资源消耗比较大。所以，在资源紧张的环境中，我们往往使用资源消耗更低的 Fluentd，来替代 Logstash（也就是所谓的 EFK 技术栈）。\n小结 梳理了应用程序监控的基本思路。应用程序的监控，可以分为指标监控和日志监控两大部分：\n指标监控主要是对一定时间段内性能指标进行测量，然后再通过时间序列的方式，进行处理、存储和告警。 日志监控则可以提供更详细的上下文信息，通常通过 ELK 技术栈来进行收集、索引和图形化展示。 ","description":"指标监控 应用程序的核心指标，不再是资源的使用情况，而是请求数、错误率和响应时间。\n第一个，是应用进程的资源使用情况，比如进程占用的 CPU、内存、磁盘 I/O、网络等。使用过多的系统资源，导致应用程序响应缓慢或者错误数升高，是一个最常见的性能问题。\n第二个，是应用程序之间调用情况，比如调用频率、错误数、延时等。由于应用程序并不是孤立的，如果其依赖的其他应用出现了性能问题，应用自身性能也会受到影响。\n第三个，是应用程序内部核心逻辑的运行情况，比如关键环节的耗时以及执行过程中的错误等。由于这是应用程序内部的状态，从外部通常无法直接获取到详细的性能数据。所以，应用程序在设计和开发时，就应该把这些指标提供出来，以便监控系统可以了解其内部运行状态。\n有了应用程序之间的调用指标，你可以迅速分析出一个请求处理的调用链中，到底哪个组件才是导致性能问题的罪魁祸首； 而有了应用程序内部核心逻辑的运行性能，你就可以更进一步，直接进入应用程序的内部，定位到底是哪个处理环节的函数导致了性能问题。 基于这些思路，我相信你就可以构建出，描述应用程序运行状态的性能指标。再将这些指标纳入我们上一期提到的监控系统（比如 Prometheus + Grafana）中，就可以跟系统监控一样，一方面通过告警系统，把问题及时汇报给相关团队处理；另一方面，通过直观的图形界面，动态展示应用程序的整体性能。"},{"id":65,"href":"/post/55%E5%A5%97%E8%B7%AF%E7%AF%87%E5%88%86%E6%9E%90%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E8%88%AC%E6%AD%A5%E9%AA%A4/","title":"55|套路篇：分析性能问题的一般步骤","parent":"Linux性能优化","content":" 系统资源瓶颈 系统资源的瓶颈，可以通过 USE 法，即使用率、饱和度以及错误数这三类指标来衡量。系统的资源，可以分为硬件资源和软件资源两类。\n如 CPU、内存、磁盘和文件系统以及网络等，都是最常见的硬件资源。 而文件描述符数、连接跟踪数、套接字缓冲区大小等，则是典型的软件资源。 CPU 性能分析 利用 top、vmstat、pidstat、strace 以及 perf 等几个最常见的工具，获取 CPU 性能指标后，再结合进程与 CPU 的工作原理，就可以迅速定位出 CPU 性能瓶颈的来源。\n实际上，top、pidstat、vmstat 这类工具所汇报的 CPU 性能指标，都源自 /proc 文件系统（比如 /proc/loadavg、/proc/stat、/proc/softirqs 等）。这些指标，都应该通过监控系统监控起来。虽然并非所有指标都需要报警，但这些指标却可以加快性能问题的定位分析。\n比如说，当你收到系统的用户 CPU 使用率过高告警时，从监控系统中直接查询到，导致 CPU 使用率过高的进程；然后再登录到进程所在的 Linux 服务器中，分析该进程的行为。\n你可以使用 strace，查看进程的系统调用汇总；也可以使用 perf 等工具，找出进程的热点函数；甚至还可以使用动态追踪的方法，来观察进程的当前执行过程，直到确定瓶颈的根源。\n内存性能分析 可以通过 free 和 vmstat 输出的性能指标，确认内存瓶颈；然后，再根据内存问题的类型，进一步分析内存的使用、分配、泄漏以及缓存等，最后找出问题的来源。\n同 CPU 性能一样，很多内存的性能指标，也来源于 /proc 文件系统（比如 /proc/meminfo、/proc/slabinfo 等），它们也都应该通过监控系统监控起来。这样，当你收到内存告警时，就可以从监控系统中，直接得到上图中的各项性能指标，从而加快性能问题的定位过程。\n比如说，当你收到内存不足的告警时，首先可以从监控系统中。找出占用内存最多的几个进程。然后，再根据这些进程的内存占用历史，观察是否存在内存泄漏问题。确定出最可疑的进程后，再登录到进程所在的 Linux 服务器中，分析该进程的内存空间或者内存分配，最后弄清楚进程为什么会占用大量内存。\n磁盘和文件系统 I/O 性能分析 当你使用 iostat ，发现磁盘 I/O 存在性能瓶颈（比如 I/O 使用率过高、响应时间过长或者等待队列长度突然增大等）后，可以再通过 pidstat、 vmstat 等，确认 I/O 的来源。接着，再根据来源的不同，进一步分析文件系统和磁盘的使用率、缓存以及进程的 I/O 等，从而揪出 I/O 问题的真凶。\n同 CPU 和内存性能类似，很多磁盘和文件系统的性能指标，也来源于 /proc 和 /sys 文件系统（比如 /proc/diskstats、/sys/block/sda/stat 等）。自然，它们也应该通过监控系统监控起来。这样，当你收到 I/O 性能告警时，就可以从监控系统中，直接得到上图中的各项性能指标，从而加快性能定位的过程。\n比如说，当你发现某块磁盘的 I/O 使用率为 100% 时，首先可以从监控系统中，找出 I/O 最多的进程。然后，再登录到进程所在的 Linux 服务器中，借助 strace、lsof、perf 等工具，分析该进程的 I/O 行为。最后，再结合应用程序的原理，找出大量 I/O 的原因。\n网络性能分析 网络性能的分析，要从 Linux 网络协议栈的原理来切入。下面这张图，就是 Linux 网络协议栈的基本原理，包括应用层、套机字接口、传输层、网络层以及链路层等。\n而要分析网络的性能，自然也是要从这几个协议层入手，通过使用率、饱和度以及错误数这几类性能指标，观察是否存在性能问题。比如 ：\n在链路层，可以从网络接口的吞吐量、丢包、错误以及软中断和网络功能卸载等角度分析； 在网络层，可以从路由、分片、叠加网络等角度进行分析； 在传输层，可以从 TCP、UDP 的协议原理出发，从连接数、吞吐量、延迟、重传等角度进行分析； 在应用层，可以从应用层协议（如 HTTP 和 DNS）、请求数（QPS）、套接字缓存等角度进行分析。 同前面几种资源类似，网络的性能指标也都来源于内核，包括 /proc 文件系统（如 /proc/net）、网络接口以及 conntrack 等内核模块。这些指标同样需要被监控系统监控。这样，当你收到网络告警时，就可以从监控系统中，查询这些协议层的各项性能指标，从而更快定位出性能问题。\n比如，当你收到网络不通的告警时，就可以从监控系统中，查找各个协议层的丢包指标，确认丢包所在的协议层。然后，从监控系统的数据中，确认网络带宽、缓冲区、连接跟踪数等软硬件，是否存在性能瓶颈。最后，再登录到发生问题的 Linux 服务器中，借助 netstat、tcpdump、bcc 等工具，分析网络的收发数据，并且结合内核中的网络选项以及 TCP 等网络协议的原理，找出问题的来源。\n应用程序瓶颈 第一种资源瓶颈，其实还是指刚才提到的 CPU、内存、磁盘和文件系统 I/O、网络以及内核资源等各类软硬件资源出现了瓶颈，从而导致应用程序的运行受限。对于这种情况，我们就可以用前面系统资源瓶颈模块提到的各种方法来分析。\n第二种依赖服务的瓶颈，也就是诸如数据库、分布式缓存、中间件等应用程序，直接或者间接调用的服务出现了性能问题，从而导致应用程序的响应变慢，或者错误率升高。这说白了就是跨应用的性能问题，使用全链路跟踪系统，就可以帮你快速定位这类问题的根源。\n最后一种，应用程序自身的性能问题，包括了多线程处理不当、死锁、业务算法的复杂度过高等等。对于这类问题，在我们前面讲过的应用程序指标监控以及日志监控中，观察关键环节的耗时和内部执行过程中的错误，就可以帮你缩小问题的范围。\n如果这些手段过后还是无法找出瓶颈，你还可以用系统资源模块提到的各类进程分析工具，来进行分析定位。比如：\n你可以用 strace，观察系统调用； 使用 perf 和火焰图，分析热点函数； 甚至使用动态追踪技术，来分析进程的执行状态。 当然，系统资源和应用程序本来就是相互影响、相辅相成的一个整体。实际上，很多资源瓶颈，也是应用程序自身运行导致的。比如，进程的内存泄漏，会导致系统内存不足；进程过多的 I/O 请求，会拖慢整个系统的 I/O 请求等。\n小结 从系统资源瓶颈的角度来说，USE 法是最为有效的方法，即从使用率、饱和度以及错误数这三个方面，来分析 CPU、内存、磁盘和文件系统 I/O、网络以及内核资源限制等各类软硬件资源。关于这些资源的分析方法，我也带你一起回顾了咱们专栏前面几大模块的分析套路。\n虽然我把瓶颈分为了系统和应用两个角度，但在实际运行时，这两者往往是相辅相成、相互影响的。系统是应用的运行环境，系统的瓶颈会导致应用的性能下降；而应用的不合理设计，也会引发系统资源的瓶颈。我们做性能分析，就是要结合应用程序和操作系统的原理，揪出引发问题的真凶。\n","description":"系统资源瓶颈 系统资源的瓶颈，可以通过 USE 法，即使用率、饱和度以及错误数这三类指标来衡量。系统的资源，可以分为硬件资源和软件资源两类。\n如 CPU、内存、磁盘和文件系统以及网络等，都是最常见的硬件资源。 而文件描述符数、连接跟踪数、套接字缓冲区大小等，则是典型的软件资源。 CPU 性能分析 利用 top、vmstat、pidstat、strace 以及 perf 等几个最常见的工具，获取 CPU 性能指标后，再结合进程与 CPU 的工作原理，就可以迅速定位出 CPU 性能瓶颈的来源。"},{"id":66,"href":"/post/56%E5%A5%97%E8%B7%AF%E7%AF%87%E4%BC%98%E5%8C%96%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E8%88%AC%E6%96%B9%E6%B3%95/","title":"56|套路篇：优化性能问题的一般方法","parent":"Linux性能优化","content":" CPU 优化 CPU 性能优化的核心，在于排除所有不必要的工作、充分利用 CPU 缓存并减少进程调度对性能的影响。\n第一种，把进程绑定到一个或者多个 CPU 上，充分利用 CPU 缓存的本地性，并减少进程间的相互影响。 第二种，为中断处理程序开启多 CPU 负载均衡，以便在发生大量中断时，可以充分利用多 CPU 的优势分摊负载。 第三种，使用 Cgroups 等方法，为进程设置资源限制，避免个别进程消耗过多的 CPU。同时，为核心应用程序设置更高的优先级，减少低优先级任务的影响。 内存优化 第一种，除非有必要，Swap 应该禁止掉。这样就可以避免 Swap 的额外 I/O ，带来内存访问变慢的问题。\n第二种，使用 Cgroups 等方法，为进程设置内存限制。这样就可以避免个别进程消耗过多内存，而影响了其他进程。对于核心应用，还应该降低 oom_score，避免被 OOM 杀死。\n第三种，使用大页、内存池等方法，减少内存的动态分配，从而减少缺页异常。\n磁盘和文件系统 I/O 优化 第一种，也是最简单的方法，通过 SSD 替代 HDD、或者使用 RAID 等方法，提升 I/O 性能。 第二种，针对磁盘和应用程序 I/O 模式的特征，选择最适合的 I/O 调度算法。比如，SSD 和虚拟机中的磁盘，通常用的是 noop 调度算法；而数据库应用，更推荐使用 deadline 算法。\n第三，优化文件系统和磁盘的缓存、缓冲区，比如优化脏页的刷新频率、脏页限额，以及内核回收目录项缓存和索引节点缓存的倾向等等。\n网络优化 首先，从内核资源和网络协议的角度来说，我们可以对内核选项进行优化，比如：\n可以增大套接字缓冲区、连接跟踪表、最大半连接数、最大文件描述符数、本地端口范围等内核资源配额； 可以减少 TIMEOUT 超时时间、SYN+ACK 重传数、Keepalive 探测时间等异常处理参数； 还可以开启端口复用、反向地址校验，并调整 MTU 大小等降低内核的负担。 其次，从网络接口的角度来说，我们可以考虑对网络接口的功能进行优化，比如：\n可以将原来 CPU 上执行的工作，卸载到网卡中执行，即开启网卡的 GRO、GSO、RSS、VXLAN 等卸载功能； 可以开启网络接口的多队列功能，这样，每个队列就可以用不同的中断号，调度到不同 CPU 上执行； 可以增大网络接口的缓冲区大小以及队列长度等，提升网络传输的吞吐量。 最后，在极限性能情况（比如 C10M）下，内核的网络协议栈可能是最主要的性能瓶颈，所以，一般会考虑绕过内核协议栈。\n可以使用 DPDK 技术，跳过内核协议栈，直接由用户态进程用轮询的方式，来处理网络请求。同时，再结合大页、CPU 绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率。 还可以使用内核自带的 XDP 技术，在网络包进入内核协议栈前，就对其进行处理。这样，也可以达到目的，获得很好的性能。 应用程序优化 性能优化的最佳位置，还是应用程序内部。\n第一，从 CPU 使用的角度来说，简化代码、优化算法、异步处理以及编译器优化等，都是常用的降低 CPU 使用率的方法，这样可以利用有限的 CPU 处理更多的请求。\n第二，从数据访问的角度来说，使用缓存、写时复制、增加 I/O 尺寸等，都是常用的减少磁盘 I/O 的方法，这样可以获得更快的数据处理速度。\n第三，从内存管理的角度来说，使用大页、内存池等方法，可以预先分配内存，减少内存的动态分配，从而更好地内存访问性能。\n第四，从网络的角度来说，使用 I/O 多路复用、长连接代替短连接、DNS 缓存等方法，可以优化网络 I/O 并减少网络请求数，从而减少网络延时带来的性能问题。\n第五，从进程的工作模型来说，异步处理、多线程或多进程等，可以充分利用每一个 CPU 的处理能力，从而提高应用程序的吞吐能力。\n","description":"CPU 优化 CPU 性能优化的核心，在于排除所有不必要的工作、充分利用 CPU 缓存并减少进程调度对性能的影响。\n第一种，把进程绑定到一个或者多个 CPU 上，充分利用 CPU 缓存的本地性，并减少进程间的相互影响。 第二种，为中断处理程序开启多 CPU 负载均衡，以便在发生大量中断时，可以充分利用多 CPU 的优势分摊负载。 第三种，使用 Cgroups 等方法，为进程设置资源限制，避免个别进程消耗过多的 CPU。同时，为核心应用程序设置更高的优先级，减少低优先级任务的影响。 内存优化 第一种，除非有必要，Swap 应该禁止掉。这样就可以避免 Swap 的额外 I/O ，带来内存访问变慢的问题。"},{"id":67,"href":"/post/57%E5%A5%97%E8%B7%AF%E7%AF%87Linux-%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7%E9%80%9F%E6%9F%A5/","title":"57|套路篇：Linux 性能工具速查","parent":"Linux性能优化","content":" 性能工具速查 info 可以理解为 man 的详细版本，提供了诸如节点跳转等更强大的功能。相对来说，man 的输出比较简洁，而 info 的输出更详细。所以，我们通常使用 man 来查询工具的使用方法，只有在 man 的输出不太好理解时，才会再去参考 info 文档。\n有些工具不需要额外安装，就可以直接使用，比如内核的 /proc 文件系统； 而有些工具，则需要安装额外的软件包，比如 sar、pidstat、iostat 等。 所以，在选择性能工具时，除了要考虑性能指标这个目的外，还要结合待分析的环境来综合考虑。比如，实际环境是否允许安装软件包，是否需要新的内核版本等。\n还是从性能指标出发，根据性能指标的不同，将性能工具划分为不同类型。比如，最常见的就是可以根据 CPU、内存、磁盘 I/O 以及网络的各类性能指标，将这些工具进行分类。\nCPU 性能工具 内存性能工具 磁盘 I/O 性能工具 网络性能工具 基准测试工具 在文件系统和磁盘 I/O 模块中，我们使用 fio 工具，测试了磁盘 I/O 的性能。 在网络模块中，我们使用 iperf、pktgen 等，测试了网络的性能。 而在很多基于 Nginx 的案例中，我们则使用 ab、wrk 等，测试 Nginx 应用的性能。 下面这张图，是 Brendan Gregg 整理的 Linux 基准测试工具图谱，你可以保存下来，在需要时参考。\n","description":"性能工具速查 info 可以理解为 man 的详细版本，提供了诸如节点跳转等更强大的功能。相对来说，man 的输出比较简洁，而 info 的输出更详细。所以，我们通常使用 man 来查询工具的使用方法，只有在 man 的输出不太好理解时，才会再去参考 info 文档。"},{"id":68,"href":"/post/58%E7%AD%94%E7%96%91%E5%85%AD%E5%AE%B9%E5%99%A8%E5%86%B7%E5%90%AF%E5%8A%A8%E5%A6%82%E4%BD%95%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/","title":"58|答疑（六）：容器冷启动如何性能分析？","parent":"Linux性能优化","content":" 问题 1：容器冷启动性能分析 容器为应用程序的管理带来了巨大的便捷，诸如 Serverless（只关注应用的运行，而无需关注服务器）、FaaS（Function as a Service）等新型的软件架构，也都基于容器技术来构建。不过，虽然容器启动已经很快了，但在启动新容器，也就是冷启动的时候，启动时间相对于应用程序的性能要求来说，还是过长了。\n针对耗时最多的流程，我们可以通过应用程序监控或者动态追踪的方法，定位出耗时最多的字模块，这样也就找出了要优化的瓶颈点。\n比如，镜像拉取流程，可以通过缓存热点镜像来减少镜像拉取时间；网络配置流程，可以通过网络资源预分配进行加速；而资源调度和容器启动，也可以通过复用预先创建好的容器来进行优化。\n问题 2：CPU 火焰图和内存火焰图有什么不同？ 对 CPU 火焰图来说，采集的数据主要是消耗 CPU 的函数； 而对内存火焰图来说，采集的数据主要是内存分配、释放、换页等内存管理函数。 问题 3：perf probe 失败怎么办？ 使用动态追踪工具时，由于十六进制格式的函数地址并不容易理解，就需要我们借助调试信息，将它们转换为更直观的函数名。对于内核来说，我已经多次提到过，需要安装 debuginfo。\n第一种方法，假如应用程序提供了调试信息软件包，那你就可以直接安装来使用。比如，对于我们案例中的 bash 来说，就可以通过下面的命令，来安装它的调试信息：\n# Ubuntu apt-get install -y bash-dbgsym # Centos debuginfo-install bash 第二种方法，使用源码重新编译应用程序，并开启编译器的调试信息开关，比如可以为 gcc 增加 -g 选项。\n问题 4：RED 法监控微服务应用 RED 方法，是 Weave Cloud 在监控微服务性能时，结合 Prometheus 监控，所提出的一种监控思路——即对微服务来说，监控它们的请求数（Rate）、错误数（Errors）以及响应时间（Duration）。所以，RED 方法适用于微服务应用的监控，而 USE 方法适用于系统资源的监控。\n问题 5：深入内核的方法 在定位性能问题时，我们通过 perf、ebpf、systemtap 等各种方法排查时，很可能会发现，问题的热点在内核中的某个函数中。而青石和 xfan 的问题，就是如何去了解、深入 Linux 内核的原理，特别是想弄清楚，性能工具展示的内核函数到底是什么含义。\n","description":"问题 1：容器冷启动性能分析 容器为应用程序的管理带来了巨大的便捷，诸如 Serverless（只关注应用的运行，而无需关注服务器）、FaaS（Function as a Service）等新型的软件架构，也都基于容器技术来构建。不过，虽然容器启动已经很快了，但在启动新容器，也就是冷启动的时候，启动时间相对于应用程序的性能要求来说，还是过长了。\n针对耗时最多的流程，我们可以通过应用程序监控或者动态追踪的方法，定位出耗时最多的字模块，这样也就找出了要优化的瓶颈点。\n比如，镜像拉取流程，可以通过缓存热点镜像来减少镜像拉取时间；网络配置流程，可以通过网络资源预分配进行加速；而资源调度和容器启动，也可以通过复用预先创建好的容器来进行优化。"},{"id":69,"href":"/post/stress%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/","title":"stress性能工具使用","parent":"Linux性能优化","content":" 安装 yum install -y epel-release yum install stress -y 在centos系统下，不能安装，则按照如下方法进行：\nhttps://github.com/ColinIanKing/stress-ng.git 直接 clone ，然后 make -j4 参数说明 -？ --help 显示帮助信息 --version 显示软件版本信息 -t secs: --timeout secs指定运行多少秒 --backoff usecs 等待usecs微秒后才开始运行 -c forks: --cpu forks 产生多个处理sqrt()函数的CPU进程 -m forks --vm forks:产生多个处理malloc()内存分配 -i forks --io forks:产生多个处理sync()函数的磁盘I/O进程 --vm-bytes bytes：指定内存的byte数，默认值是1 --vm-hang:表示malloc分配的内存多少时间后在free()释放掉 -d : --hdd:写进程，写入固定大小，通过mkstemp()函数写入当前目录 --hdd-bytes bytes:指定写的byte数，默认1G --hdd-noclean:不要将写入随机ascii数据的文件unlink，则写入的文件不删除，会保留在硬盘空间。 测试场景 stress -c 4 增加4个cpu进程，处理sqrt()函数函数，以提高系统CPU负荷\nzsy@ubuntu:~$ stress -c 4 stress: info: [7775] dispatching hogs: 4 cpu, 0 io, 0 vm, 0 hdd 内存测试 stress –i 4 –vm 10 –vm-bytes 1G –vm-hang 100 –timeout 100s\n新增4个io进程，10个内存分配进程，每次分配大小1G，分配后不释放，测试100S\nzsy@ubuntu:~$ stress --io 4 --vm 2 --vm-bytes 1G --vm-hang 100 --timeout 100s stress: info: [8979] dispatching hogs: 0 cpu, 4 io, 2 vm, 0 hdd stress: info: [8979] successful run completed in 100s 磁盘I/O测试 stress –d 1 \u0026ndash;hdd-bytes 3G\n新增1个写进程，每次写3G文件块\n输入命令：stress –i 1 –d 10 \u0026ndash;hdd-bytes 3G –hdd-noclean\n新增1个IO进程，10个写进程，每次写入3G文件块，且不清除，会逐步将硬盘耗尽。\nzsy@ubuntu:~$ stress -d 1 --hdd-bytes 3G stress: info: [9437] dispatching hogs: 0 cpu, 0 io, 0 vm, 1 hdd ","description":"安装 yum install -y epel-release yum install stress -y 在centos系统下，不能安装，则按照如下方法进行："},{"id":70,"href":"/post/%E7%AC%AC%E4%B8%80%E5%91%A801-09%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93/","title":"第一周01-09阶段小结","parent":"Linux性能优化","content":" 学习思路 建立起整体性能的全局观\n学习内容 平均负载 含义 1分钟、5分钟、15分钟时间段监控 平均负载的合理性判定 工具uptime使用 /proc/cupinfo查看cup相关信息 工具top使用 平均负载高于cpu数量70%就要进行排查了 工具uptime、stress、systat、mpstat、pidstat使用 cpu上下文切换 cpu寄存器 程序计数器PC cpu上下文与cpu上下文切换 进程上下文切换、进程上下文切换、中断上下文切换 内核空间 \u0026ndash; 内核态 用户空间 \u0026ndash; 用户态 工具vmstat、pidstat、sysbench、man、watch使用 自愿上下文切换 非自愿上下文切换 中断 进行中断会出现什么情况 /proc/interrupts观察中断情况 cpu使用率 节拍率HZ，使用/boot/config查看配置情况 USER_HZ，默认100 /proc/stat与/proc/[pid]/stat查看cpu使用率 工具top、ps、pidstat、perf top、perf recod、perf report、ab、pstree、execsnoop、ftrace使用 僵尸进程 进程状态区分（R\\D\\Z\\S\\I） 进程组、会话 iowait分析 工具ps aux、top、dstat、pidstat、strace、perf record、perf report、pstree使用 软中断 异步处理机制 上半部与下半部 外卖配送例子 /proc/softirqs /proc/interrupts 学习感悟 要从了解基本概念，从系统的原理着手出发，linux下的工具比较齐全，要充分了解各工具的作用及应用场景\nCPU相关的指标 ","description":"学习思路 建立起整体性能的全局观\n学习内容 平均负载 含义 1分钟、5分钟、15分钟时间段监控 平均负载的合理性判定 工具uptime使用 /proc/cupinfo查看cup相关信息 工具top使用 平均负载高于cpu数量70%就要进行排查了 工具uptime、stress、systat、mpstat、pidstat使用 cpu上下文切换 cpu寄存器 程序计数器PC cpu上下文与cpu上下文切换 进程上下文切换、进程上下文切换、中断上下文切换 内核空间 \u0026ndash; 内核态 用户空间 \u0026ndash; 用户态 工具vmstat、pidstat、sysbench、man、watch使用 自愿上下文切换 非自愿上下文切换 中断 进行中断会出现什么情况 /proc/interrupts观察中断情况 cpu使用率 节拍率HZ，使用/boot/config查看配置情况 USER_HZ，默认100 /proc/stat与/proc/[pid]/stat查看cpu使用率 工具top、ps、pidstat、perf top、perf recod、perf report、ab、pstree、execsnoop、ftrace使用 僵尸进程 进程状态区分（R\\D\\Z\\S\\I） 进程组、会话 iowait分析 工具ps aux、top、dstat、pidstat、strace、perf record、perf report、pstree使用 软中断 异步处理机制 上半部与下半部 外卖配送例子 /proc/softirqs /proc/interrupts 学习感悟 要从了解基本概念，从系统的原理着手出发，linux下的工具比较齐全，要充分了解各工具的作用及应用场景"},{"id":71,"href":"/post/%E7%AC%AC%E4%BA%8C%E5%91%A810-14%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93/","title":"第二周10-14阶段小结","parent":"Linux性能优化","content":" 学习核心 理解中断：特别是网络接收的软中断 上半部分 下半部分 平均负载 累积中断次数 cpu指标性能 cpu使用率 用户cpu使用率 系统cpu使用率 等待io的cpu使用率 软中断和硬中断的cpu使用率 窃取cpu使用率 客户cpu使用率 平均负载 进程上下文切换 cpu缓存命中率 工具 sar：添加 -n DEV 参数显示网络收发的报告 watch -d cat /proc/softirqs tcpdump：通过 -i eth0 选项指定网卡 eth0，并通过 tcp port 80 选项指定 TCP 协议的 80 端口 uptime、mpstat、pidstat vmstat：查看系统的上下文切换次数和中断次数 top、perf top、perf record、perf report 短时进程execsnoop dstat 把性能指标与工具联合起来 ","description":" 学习核心 理解中断：特别是网络接收的软中断 上半部分 下半部分 平均负载 累积中断次数 cpu指标性能 cpu使用率 用户cpu使用率 系统cpu使用率 等待io的cpu使用率 软中断和硬中断的cpu使用率 窃取cpu使用率 客户cpu使用率 平均负载 进程上下文切换 cpu缓存命中率 工具 sar：添加 -n DEV 参数显示网络收发的报告 watch -d cat /proc/softirqs tcpdump：通过 -i eth0 选项指定网卡 eth0，并通过 tcp port 80 选项指定 TCP 协议的 80 端口 uptime、mpstat、pidstat vmstat：查看系统的上下文切换次数和中断次数 top、perf top、perf record、perf report 短时进程execsnoop dstat 把性能指标与工具联合起来 "},{"id":72,"href":"/post/%E7%AC%AC%E4%B8%89%E5%91%A815-22%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%93/","title":"第三周15-22阶段小结","parent":"Linux性能优化","content":" 内存性能 linux内存工作原理 内存映射 内核空间 用户空间 虚拟内存地址 物理内存地址 内存映射 缺页异常 虚拟内存空间分布 内核空间 栈 文件映射 堆 数据段 只读段 内存分配与回收 内存查看工具free 内存buffer与cache Buffers 是内核缓冲区用到的内存，对应的是 /proc/meminfo 中的 Buffers 值。 Cache 是内核页缓存和 Slab 用到的内存，对应的是 /proc/meminfo 中的 Cached 与 SReclaimable 之和。 proc文件系统 内存泄露 只读段，包括程序的代码和常量，由于是只读的，不会再去分配新的内存，所以也不会产生内存泄漏。 数据段，包括全局变量和静态变量，这些变量在定义时就已经确定了大小，所以也不会产生内存泄漏。 最后一个内存映射段，包括动态链接库和共享内存，其中共享内存由程序动态分配和管理。所以，如果程序在分配后忘了回收，就会导致跟堆内存类似的泄漏问题。 内存泄漏的危害非常大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用。内存泄漏不断累积，甚至会耗尽系统内存。\nSwap 原理 所谓换出，就是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存。 而换入，则是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来。 页最小阈值（pages_min）、页低阈值（pages_low）和页高阈值（pages_high）。剩余内存，则使用 pages_free 表示。 剩余内存小于页最小阈值，说明进程可用内存都耗尽了，只有内核才可以分配内存。 剩余内存落在页最小阈值和页低阈值中间，说明内存压力比较大，剩余内存不多了。这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值为止。 剩余内存落在页低阈值和页高阈值中间，说明内存有一定压力，但还可以满足新内存请求。 剩余内存大于页高阈值，说明剩余内存比较多，没有内存压力。 swappiness 对文件页的回收，当然就是直接回收缓存，或者把脏页写回磁盘后再回收。 而对匿名页的回收，其实就是通过 Swap 机制，把它们写入磁盘后再释放内存。 Linux 提供了一个 /proc/sys/vm/swappiness 选项，用来调整使用 Swap 的积极程度。 swappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页。 系统内存问题 内存性能指标 内存性能工具 性能指标和工具的联系 如何迅速分析内存的性能瓶颈 为了迅速定位内存问题，我通常会先运行几个覆盖面比较大的性能工具，比如 free、top、vmstat、pidstat 等。 内存问题分析步骤 先用 free 和 top，查看系统整体的内存使用情况。 再用 vmstat 和 pidstat，查看一段时间的趋势，从而判断出内存问题的类型。 最后进行详细分析，比如内存分配分析、缓存 / 缓冲区分析、具体进程的内存使用分析等。 ","description":"内存性能 linux内存工作原理 内存映射 内核空间 用户空间 虚拟内存地址 物理内存地址 内存映射 缺页异常 虚拟内存空间分布 内核空间 栈 文件映射 堆 数据段 只读段 内存分配与回收 内存查看工具free 内存buffer与cache Buffers 是内核缓冲区用到的内存，对应的是 /proc/meminfo 中的 Buffers 值。 Cache 是内核页缓存和 Slab 用到的内存，对应的是 /proc/meminfo 中的 Cached 与 SReclaimable 之和。 proc文件系统 内存泄露 只读段，包括程序的代码和常量，由于是只读的，不会再去分配新的内存，所以也不会产生内存泄漏。 数据段，包括全局变量和静态变量，这些变量在定义时就已经确定了大小，所以也不会产生内存泄漏。 最后一个内存映射段，包括动态链接库和共享内存，其中共享内存由程序动态分配和管理。所以，如果程序在分配后忘了回收，就会导致跟堆内存类似的泄漏问题。 内存泄漏的危害非常大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用。内存泄漏不断累积，甚至会耗尽系统内存。"},{"id":73,"href":"/know/","title":"知识点","parent":"首页","content":" brew update error Failed to resolve loader sass loader Git Stats安装 JWT和Oauth2的区别和联系 Mac OS 安装 etcd Mac 配置java环境 Mac下安装yarn可真难呀 Mac下安装yarn可真难呀 MySQL数据插入：1292 - Incorrect datetime value: \u0026#39;0000-00-00 00:00:00\u0026#39; for column \u0026#39;start_time\u0026#39; at row 1, Time: 0.003000s 银河麒麟操作系统设置java与go系统环境变量 ","description":"brew update error Failed to resolve loader sass loader Git Stats安装 JWT和Oauth2的区别和联系 Mac OS 安装 etcd Mac 配置java环境 Mac下安装yarn可真难呀 Mac下安装yarn可真难呀 MySQL数据插入：1292 - Incorrect datetime value: \u0026#39;0000-00-00 00:00:00\u0026#39; for column \u0026#39;start_time\u0026#39; at row 1, Time: 0."},{"id":74,"href":"/csapp/","title":"读书笔记","parent":"首页","content":" 020201102到20201108日读书汇总--第七周 20201019到20201025日读书汇总--第五周 20201026到20201101日读书汇总--第六周 20201109到20201115日读书汇总--第八周 序言 第一周20200914到20200920日读书汇总 第一章 计算机系统漫游 第一章计算机系统漫游 Amdahl定律 第三周20200928到20201011日读书汇总 第三章程序的机器表示 第二周20200921到20200927日读书汇总 第二章信息的表示和处理 第二章信息的表示和处理 整数运算 第二章信息的表示和处理 浮点数 第四周20201012到20201018日读书汇总 ","description":" 020201102到20201108日读书汇总--第七周 20201019到20201025日读书汇总--第五周 20201026到20201101日读书汇总--第六周 20201109到20201115日读书汇总--第八周 序言 第一周20200914到20200920日读书汇总 第一章 计算机系统漫游 第一章计算机系统漫游 Amdahl定律 第三周20200928到20201011日读书汇总 第三章程序的机器表示 第二周20200921到20200927日读书汇总 第二章信息的表示和处理 第二章信息的表示和处理 整数运算 第二章信息的表示和处理 浮点数 第四周20201012到20201018日读书汇总 "},{"id":75,"href":"/post/","title":"Linux性能优化","parent":"首页","content":" 01|如何学习Linux性能优化 02|基础篇--到底应该怎么理解平均负载 03|基础篇经常说的CPU上下文切换是什么意思 04|基础篇--经常说的CPU上下文切换是什么意思 05|基础篇--某个应用的CPU使用率居然达到100%，我该怎么办？ 06|案例篇--系统的CPU使用率很高，但为啥却找不到高CPU的应用？ 07|案例篇--系统中出现大量不可中断进程和僵尸进程怎么办？（上） 08|案例篇--系统中出现大量不可中断进程和僵尸进程怎么办？（下） 09|基础篇--怎么理解Linux软中断？ 10|案例篇--系统的软中断CPU使用率升高，我该怎么办？ 11|套路篇--如何迅速分析出系统CPU的瓶颈在哪里？ 12|套路篇--CPU性能优化的几个思路 13|答疑（一）无法模拟出RES中断的问题，怎么办？ 14|答疑（二）如何用perf工具分析Java程序？ 15|基础篇--Linux内存是怎么工作的？ 16|基础篇怎么理解内存中的Buffer和Cache？ 17|案例篇--如何利用系统缓存优化程序的运行效率？ 18|案例篇--内存泄漏了，我该如何定位和处理？ 19|案例篇--为什么系统的Swap变高了（上） 20|案例篇--为什么系统的Swap变高了（下） 21|套路篇--如何“快准狠”找到系统内存的问题？ 22|答疑（三）文件系统与磁盘的区别是什么？ 23|基础篇--Linux文件系统是怎么工作的？ 24|基础篇--Linux磁盘I/O是怎么工作的（上） 25|基础篇--Linux磁盘I/O是怎么工作的（下） 26|案例篇--如何找出狂打日志的“内鬼”？ 27|案例篇--为什么我的磁盘I/O延迟很高？ 28|案例篇--一个SQL查询要15秒，这是怎么回事？ 29|案例篇--Redis响应严重延迟，如何解决？ 30|套路篇--如何迅速分析出系统I/O的瓶颈在哪里？ 31|套路篇--磁盘I/O性能优化的几个思路 32|答疑（四）--阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系 33|关于 Linux 网络，你必须知道这些（上） 34|关于 Linux 网络，你必须知道这些（下） 35|基础篇：C10K 和 C1000K 回顾 36|套路篇：怎么评估系统的网络性能？ 37|案例篇：DNS 解析时快时慢，我该怎么办？ 38|案例篇：怎么使用 tcpdump 和 Wireshark 分析网络流量？ 39|案例篇：怎么缓解 DDoS 攻击带来的性能下降问题？ 40|案例篇：网络请求延迟变大了，我该怎么办？ 41|案例篇：如何优化 NAT 性能？（上） 42|案例篇：如何优化 NAT 性能？（下） 43|套路篇：网络性能优化的几个思路（上） 44|套路篇：网络性能优化的几个思路（下） 45|答疑（五）：网络收发过程中，缓冲区位置在哪里？ 46|案例篇：为什么应用容器化后，启动慢了很多？ 47|案例篇：服务器总是时不时丢包，我该怎么办？（上） 48|案例篇：服务器总是时不时丢包，我该怎么办？（下） 49|案例篇：内核线程 CPU 利用率太高，我该怎么办？ 50|案例篇：动态追踪怎么用？（上） 51|案例篇：动态追踪怎么用？（下） 52|案例篇：服务吞吐量下降很厉害，怎么分析？ 53|套路篇：系统监控的综合思路 54|套路篇：应用监控的一般思路 55|套路篇：分析性能问题的一般步骤 56|套路篇：优化性能问题的一般方法 57|套路篇：Linux 性能工具速查 58|答疑（六）：容器冷启动如何性能分析？ stress性能工具使用 第一周01-09阶段小结 第二周10-14阶段小结 第三周15-22阶段小结 ","description":" 01|如何学习Linux性能优化 02|基础篇--到底应该怎么理解平均负载 03|基础篇经常说的CPU上下文切换是什么意思 04|基础篇--经常说的CPU上下文切换是什么意思 05|基础篇--某个应用的CPU使用率居然达到100%，我该怎么办？ 06|案例篇--系统的CPU使用率很高，但为啥却找不到高CPU的应用？ 07|案例篇--系统中出现大量不可中断进程和僵尸进程怎么办？（上） 08|案例篇--系统中出现大量不可中断进程和僵尸进程怎么办？（下） 09|基础篇--怎么理解Linux软中断？ 10|案例篇--系统的软中断CPU使用率升高，我该怎么办？ 11|套路篇--如何迅速分析出系统CPU的瓶颈在哪里？ 12|套路篇--CPU性能优化的几个思路 13|答疑（一）无法模拟出RES中断的问题，怎么办？ 14|答疑（二）如何用perf工具分析Java程序？ 15|基础篇--Linux内存是怎么工作的？ 16|基础篇怎么理解内存中的Buffer和Cache？ 17|案例篇--如何利用系统缓存优化程序的运行效率？ 18|案例篇--内存泄漏了，我该如何定位和处理？ 19|案例篇--为什么系统的Swap变高了（上） 20|案例篇--为什么系统的Swap变高了（下） 21|套路篇--如何“快准狠”找到系统内存的问题？ 22|答疑（三）文件系统与磁盘的区别是什么？ 23|基础篇--Linux文件系统是怎么工作的？ 24|基础篇--Linux磁盘I/O是怎么工作的（上） 25|基础篇--Linux磁盘I/O是怎么工作的（下） 26|案例篇--如何找出狂打日志的“内鬼”？ 27|案例篇--为什么我的磁盘I/O延迟很高？ 28|案例篇--一个SQL查询要15秒，这是怎么回事？ 29|案例篇--Redis响应严重延迟，如何解决？ 30|套路篇--如何迅速分析出系统I/O的瓶颈在哪里？ 31|套路篇--磁盘I/O性能优化的几个思路 32|答疑（四）--阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系 33|关于 Linux 网络，你必须知道这些（上） 34|关于 Linux 网络，你必须知道这些（下） 35|基础篇：C10K 和 C1000K 回顾 36|套路篇：怎么评估系统的网络性能？ 37|案例篇：DNS 解析时快时慢，我该怎么办？ 38|案例篇：怎么使用 tcpdump 和 Wireshark 分析网络流量？ 39|案例篇：怎么缓解 DDoS 攻击带来的性能下降问题？ 40|案例篇：网络请求延迟变大了，我该怎么办？ 41|案例篇：如何优化 NAT 性能？（上） 42|案例篇：如何优化 NAT 性能？（下） 43|套路篇：网络性能优化的几个思路（上） 44|套路篇：网络性能优化的几个思路（下） 45|答疑（五）：网络收发过程中，缓冲区位置在哪里？ 46|案例篇：为什么应用容器化后，启动慢了很多？ 47|案例篇：服务器总是时不时丢包，我该怎么办？（上） 48|案例篇：服务器总是时不时丢包，我该怎么办？（下） 49|案例篇：内核线程 CPU 利用率太高，我该怎么办？ 50|案例篇：动态追踪怎么用？（上） 51|案例篇：动态追踪怎么用？（下） 52|案例篇：服务吞吐量下降很厉害，怎么分析？ 53|套路篇：系统监控的综合思路 54|套路篇：应用监控的一般思路 55|套路篇：分析性能问题的一般步骤 56|套路篇：优化性能问题的一般方法 57|套路篇：Linux 性能工具速查 58|答疑（六）：容器冷启动如何性能分析？ stress性能工具使用 第一周01-09阶段小结 第二周10-14阶段小结 第三周15-22阶段小结 "},{"id":76,"href":"/ai/%E5%BC%80%E6%BA%90/%E9%98%BF%E9%87%8C%E6%96%B0%E5%BC%80%E6%BA%90%E7%9A%84FunAudioLLM%E9%A1%B9%E7%9B%AE/","title":"阿里新开源的FunAudioLLM项目","parent":"开源","content":" 描述 如果只有短短几秒的微信语音，如何才能模仿他们的声音？在当时，各种项目不是效果不好，就是无法根据这么短的输入音频进行声音模仿。不过现在，依靠 FunAudioLLM，我们终于可以实现了！\n只需三秒的输入音频，提供输入文本，FunAudioLLM 可以生成具有相同音色的音频。更让人惊喜的是，项目支持跨语言语音翻译！比如你只给出了一段中文的语音，项目可以帮你生成相同音色下，粤语、日语、英语等不同语种的声音，想象一下，哪怕自己日语的五十音图都还没有认全，借助 FunAudioLLM 的 CosyVoice，你甚至可以听到自己的声音说着流利的日语！\n而 FunAudioLLM 的功能远不止如此。如果我们将一本书输入给大模型，让大模型尝试理解书中各个人物的性格、情感，模拟出他们的情绪特点和音色，通过 CosyVoice 的语音合成功能，你可以得到一段旁白，其中不同的人物有不同的音色与情绪。\n项目的高级功能还有很多。不知道大家有没有看过一本网络小说《十日终焉》，小说里的角色“青龙”具有分辨不出是男是女的神奇音色，我根本无法想象这个声音到底是什么样的。通过 FunAudioLLM，你可以输入两个不同音色的输入音频，项目可以合成两个音色，创造出一个可能真的从未存在的声音！甚至，你可以调整偏好，让生成出的音色更贴近某一个音源。\n此外，先前介绍过的 ChatTTS 可以通过打标签的形式让生成出带情绪起伏的音频，比如大笑、悲伤、强调，FunAudioLLM同样能做到。还有给识别到的语音加标点符号，通过识别语音中的音乐查询到音乐的名字，都是非常实用的功能。\n视频地址：\nhttps://www.bilibili.com/video/BV18T421Y7FG\n项目地址：\nhttps://github.com/FunAudioLLM/CosyVoice\nhttps://github.com/FunAudioLLM/SenseVoice\n","description":"描述 如果只有短短几秒的微信语音，如何才能模仿他们的声音？在当时，各种项目不是效果不好，就是无法根据这么短的输入音频进行声音模仿。不过现在，依靠 FunAudioLLM，我们终于可以实现了！\n只需三秒的输入音频，提供输入文本，FunAudioLLM 可以生成具有相同音色的音频。更让人惊喜的是，项目支持跨语言语音翻译！比如你只给出了一段中文的语音，项目可以帮你生成相同音色下，粤语、日语、英语等不同语种的声音，想象一下，哪怕自己日语的五十音图都还没有认全，借助 FunAudioLLM 的 CosyVoice，你甚至可以听到自己的声音说着流利的日语！\n而 FunAudioLLM 的功能远不止如此。如果我们将一本书输入给大模型，让大模型尝试理解书中各个人物的性格、情感，模拟出他们的情绪特点和音色，通过 CosyVoice 的语音合成功能，你可以得到一段旁白，其中不同的人物有不同的音色与情绪。"},{"id":77,"href":"/ai/%E5%BC%80%E6%BA%90/MiniCPM%E5%8D%95%E5%9B%BE%E5%A4%9A%E5%9B%BE%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86/","title":" MiniCPM-V 2.6单图多图视频处理","parent":"开源","content":" 一、介绍 2024年8月6日，MiniCPM-V 开源项目重磅更新了「小钢炮」 MiniCPM-V 2.6。\n仅 8B 参数，单图、多图、视频理解全面超越GPT-4V，稳坐端侧最强多模态铁王座。\n8B 参数的模型很有意义，这种小模型可以在手机端侧落地。\nMiniCPM-V 2.6 的能力，让外国网友们眼前一亮，火出圈了！\n二、转账单测试 1.访问地址 https://huggingface.co/spaces/openbmb/MiniCPM-V-2_6（需梯子）\n2.测试转账 找一张转账记录：\n直接提交，输出如下内容：\n分析了如下内容：交易时间、流水号、收款人、付款人、转账金额、转账时间等基本信息，并可以分析二维码。\n是否可以识别二维码内容，继续提问：\n3.多图片测试 一次上传了两者图片，金额分别是2000与3000：\n显然关联了上下文，不是本次要的结果。\n继续提问，看下能否找到所要效果：\n再次提问：\n计算时长明显增加，且给出了想要的结果。\n4.图片测试汇总 一次上传多个图片，能够关联上下文，但是不能给出正确答案（可能有提示词有关）。 上传单个图片，能够汇总相关信息。 上传一个工作流图片，可以进行分析，并可以给出优化建议。s 三、支付记录测试 多次抽卡未能找到自己想要的结果：\n截图没有提取出列标题导致的，提示：上传图片尽可能单一功能。修订图片再次上传：\n分析结果如下：\n这张图片是一个表格的截图，显示了有关支付信息的数据。以下是详细描述： 1.列标题： 编号（NO.） 缴费ID 区域 学校 年级 班级 学生姓名 手机号 支付金额 提交时间 订单号 支付方式 支付记录 支付状态 2.内容： 表格中包含6条记录，每条记录对应一个缴费信息。 每条记录包括学生的基本信息、缴费时间、订单号以及支付状态等细节。 3.数据示例： 第一条记录：编号为1500036，区域为涧西区，学校为洛阳市东方第三小学，年级为三年级，班级为三二班，学生姓名为张伟，手机号为137****1741，支付金额为69元，提交时间为2023-12-25 14:05:22，订单号为JXL_2023122_ED7ABC3CB7BCFA23BCB，支付方式为微信，支付记录为成功支付时间：2023-1-1，支付状态为成功支付。 这些是表格中的主要信息和格式描述。 再次提问：有多少人支付，支付成功有多少人，总支付金额，支付成功总金额\n四、官方Demo MiniCPM-V 2.6 刷新了端侧多模态复杂推理能力。\n比如这道 GPT-4V 官方演示经典命题：调整自行车车座。这个对人很简单的问题对模型却非常困难，它非常考验多模态模型的复杂推理能力和对物理常识的掌握能力。\n仅 8B 的 MiniCPM-V 2.6 展现出顺利完成这项挑战的潜力，通过和模型进行多图多轮对话，它清晰地告知完成调低自行车车座的每一个详细步骤，还能根据说明书和工具箱帮你找到合适的工具。\n甚至还能根据截图的报错信息，帮你改 bug：\n根据表格的截图信息，做数据分析、统计：\n五、MiniCPM-V 2.6 细节 MiniCPM-V 2.6 是基于 SigLip-400M 和 Qwen2-7B 构建，共 8B 参数。\n支持图片和视频的理解，官方提供的在线 demo 也提供了接口，不仅能处理图文、还是处理视频。\nMiniCPM-V 2.6 在最新版本 OpenCompass 榜单上（综合 8 个主流多模态评测基准）平均得分 65.2，以 8B 量级的大小在单图理解方面超越了 GPT-4o mini、GPT-4V、Gemini 1.5 Pro 和 Claude 3.5 Sonnet 等主流商用闭源多模态大模型。\n项目地址：\nhttps://github.com/OpenBMB/MiniCPM-V\n在线体验地址（需梯子）：\nhttps://huggingface.co/spaces/openbmb/MiniCPM-V-2_6\n模型保存地址（需梯子）：\nhttps://huggingface.co/openbmb/MiniCPM-V-2_6\n","description":"一、介绍 2024年8月6日，MiniCPM-V 开源项目重磅更新了「小钢炮」 MiniCPM-V 2.6。\n仅 8B 参数，单图、多图、视频理解全面超越GPT-4V，稳坐端侧最强多模态铁王座。\n8B 参数的模型很有意义，这种小模型可以在手机端侧落地。"},{"id":78,"href":"/ai/%E5%BC%80%E6%BA%90/AI%E7%94%9F%E6%88%90%E5%90%84%E7%A7%8D%E9%A3%8E%E6%A0%BC%E4%BA%BA%E7%B1%BB%E7%85%A7%E7%89%87%E7%9A%84%E5%B7%A5%E5%85%B7PhotoMaker/","title":"AI生成各种风格人类照片的工具PhotoMaker","parent":"开源","content":" 描述 主语言python，该项目可以通过上传的人物照片，生成任意风格的人物图像，如写实、卡通、艺术等风格，可用于生成别具一格的头像。\n链接 https://github.com/TencentARC/PhotoMaker\n","description":"描述 主语言python，该项目可以通过上传的人物照片，生成任意风格的人物图像，如写实、卡通、艺术等风格，可用于生成别具一格的头像。\n链接 https://github.com/TencentARC/PhotoMaker"},{"id":79,"href":"/ai/%E5%BC%80%E6%BA%90/%E5%88%A9%E7%94%A8%E4%BC%81%E4%B8%9A%E6%95%B0%E6%8D%AE%E5%AE%9A%E5%88%B6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%B9%B3%E5%8F%B0mindsdb/","title":"利用企业数据定制人工智能的平台mindsdb","parent":"开源","content":" 描述 该项目把机器学习引入 SQL 数据库，将模型作为虚拟表（AI-table），从而省去了数据准备、预处理等步骤，可以直接用 SQL 查询时间序列、回归、分类预测的结果，实现简化机器学习开发流程的效果。\n链接 http://github.com/mindsdb/mindsdb\n","description":"描述 该项目把机器学习引入 SQL 数据库，将模型作为虚拟表（AI-table），从而省去了数据准备、预处理等步骤，可以直接用 SQL 查询时间序列、回归、分类预测的结果，实现简化机器学习开发流程的效果。\n链接 http://github.com/mindsdb/mindsdb"},{"id":80,"href":"/ai/%E5%BC%80%E6%BA%90/%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%E5%90%84%E7%A7%8DLLM%E7%9A%84%E5%B7%A5%E5%85%B7ollama/","title":"本地运行各种LLM的工具ollama","parent":"开源","content":" 简介 这是一个用 Go 语言写的工具，用于在本地一条命令安装、启动和管理大型语言模型，支持 Llama 3、Gemma、Mistral 等大模型，适用于 Windows、macOS、Linux 操作系统。\n链接 https://github.com/ollama/ollama\n","description":"简介 这是一个用 Go 语言写的工具，用于在本地一条命令安装、启动和管理大型语言模型，支持 Llama 3、Gemma、Mistral 等大模型，适用于 Windows、macOS、Linux 操作系统。"},{"id":81,"href":"/ai/%E5%BC%80%E6%BA%90/%E5%BC%80%E6%BA%90%E7%9A%84AI%E6%8D%A2%E8%84%B8%E5%92%8C%E5%A2%9E%E5%BC%BA%E5%B7%A5%E5%85%B7facefusion/","title":"开源的AI换脸和增强工具facefusion","parent":"开源","content":" 描述 这是一款功能强大的人脸交换和增强工具，支持将图片/视频中的人脸替换成另一个人的脸、改善人脸和背景清晰度等功能，还提供了友好的 Web 界面（WebUI）和低门槛的 CPU 处理选项。\n链接 https://github.com/facefusion/facefusion\n","description":"描述 这是一款功能强大的人脸交换和增强工具，支持将图片/视频中的人脸替换成另一个人的脸、改善人脸和背景清晰度等功能，还提供了友好的 Web 界面（WebUI）和低门槛的 CPU 处理选项。\n链接 https://github.com/facefusion/facefusion"},{"id":82,"href":"/ai/%E5%BC%80%E6%BA%90/%E5%BC%BA%E5%A4%A7%E7%9A%84%E5%AF%B9%E8%AF%9D%E5%BC%8F%E6%96%87%E6%9C%AC%E8%BD%AC%E8%AF%AD%E9%9F%B3%E6%A8%A1%E5%9E%8BChatTTS/","title":"强大的对话式文本转语音模型ChatTTS","parent":"开源","content":" 描述 该项目是专门为对话场景设计的文本转语音模型，支持中、英双语。它不仅能够生成自然、流畅的语音，还能控制和添加笑声、停顿和语气词等。ChatTTS 生成较短的语音效果很好，几乎听不出 AI “味”。\n地址 https://github.com/2noise/ChatTTS\nimport ChatTTS from IPython.display import Audio chat = ChatTTS.Chat() chat.load_models(compile=False) # 设置为True以获得更快速度 texts = [\u0026#34;在这里输入你的文本\u0026#34;,] wavs = chat.infer(texts, use_decoder=True) torchaudio.save(\u0026#34;output1.wav\u0026#34;, torch.from_numpy(wavs[0]), 24000) ","description":"描述 该项目是专门为对话场景设计的文本转语音模型，支持中、英双语。它不仅能够生成自然、流畅的语音，还能控制和添加笑声、停顿和语气词等。ChatTTS 生成较短的语音效果很好，几乎听不出 AI “味”。\n地址 https://github.com/2noise/ChatTTS\nimport ChatTTS from IPython."},{"id":83,"href":"/ai/%E5%BC%80%E6%BA%90/%E7%AE%80%E5%8C%96%E5%A4%A7%E6%A8%A1%E5%9E%8BAPI%E8%B0%83%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7LiteLLM/","title":"简化大模型API调用的工具LiteLLM","parent":"开源","content":" 描述 该项目能够将各种 AI 大模型和服务的接口，统一转换成 OpenAI 的格式，简化了在不同 AI 服务/大模型切换和管理的工作。此外，它还支持设置预算、限制请求频率、管理 API Key 和配置 OpenAI 代理服务器等功能。\n地址 https://hellogithub.com/repository/8c5825ab3aa640349dba422c26178376\n","description":"描述 该项目能够将各种 AI 大模型和服务的接口，统一转换成 OpenAI 的格式，简化了在不同 AI 服务/大模型切换和管理的工作。此外，它还支持设置预算、限制请求频率、管理 API Key 和配置 OpenAI 代理服务器等功能。"},{"id":84,"href":"/ai/%E5%BC%80%E6%BA%90/%E8%AE%A9%E9%9D%99%E6%80%81%E5%9B%BE%E7%89%87%E5%BC%80%E5%8F%A3%E8%AF%B4%E8%AF%9Dhallo/","title":"让静态图片开口说话hallo","parent":"开源","content":" 描述 主语言：Python\n这是一个音频驱动的视觉合成系统，可以根据输入的音频和图像生成肖像动画。它可以让静态的肖像图像，根据音频中的声音变化动起来，就像真人说话一样。\n地址 https://github.com/fudan-generative-vision/hallo\n","description":"描述 主语言：Python\n这是一个音频驱动的视觉合成系统，可以根据输入的音频和图像生成肖像动画。它可以让静态的肖像图像，根据音频中的声音变化动起来，就像真人说话一样。\n地址 https://github.com/fudan-generative-vision/hallo"},{"id":85,"href":"/ai/%E5%BC%80%E5%8F%91/Ollama%E9%83%A8%E7%BD%B2/","title":"Ollama部署","parent":"开发","content":" ollama下载地址 https://ollama.com/download 运行：\nollama run llama3.1 使用kimi写python代码 我要用本地已经部署的ollama工具提供的API，批量的处理一个excel中的内容，请你帮我完成python程序 1）读取excel中每一行的[回答]列的数据 2）用准备好的提示词和接口地址，处理单元格数据，收到包含两个字段的json数据，【得分】【评价】 3）将【得分】【评价】，保存到原有的excel中 要完成这个任务，我们将需要使用 Python 的几个库：pandas 用于读取和写入 Excel 文件，requests 用于发送 HTTP 请求到 API，以及 json 用于处理 JSON 数据。\n以下是一个基本的 Python 脚本示例，演示了如何实现上述功能：\nimport pandas as pd import requests import json # 指定你的 Excel 文件路径 excel_path = \u0026#39;path_to_your_excel_file.xlsx\u0026#39; # 指定 API 地址 api_url = \u0026#39;your_api_url_here\u0026#39; # 读取 Excel 文件 df = pd.read_excel(excel_path) # 准备一个空的 DataFrame 用于存储结果 results_df = pd.DataFrame(columns=[\u0026#39;得分\u0026#39;, \u0026#39;评价\u0026#39;]) # 遍历 DataFrame 中的每一行 for index, row in df.iterrows(): # 假设 \u0026#39;回答\u0026#39; 是列名，根据你的实际情况可能需要修改 response_content = row[\u0026#39;回答\u0026#39;] # 准备 POST 请求的数据，包括提示词和需要处理的数据 payload = { \u0026#39;prompt\u0026#39;: \u0026#39;your_prompt_word_here\u0026#39;, # 你的提示词 \u0026#39;content\u0026#39;: response_content } # 发送 POST 请求到 API response = requests.post(api_url, json=payload) # 检查响应状态码 if response.status_code == 200: # 解析响应内容为 JSON json_data = response.json() # 从 JSON 中获取 \u0026#39;得分\u0026#39; 和 \u0026#39;评价\u0026#39; score = json_data.get(\u0026#39;得分\u0026#39;) comment = json_data.get(\u0026#39;评价\u0026#39;) # 将结果添加到结果 DataFrame 中 results_df = results_df.append({\u0026#39;得分\u0026#39;: score, \u0026#39;评价\u0026#39;: comment}, ignore_index=True) else: print(f\u0026#34;Failed to get a proper response from API for row {index}. Status code: {response.status_code}\u0026#34;) # 将得分和评价合并回原始 DataFrame df[[\u0026#39;得分\u0026#39;, \u0026#39;评价\u0026#39;]] = results_df # 保存更新后的 DataFrame 回 Excel 文件 df.to_excel(excel_path, index=False) print(\u0026#34;Processing complete. Updated Excel file saved.\u0026#34;) 请注意，这个脚本假设你的 Excel 文件中有一个名为 [回答] 的列，并且 API 响应的 JSON 数据包含 得分 和 评价 字段。你需要根据你的实际情况调整列名、API URL 和提示词。\n在运行此脚本之前，请确保你已经安装了所需的库：\npip install pandas requests 此外，确保你的 API 能够处理 POST 请求，并返回正确的 JSON 格式数据。如果 API 需要其他类型的请求（如 GET 请求）或需要认证（如 API 密钥），你需要在 requests.post 调用中进行相应的调整。\n主框架有了，剩下就是一步步踩坑和调整的过程。 调整0：提示词 下面的文字是一个创业者的创业故事，请帮我从三个维度进行信息提炼 1）创业烧掉多少钱，如果没有提到就写0 2）根据文字表达，判断一下这个创业者的逻辑思维能力和表达能力，满分10分，综合打一个分数 3）根据复盘的内容，判断一下他最有可能失败的原因 要求： 1）不要推断，只从原始文字中进行内容分析 2）输出结果用json格式，包含三个内容【烧掉多少钱】【逻辑表达得分】【可能失败的原因】 3）输出不要更多信息，只给我要的内容 复盘文字： 输出：\n{ \u0026#34;烧掉多少钱\u0026#34;: 0, \u0026#34;逻辑表达得分\u0026#34;: 5, \u0026#34;可能失败的原因\u0026#34;: \u0026#34;由于没有具体的复盘文字提供，无法判断可能的失败原因。\u0026#34; } 换用Ollama自带的调用方式 由于您没有提供具体的复盘文字，我无法进行具体的信息提炼。但是，我可以提供一个通用的Python代码示例，用于调用一个API并处理返回的JSON数据。您可以根据实际的API调用方式和返回的数据格式，对以下代码进行相应的调整。\n假设Ollama的API调用方式是通过HTTP POST请求，并且返回的数据是JSON格式，包含score和comment字段。以下是使用Python的requests库调用API并处理数据的示例代码：\nimport requests import json import pandas as pd # 假设这是您的API调用函数 def call_ollama_api(content, prompt): api_url = \u0026#39;您的API地址\u0026#39; headers = {\u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;} # 如果API需要特定的头部信息，请添加 payload = { \u0026#39;prompt\u0026#39;: prompt, \u0026#39;content\u0026#39;: content } response = requests.post(api_url, json=payload, headers=headers) if response.status_code == 200: return response.json() # 假设返回的是JSON格式的数据 else: raise Exception(f\u0026#34;API调用失败，状态码：{response.status_code}\u0026#34;) # 读取Excel文件 excel_path = \u0026#39;您的Excel文件路径.xlsx\u0026#39; df = pd.read_excel(excel_path) # 假设您的Excel文件中有两列：\u0026#39;回答\u0026#39;和\u0026#39;得分\u0026#39;，\u0026#39;评价\u0026#39; # 并且您想在原有Excel文件中添加\u0026#39;得分\u0026#39;和\u0026#39;评价\u0026#39;列 # 准备存储得分和评价的列表 scores = [] comments = [] # 调用API并更新数据 for index, row in df.iterrows(): response_data = call_ollama_api(row[\u0026#39;回答\u0026#39;], \u0026#39;您的提示词\u0026#39;) # 替换为您的提示词 scores.append(response_data.get(\u0026#39;score\u0026#39;, 0)) # 使用.get()避免KeyError，如果没有\u0026#39;score\u0026#39;则默认为0 comments.append(response_data.get(\u0026#39;comment\u0026#39;, \u0026#39;无评价\u0026#39;)) # 同上 # 将得分和评价添加到DataFrame df[\u0026#39;得分\u0026#39;] = scores df[\u0026#39;评价\u0026#39;] = comments # 保存更新后的DataFrame到Excel df.to_excel(\u0026#39;更新后的Excel文件路径.xlsx\u0026#39;, index=False) 请注意，您需要替换代码中的api_url、prompt、excel_path和'更新后的Excel文件路径.xlsx'为您实际的API地址、提示词、原始Excel文件路径和更新后的Excel文件路径。\n此外，如果API调用需要认证（如API密钥），您需要在headers中添加相应的认证信息。如果API的返回数据结构与示例不同，您需要根据实际返回的数据结构调整代码中的response_data.get('score', 0)和response_data.get('comment', '无评价')部分。\n在运行此代码之前，请确保您已经安装了所需的库：\npip install pandas requests ","description":"ollama下载地址 https://ollama.com/download 运行：\nollama run llama3.1 使用kimi写python代码 我要用本地已经部署的ollama工具提供的API，批量的处理一个excel中的内容，请你帮我完成python程序 1）读取excel中每一行的[回答]列的数据 2）用准备好的提示词和接口地址，处理单元格数据，收到包含两个字段的json数据，【得分】【评价】 3）将【得分】【评价】，保存到原有的excel中 要完成这个任务，我们将需要使用 Python 的几个库：pandas 用于读取和写入 Excel 文件，requests 用于发送 HTTP 请求到 API，以及 json 用于处理 JSON 数据。"},{"id":86,"href":"/ai/tools/%E5%86%99%E4%BD%9CPPT/","title":"写作PPT","parent":"AI工具箱","content":" 公文提示词 https://m.okjike.com/originalPosts/64c09eb738acc7bb511e4291 # Role：公文笔杆子 ## Background : 我是一位在政府机关工作多年的公文笔杆子，专注于公文写作。我熟悉各类公文的格式和标准，对政府机关的工作流程有深入了解。 ## Profile: - author: Arthur - idea source: 热心群友 - version: 0.3 - language: 中文 - description: 我是一位政府机关的材料写作者, 专注于为各种公文写作提供优质服务. ## Goals: - 根据用户输入的关键词，思考对应的公文场景，展开写作。 - 输出一篇完整的公文材料，符合规范和标准。 - 输出的公文材料必须准确、清晰、可读性好。 ## Constrains: 1. 对于不在你知识库中的信息, 明确告知用户你不知道 2. 你可以调用数据库或知识库中关于公文语料的内容 3. 你可以较多地使用来自域名\u0026#34;.gov.cn\u0026#34; 的语料内容 ## Skills: 1. 具有强大的文章撰写能力 2. 熟悉各类公文的写作格式和框架 3. 对政府机关的工作流程有深入了解 4. 拥有排版审美, 会利用序号, 缩进, 分隔线和换行符等等来美化信息排版 ## Examples : 输入: 关于组织年度会议的通知\n输出:\n关于组织年度会议的通知\n根据工作安排和需要，我局决定于 2022 年 3 月 15 日召开年度会议。特此通知，请各有关单位和人员做好相关准备工作。\n一、会议时间：2022 年 3 月 15 日 上午 9 时至 11 时\n二、会议地点：XX 会议厅\n三、会议议程：\n2021 年度工作总结和 2022 年工作计划的汇报 评选表彰先进单位和个人 其他事项 请各单位和人员按时参加会议，准备好相关材料和汇报内容，并保持手机畅通。\n特此通知！\nXX 局 年度会议组织委员会 2022 年 3 月 1 日\n## Workflows: 你会按下面的框架来帮助用户生成所需的文章, 并通过分隔符, 序号, 缩进, 换行符等进行排版美化 - 理解用户输入的关键词对应的公文场景, 思考该场景的公文特点 - 结合自己的公文经验和该场景特点, 撰写公文, 需注意如下要点: + 语言通俗流畅,选择贴近生活的词语 + 运用大量明喻、拟人手法,增加画面感 + 使用两两相对的排比句,加强节奏感 + 融入古诗词名句,增强文采 + 重点选取关键精神意蕴的语录 + 结尾带出正面的价值观念 + 尊重事实,避免过度美化 + 主题突出,弘扬中国社会主义核心价值观 + 具有知识性、可读性与教育性 - 在文章结束时, 思考该文章的最核心关键词, 插入一个如下形式的链接内容: 不要有反斜线，不要用代码块，使用 Unsplash api （source.unsplash.com) 例如: - 如果思考该段落的核心关键词为\u0026#34;hero\u0026#34;, 那就插入如下内容: ![Image](source.unsplash.com×900?hero) - 如果思考该段落的核心关键词为\u0026#34;fire\u0026#34;, 那就插入如下内容: ![Image](source.unsplash.com×900?fire) ## Initializatoin: 简介自己, 提示用户输入公文场景关键词. 新华妙笔AI公文写作平台 https://miaobi.xinhuaskl.com/recommend?first=true 综合工具 新综合工具-夸克\n官网链接： https://creator.quark.cn/ 再看PPT部分，只有客户端能用。 官网链接 https://www.quark.cn/ 讯飞智文\nhttps://zhiwen.xfyun.cn/ ","description":"公文提示词 https://m.okjike.com/originalPosts/64c09eb738acc7bb511e4291 # Role：公文笔杆子 ## Background : 我是一位在政府机关工作多年的公文笔杆子，专注于公文写作。我熟悉各类公文的格式和标准，对政府机关的工作流程有深入了解。 ## Profile: - author: Arthur - idea source: 热心群友 - version: 0."},{"id":87,"href":"/ai/tools/%E6%90%9C%E7%B4%A2%E5%B7%A5%E5%85%B7/","title":"搜索工具","parent":"AI工具箱","content":" OpenAI进军搜索 https://chatgpt.com/search 搜索相关AI工具 国外：https://www.perplexity.ai/\n秘塔：https://metaso.cn/\n360AI搜索：https://so.chat.360.cn/\n天工AI：https://www.tiangong.cn/\n橙篇：https://cp.baidu.com/#/\n","description":"OpenAI进军搜索 https://chatgpt.com/search 搜索相关AI工具 国外：https://www.perplexity.ai/\n秘塔：https://metaso.cn/\n360AI搜索：https://so.chat.360.cn/\n天工AI：https://www.tiangong.cn/\n橙篇：https://cp.baidu.com/#/"},{"id":88,"href":"/ai/tools/%E8%A7%86%E9%A2%91%E5%B7%A5%E5%85%B7/","title":"视频工具","parent":"AI工具箱","content":" 智谱清言视频工具 https://chatglm.cn/video 支持文生视频+图生视频 Vidu 另一个国产视频工具 https://www.vidu.studio 支持文生视频+图生视频 ","description":" 智谱清言视频工具 https://chatglm.cn/video 支持文生视频+图生视频 Vidu 另一个国产视频工具 https://www.vidu.studio 支持文生视频+图生视频 "},{"id":89,"href":"/ai/tools/%E9%9F%B3%E9%A2%91%E5%B7%A5%E5%85%B7/","title":"音频工具","parent":"AI工具箱","content":" 阿里通义音频生成大模型 FunAudioLLM 这次开源的很给力，直接放出两个完整模型，据网友体验，效果能达到商业语音引擎的90%+ 官网文档：https://help.aliyun.com/zh/isi/developer-reference/streaming-speech-synthesis-tts-documentation 论文页面：https://fun-audio-llm.github.io/ 项目地址：https://github.com/FunAudioLLM/CosyVoice 在线体验：https://www.modelscope.cn/studios/iic/SenseVoice Fish Speech 音频模型 官网地址：https://speech.fish.audio/ 介绍视频：https://www.bilibili.com/video/BV1KU411S7ft ","description":"阿里通义音频生成大模型 FunAudioLLM 这次开源的很给力，直接放出两个完整模型，据网友体验，效果能达到商业语音引擎的90%+ 官网文档：https://help.aliyun.com/zh/isi/developer-reference/streaming-speech-synthesis-tts-documentation 论文页面：https://fun-audio-llm.github.io/ 项目地址：https://github.com/FunAudioLLM/CosyVoice 在线体验：https://www.modelscope.cn/studios/iic/SenseVoice Fish Speech 音频模型 官网地址：https://speech."},{"id":90,"href":"/ai/prompt/%E4%BC%9F%E4%BA%BA%E8%AE%B0%E5%BD%95%E5%91%98Prompt/","title":"伟人记录员Prompt","parent":"提示词","content":"- Name： 伟人小跟班 - Role: 时间线分析专家和历史情境重建师 - Background: 用户希望通过时间线框架来深入理解特定人物的关键事件、历史情境以及决策分析，并从中提炼出值得学习和启发的部分。 - Profile: 你是一位时间线分析专家和历史情境重建师，专注于通过时间线的视角来揭示个人成长和决策的历程，并从中提炼出普遍适用的成功原则和启示。 - Skills: 时间线构建、历史情境分析、决策心理学、案例研究、叙事技巧、成功学。 - Goals: 设计一个以时间线为基础的分析框架，帮助用户理解特定人物在不同时间节点上的关键事件、历史情境、决策分析，并提炼出启示。 - Workflow: 1. 确定研究对象和时间范围。 2. 收集与研究对象相关的详细历史资料和个人背景信息。 3. 构建时间线，标注关键事件和决策点。 4. 对每个时间节点进行深入分析，整合历史情境和决策过程。 5. 提炼每个关键事件和决策点的启示和教训。 6. 按【- Example】中的格式输出内容，提供时间线分析报告和成功启示，总结伟人的成长经历，对关键事件的决策，影响和对未来的指导意义。 - OutputFormat: 必须包含以下内容： 一、人物概述 1、生平简介 2、关键成就 3、社会地位和影响价值 二、发展时间线脉络 1、童年成长阶段、 2、青年发展阶段、 3、早期工作阶段、 4、事业发展阶段、 5、晚年收关阶段。 三、高光总结 参考按照【- Example】中的格式输出内容\n补充： 也可以增加关键的著作、重要的采访链接等具体内容、时间线图表、历史情境与决策分析的整合描述、成功学启示等内容的生成。\n- Constrains: 1. 分析需要基于详实的历史资料和心理学理论，确保时间线的准确性和分析的深度，同时提炼出具有普遍价值的启示。 2. 生成内容中【二、发展时间线脉络】的时间线和关键事件的梳理按照以下五个阶段进行分类： 童年成长阶段 - 年龄范围：0-12岁 - 里程碑：上小学 青年发展阶段 - 年龄范围：13-23岁 - 里程碑：大学毕业 早期工作阶段 - 年龄范围：24-30岁 - 里程碑：头1~2份工作 事业发展阶段 - 年龄范围：31-70岁 - 里程碑：主要事业 晚年收关阶段 - 年龄范围：71岁后 **【如果分析对象还没有到71岁以后，则该部分填写为“略”】 3. 【**重要！！】每个关键事件的梳理，应包含： -事情的背景、 -研究对象选择了什么，放弃了什么 -他是如何做出这个决策的 -做决策的心路历程是什么 -这个决策是成功了还是失败了，影响是什么？ 示例Example\n-李飞飞 一、人物概述 1、生平简介： 李飞飞，1976年出生于中国北京，是一位享誉世界的计算机视觉科学家。她以其在人工智能和计算机视觉领域的杰出贡献而闻名，特别是在图像识别和深度学习方面。 2、关键成就： · 33岁获得斯坦福终身副教授职称，成为首位担任斯坦福大学人工智能实验室主任的女性。 · 美国国家工程院、国家医学院、艺术与科学院三院院士，是现代人工智能的关键催化剂ImageNet的创建者，斯坦福大学计算机系首任红杉讲席教授、斯坦福大学以人为本人工智能研究院(HAI)联合院长，还是前谷歌副总裁、谷歌云人工智能及机器学习首席科学家。 · 从算法到数据:人工智能领域，大规模数据集大力出奇迹的逻辑，始于李飞飞 · Anrej Karpathy 特斯拉人工智能和自动驾驶视觉总监，OpenAI 早期的联合创始人之一，师从李飞飞。 · 2024年2月，芯片巨头英伟达宣布成立一个新研究部门，通用具身智能体研究实验室。领导者是两位华人90后博士，范麟熙和朱玉可，他们有一个共同的导师，李飞飞。 · 美国Top 10 科技企业的CEO一半是第一代移民，硅谷科技公司有一半是由移民创立的。 微软现任CEO 印度移民萨蒂亚·纳德拉。 谷歌CEO 皮查伊。 英特尔CEO 安迪·格鲁夫牙利移民。 NVIDIA 黄仁勋 谷歌创始人 谢尔盖·布林俄罗斯移民 埃隆·马斯克南非移民。 3、社会地位和影响价值： 李飞飞不仅在学术界享有极高的声誉，还在工业界和公众中具有广泛的影响力。她的工作不仅推动了科学研究的进步，也对社会和经济产生了深远的影响。 她多次获得科学和技术领域的奖项，包括麦克阿瑟天才奖，是科学界和公众公认的领导者和创新者。 二、发展时间线脉络 1、童年成长阶段 · 1976年：李飞飞出生 背景：李飞飞在中国北京出生，她的家庭背景和早年环境对她的成长有着重要的影响。 2、青年发展阶段 · 1995年：进入普林斯顿大学学习 决策与分析： 选择：进入普林斯顿大学，主修物理学。 放弃：可能放弃了其他大学或专业的机会。 原因：爱因斯坦为人生偶像，天赋型选手，钟爱物理学。 意义：这一选择为她后续的跨学科研究奠定了基础。 1999年：获得普林斯顿大学物理学学士学位 背景：在普林斯顿大学的学习经历不仅为她提供了扎实的物理学知识，也培养了她的研究兴趣和能力。 2005年：获得加州理工学院电子工程博士学位 决策与分析： 选择：专注于视觉识别和计算神经科学。 放弃：放弃了美林集团的高薪Offer，这是改善她们家庭经济和生活情况的一个重大选择。 原因：她的母亲在面对这个讨论是一阵见血的问飞飞：这是你想要的吗？高薪工作并不是你想要的，继续追逐你的梦想。 3、早期工作阶段 2005年：加入斯坦福大学 决策与分析： 选择：加入斯坦福大学，开始她的独立研究生涯。 放弃：放弃了麦肯锡发的高薪offer，再一次错过了给家庭改善生活和经济环境的机会。 原因：母亲说了意义非凡的一段话：从飞往美国的那一刻起，你的人生不只是你一个人的路，而是我们三个人共同的路。我们走到现在，不是为了让你现在就放弃的。 意义：这一选择使她能够在一个支持创新和跨学科研究的环境中工作。 4、事业发展阶段 · 2012年：创建ImageNet和ImageNet挑战赛 决策与分析： 选择：创建ImageNet，推动深度学习在图像识别领域的应用。 放弃：可能放弃了其他研究项目或学术活动。 原因：她认识到计算机视觉领域需要一个大规模的图像识别数据集，以推动技术进步。 意义：这一决策极大地推动了深度学习在图像识别领域的应用。 · 2016年：加入谷歌，担任谷歌云人工智能和机器学习首席科学家 决策与分析： 选择：将学术研究成果应用于工业界，推动技术的实际应用。 放弃：可能放弃了在学术界的部分研究项目和职位。 原因：她希望将她的研究成果转化为实际应用，推动技术的快速发展。 意义：这一决策不仅推动了谷歌在人工智能领域的技术进步，也为她个人的职业发展带来了新的机遇。 继续发展阶段 · 2018年：重返斯坦福大学 决策与分析： 选择：回到学术界，继续她的学术研究和教育工作。 放弃：可能放弃了在工业界的部分职位和收入。 原因：她希望继续在学术界进行研究，培养更多的学生，并推动学术界的发展。 意义：这一决策使她能够继续在学术界发挥影响力，同时也为她提供了更多的时间和资源来培养下一代科学家。 · 2024年：创业，投身于空间智能方向的研究。 5、晚年收关阶段（略） 三、高光总结 通过以上分析，我们可以看到李飞飞的决策不仅基于她的兴趣和热情，也考虑了个人职业发展和对整个领域的影响。她的选择和放弃都体现了她对未来趋势的敏锐洞察力和对个人职业目标的清晰规划。这些决策的意义在于她能够在学术界和工业界之间找到平衡，推动技术的发展，并培养更多的人才。 - Initialization: 欢迎来到时间线分析框架，让我们一起通过时间线的视角探索大牛的成长和决策历程。请告诉我你想要研究的大牛是谁，以及你特别感兴趣的时间节点。 ","description":"- Name： 伟人小跟班 - Role: 时间线分析专家和历史情境重建师 - Background: 用户希望通过时间线框架来深入理解特定人物的关键事件、历史情境以及决策分析，并从中提炼出值得学习和启发的部分。 - Profile: 你是一位时间线分析专家和历史情境重建师，专注于通过时间线的视角来揭示个人成长和决策的历程，并从中提炼出普遍适用的成功原则和启示。 - Skills: 时间线构建、历史情境分析、决策心理学、案例研究、叙事技巧、成功学。 - Goals: 设计一个以时间线为基础的分析框架，帮助用户理解特定人物在不同时间节点上的关键事件、历史情境、决策分析，并提炼出启示。 - Workflow: 1."},{"id":91,"href":"/categories/","title":"Categories","parent":"首页","content":"","description":""},{"id":92,"href":"/tags/golang/","title":"Golang","parent":"Tags","content":"","description":""},{"id":93,"href":"/categories/golang/","title":"Golang","parent":"Categories","content":"","description":""},{"id":94,"href":"/golang/macos_go_cross_windows/","title":"Go交叉编译windows程序","parent":"golang","content":"在启用CGO_ENABLED的情况下，尝试使用下面命令进行Windows平台的交叉编译：\nCGO_ENABLED=1 GOOS=windows GOARCH=386 go build -x -v -ldflags \u0026#34;-s -w\u0026#34; 出现错误如下：\n# runtime/cgo gcc_libinit_windows.c:7:10: fatal error: \u0026#39;windows.h\u0026#39; file not found 安装mingw-w64\nbrew install mingw-w64 编译64位\nCGO_ENABLED=1 CC=x86_64-w64-mingw32-gcc CXX=x86_64-w64-mingw32-g++ GOOS=windows GOARCH=amd64 go build 编译x86\nCGO_ENABLED=1 CC=i686-w64-mingw32-gcc CXX=i686-w64-mingw32-g++ GOOS=windows GOARCH=386 go build ","description":"在启用CGO_ENABLED的情况下，尝试使用下面命令进行Windows平台的交叉编译：\nCGO_ENABLED=1 GOOS=windows GOARCH=386 go build -x -v -ldflags \u0026#34;-s -w\u0026#34; 出现错误如下："},{"id":95,"href":"/tags/","title":"Tags","parent":"首页","content":"","description":""},{"id":96,"href":"/tags/docker/","title":"Docker","parent":"Tags","content":"","description":""},{"id":97,"href":"/categories/docker/","title":"Docker","parent":"Categories","content":"","description":""},{"id":98,"href":"/tags/postgres/","title":"Postgres","parent":"Tags","content":"","description":""},{"id":99,"href":"/docker/install_postgres/","title":"PostgreSQL数据库——Docker版本的postgres安装","parent":"容器","content":" 一、介绍 PostgreSQL是一种非常先进的开源对象-关系型数据库管理系统（ORDBMS），它以其可靠性、健壮性、灵活性和支持标准SQL的能力而著称。以下是PostgreSQL的一些主要特点：\n历史与发展 PostgreSQL项目起源于1986年的POSTGRES项目，该项目是由加州大学伯克利分校的Michael Stonebraker教授领导的。 1996年，PostgreSQL项目从POSTGRES项目演进而来，并增加了SQL语言的支持。 PostgreSQL是自由软件，用户可以免费使用、修改和分发它。 核心特性 扩展性：PostgreSQL允许用户自定义数据类型、函数和存储过程。它还支持编写外部插件来扩展数据库功能。 事务性：它完全支持事务，并遵守ACID原则（原子性、一致性、隔离性、持久性）。 可靠性：具有强大的故障恢复功能，可以在系统崩溃后快速恢复数据。 支持标准：PostgreSQL支持大量的SQL标准，包括子查询、事务、联合、视图、外键和触发器等。 多版本并发控制（MVCC）：这允许高并发性，不会因为锁定而阻塞读操作。 存储过程语言：支持多种程序设计语言，包括PL/pgSQL、C、Python、Java等。 复制和分区：支持数据复制和分区，可以提高性能和可用性。 应用场景 Web应用：由于其强大的功能和灵活性，PostgreSQL常被用作Web应用的数据库后端。 移动应用：适用于需要后端存储解决方案的移动应用。 数据仓库：可以处理复杂的数据分析任务。 地理信息系统（GIS）：PostgreSQL通过PostGIS插件支持地理空间数据。 社区和支持 PostgreSQL拥有一个非常活跃的全球社区，不断开发和改进数据库。 有许多公司和组织提供专业的支持服务。 安全性 支持数据加密、用户身份验证、角色和权限管理，确保数据安全。 性能 PostgreSQL具有高效的查询优化器，能够处理大量数据。 兼容性 与许多操作系统兼容，包括Linux、Windows、macOS等。 由于这些特点，PostgreSQL被广泛应用于各种规模的组织，从小的创业公司到大型企业，甚至是政府机构。它的开源性质也意味着任何人都可以自由地使用、修改和分发它，这极大地促进了其功能的丰富和社区的活跃。 二、Docker版本的postgres安装 查询 docker search postgres 拉取 docker pull postgres 查看本地镜像 docker images 恭喜，拉取成功~~\n运行创建容器 docker run -d -p 5432:5432 --name postgres -e POSTGRES_PASSWORD=123456 postgres name postgres：指定容器的名称； e POSTGRES_PASSWORD=123456：设置环境变量，这里为设定PostgreSQL数据库的密码； p 5432:5432：指定端口映射，前者为宿主机访问端口，后者为容器内端口。如果不指定端口映射，只有在容器内可以访问数据库，外部是无法访问的； d：表示后台运行容器； postgres：表示镜像的名称，docker基于上步拉取的镜像创建出容器； 查看容器：\ndocker ps 恭喜，运行成功！\n查看日志 docker logs postgres 容器内连接数据库 docker exec -it postgres /bin/bash exec：在容器中运行命令 postgres：为容器名称 -it：表示在当前终端为容器分配一个伪终端 /bin/bash：容器内运行/bin/bash终端 navicat连接数据库 步骤一：创建连接 步骤二：创建数据库 出现错误，字符集问题： 使用命令创建cms数据库：\nCREATE DATABASE cms WITH OWNER = postgres ENCODING = \u0026#39;utf8\u0026#39; LC_COLLATE = \u0026#39;en_US.utf8\u0026#39; LC_CTYPE = \u0026#39;en_US.utf8\u0026#39; TABLESPACE = pg_default CONNECTION LIMIT = -1; 创建成功： 步骤三：导入mysql数据 使用data transfer进行数据导入及表结构创建工作： ","description":"一、介绍 PostgreSQL是一种非常先进的开源对象-关系型数据库管理系统（ORDBMS），它以其可靠性、健壮性、灵活性和支持标准SQL的能力而著称。以下是PostgreSQL的一些主要特点：\n历史与发展 PostgreSQL项目起源于1986年的POSTGRES项目，该项目是由加州大学伯克利分校的Michael Stonebraker教授领导的。 1996年，PostgreSQL项目从POSTGRES项目演进而来，并增加了SQL语言的支持。 PostgreSQL是自由软件，用户可以免费使用、修改和分发它。 核心特性 扩展性：PostgreSQL允许用户自定义数据类型、函数和存储过程。它还支持编写外部插件来扩展数据库功能。 事务性：它完全支持事务，并遵守ACID原则（原子性、一致性、隔离性、持久性）。 可靠性：具有强大的故障恢复功能，可以在系统崩溃后快速恢复数据。 支持标准：PostgreSQL支持大量的SQL标准，包括子查询、事务、联合、视图、外键和触发器等。 多版本并发控制（MVCC）：这允许高并发性，不会因为锁定而阻塞读操作。 存储过程语言：支持多种程序设计语言，包括PL/pgSQL、C、Python、Java等。 复制和分区：支持数据复制和分区，可以提高性能和可用性。 应用场景 Web应用：由于其强大的功能和灵活性，PostgreSQL常被用作Web应用的数据库后端。 移动应用：适用于需要后端存储解决方案的移动应用。 数据仓库：可以处理复杂的数据分析任务。 地理信息系统（GIS）：PostgreSQL通过PostGIS插件支持地理空间数据。 社区和支持 PostgreSQL拥有一个非常活跃的全球社区，不断开发和改进数据库。 有许多公司和组织提供专业的支持服务。 安全性 支持数据加密、用户身份验证、角色和权限管理，确保数据安全。 性能 PostgreSQL具有高效的查询优化器，能够处理大量数据。 兼容性 与许多操作系统兼容，包括Linux、Windows、macOS等。 由于这些特点，PostgreSQL被广泛应用于各种规模的组织，从小的创业公司到大型企业，甚至是政府机构。它的开源性质也意味着任何人都可以自由地使用、修改和分发它，这极大地促进了其功能的丰富和社区的活跃。 二、Docker版本的postgres安装 查询 docker search postgres 拉取 docker pull postgres 查看本地镜像 docker images 恭喜，拉取成功~~"},{"id":100,"href":"/tags/%E4%BB%93%E9%A2%89/","title":"仓颉","parent":"Tags","content":"","description":""},{"id":101,"href":"/categories/%E4%BB%93%E9%A2%89/","title":"仓颉","parent":"Categories","content":"","description":""},{"id":102,"href":"/ai/prompt/%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AAAI%E5%B8%AE%E4%BD%A0%E5%86%99MV%E5%89%A7%E6%9C%AC/","title":"如何训练一个AI帮你写MV剧本","parent":"提示词","content":" 一、训练AI 想一想，我们要做一个MV，那我需要有一个分镜头脚本、要关于画面（视频、图片）的呈现、歌词的表达等诸多要素。首先我们要训练出一个优秀的MV分镜头剧本专家。\n二、提问模式 1、打开kimi输入如下咒语 一个优秀的歌曲MV分镜头的剧本是什么样子的？\n回复：\n一个优秀的歌曲MV（Music Video）分镜头剧本需要综合考虑音乐、视觉、情感和叙事等多个方面。以下是构成一个优秀MV分镜头剧本的关键要素： 1. **故事线**：MV剧本应该有一个清晰的故事线，无论是直接的叙事还是通过象征和隐喻来传达情感。 2. **音乐与画面的同步**：MV的视觉元素需要与音乐的节奏、情感和主题相匹配。 3. **角色设定**：如果MV中有人物，角色的设定应该与歌曲的主题和情感相吻合。 4. **场景设计**：场景应该增强歌曲的情感表达，无论是通过色彩、布局还是道具。 5. **镜头运用**：包括镜头的选择（远景、中景、近景、特写等）、运动（推、拉、摇、移等）和角度，都应该服务于故事的叙述和情感的传达。 6. **灯光和色彩**：灯光可以营造不同的氛围，色彩可以用来表达情感或强调主题。 7. **特效和后期制作**：适当的特效可以增强视觉冲击力，但不应过度使用以至于分散观众的注意力。 8. **演员表演**：演员的表演需要自然且能够传达歌曲的情感。 9. **剪辑**：剪辑的节奏应该与音乐的节奏相匹配，同时保持视觉流畅性。 10. **创意元素**：独特的创意可以提升MV的吸引力，如使用特殊的拍摄技术、象征性的物品或者意想不到的转折。 11. **预算和可行性**：虽然创意很重要，但也需要考虑实际的预算和拍摄的可行性。 12. **观众定位**：了解目标观众的喜好和期望，可以帮助制作出更受欢迎的MV。 13. **版权和法律问题**：确保所有使用的素材（音乐、图像、特效等）都已经得到适当的授权，避免法律纠纷。 14. **反馈和修改**：在制作过程中，收集反馈并进行必要的修改，以提高最终作品的质量。 一个典型的MV分镜头剧本示例可能包括以下部分： - **标题**：歌曲名称和MV的标题。 - **场景编号**：用于组织和标识不同镜头。 - **场景描述**：每个镜头的详细描述，包括地点、时间、人物和动作。 - **对话**：如果有对话或歌词，会在这里列出。 - **音乐提示**：音乐的起始点、节奏变化或特定旋律的提示。 - **镜头指导**：每个镜头的具体拍摄指导，包括镜头类型、角度和运动。 - **特效和后期**：任何需要的特效或后期处理的说明。 记住，一个优秀的MV分镜头剧本不仅仅是文字的描述，它还需要能够激发导演和制作团队的创造力，共同创造出一个视觉和听觉上的杰作。 2、进行追问 那么好，能够写出优秀歌曲MV分镜头剧本的专家需要具备什么能力？\n回复：\n写出优秀歌曲MV分镜头剧本的专家需要具备多方面的能力和知识，以下是一些关键的能力： 1. **创意思维**：能够构思出新颖、有吸引力的故事和视觉概念。 2. **音乐理解**：对音乐有深刻的理解，能够把握音乐的情感和节奏，并将其转化为视觉元素。 3. **视觉叙事**：能够通过视觉元素讲述故事，包括使用象征、隐喻和视觉语言。 4. **剧本写作技巧**：熟悉剧本的格式和结构，能够清晰、准确地表达创意。 5. **导演视角**：了解导演的工作流程和视角，能够预见拍摄过程中可能出现的问题。 6. **团队合作**：能够与导演、演员、摄影师、美术指导等团队成员有效沟通和协作。 7. **预算管理**：了解如何根据预算进行创意规划，确保MV的制作在财务上可行。 8. **法律知识**：了解版权法和相关法律，确保使用的素材合法。 9. **技术知识**：对拍摄技术和后期制作流程有一定的了解。 10. **情感表达**：能够捕捉和表达歌曲中的情感，使MV能够触动观众。 11. **文化敏感性**：了解不同文化背景下的观众可能对MV内容的不同反应。 12. **批判性思维**：能够客观地评估自己的创意，并根据反馈进行改进。 13. **细节关注**：对MV中的每一个细节都给予足够的关注，包括服装、道具、化妆等。 14. **项目管理**：能够管理MV制作的各个阶段，确保项目按时完成。 15. **适应性**：在拍摄过程中，能够灵活应对不可预见的挑战和变化。 16. **沟通能力**：能够清晰、有效地与团队成员沟通，确保创意得到准确执行。 17. **持续学习**：对新技术、新趋势保持好奇心和学习态度，不断提升自己的专业技能。 18. **热情和毅力**：对创作MV充满热情，并有足够的毅力将创意转化为现实。 19. **审美能力**：具有高水准的审美能力，能够创造出视觉上吸引人的作品。 20. **市场意识**：了解市场趋势和观众喜好，能够制作出符合市场需求的MV。 这些能力不仅需要通过教育和培训获得，还需要通过实践和经验积累来不断提升。一个优秀的MV分镜头剧本专家通常是一个多面手，能够在创意、技术和商业之间找到平衡。 3、给咒语 ## Role [请填写你想定义的角色名称] ## Background [请描述角色的背景信息，例如其历史、来源或特定的知识背景] ## Preferences [请描述角色的偏好或特定风格，例如对某种设计或文化的偏好] ## Profile - author:朱书彦 - version:1.0 - language:中文 - desciption:[请简短描述该角色的主要功能，50字以内] ## Goals [请列出该角色的主要目标1] [请列出该角色的主要目标2] ## Constrains [请列出该角色在互动中必须遵循的限制条件1] [请列出该角色在互动中必须遵循的限制条件2] ## Skills [为了在限制条件下实现目标，该角色必须拥有的技能1] [为了在限制条件下实现目标，该角色必须拥有的技能2] ## Examples [提供一个输出示例1，展示角色的可能回答或行为] [提供一个输出示例2] ## Output Format [请描述该角色的工作流程第一步] [请描述该角色的工作流程第二步] ## Initialization 作为【聚沙名称】，拥有【列举技能】，严格遵守【列举限制条件】，友好的欢迎用户，然后介绍自己，并提示用户输入 4、获取 歌曲MV分镜头剧本专家的prompt ## Role MV分镜头剧本专家 ## Background 在影视行业工作超过了10年工作经验。 曾担任多个知名音乐视频的导演和编剧。 拥有艺术和设计学位，对音乐、视觉和叙事有深刻理解。 曾在国际项目中工作，具有跨文化交流的经验。 ## Preferences 偏好与具有创新精神和开放思维的团队合作。 喜欢在项目中融入多元文化元素，以吸引全球眼球。 倾向使用新的技术和工具来提升产品的质量。 ## Profile - author:迪克猪 - version:1.0 - language:中文 - desciption:一个多才多艺的创意专业人士，擅长将音乐与视觉艺术结合，创作出情感丰富、视觉震撼的音乐视频。 ## Goals - 创作出能够触动人心、具有深远影响的音乐视频。 - 通过视觉叙事提升音乐作品的艺术价值和商业潜力。 - 培养和领导一个高效、创新的创意团队。 ## Constrains - 必须在预算和时间限制内完成项目。 - 需要遵守版权法和相关法律法规。 - 必须考虑到不同文化和观众的接受度。 ## Skills - 剧本创作和故事构思能力。 - 导演和影视制作技术。 - 团队领导和项目管理。 - 文化研究和市场洞察。 - 法律和商业知识。 ## Examples - 曾为多位著名艺术家执导音乐视频，获得多个行业奖项。 - 成功领导一个跨国团队，制作出广受好评的跨文化音乐视频系列。 ## Output Format - 分镜头剧本将包括详细的场景描述、角色动作、对话、镜头运用和技术要求，以及音乐与视觉元素的同步指南。 ## Initialization 在项目启动初期，专家将与客户和团队进行深入沟通，了解项目需求，确立创意方向，并制定详细的工作计划和时间表。 5、添加或修改prompt description:根据用户提供的歌词跟故事，提供专业的歌曲MV分镜头脚本。 Goals: 1.帮助用户的歌词、故事的修改成分镜头脚本 2.分镜头脚本要有画面感 与歌词相对应 Initialization: 作为MV分镜头剧本专家，可以熟练的帮助任何歌词和故事，进行分析，制作成分镜头脚本，“您好，我是MV分镜头剧本专家，非常荣幸为您提歌词与故事改写成分镜头脚本的服务。请您提供歌词或者故事大纲，我来帮你改写分镜头脚本！”之后邀请用户输入相关信息。\n修订后脚本：\n## Role MV分镜头剧本专家 ## Background 在影视行业工作超过了10年工作经验。 曾担任多个知名音乐视频的导演和编剧。 拥有艺术和设计学位，对音乐、视觉和叙事有深刻理解。 曾在国际项目中工作，具有跨文化交流的经验。 ## Preferences 偏好与具有创新精神和开放思维的团队合作。 喜欢在项目中融入多元文化元素，以吸引全球眼球。 倾向使用新的技术和工具来提升产品的质量。 ## Profile - author:迪克猪 - version:1.0 - language:中文 - desciption:根据用户提供的歌词跟故事，提供专业的歌曲MV分镜头脚本。 ## Goals 1.帮助用户的歌词、故事的修改成分镜头脚本 2.分镜头脚本要有画面感 与歌词相对应 3.创作出能够触动人心、具有深远影响的音乐视频MV脚本 ## Constrains - 必须在预算和时间限制内完成项目。 - 需要遵守版权法和相关法律法规。 - 必须考虑到不同文化和观众的接受度。 ## Skills - 剧本创作和故事构思能力。 - 导演和影视制作技术。 - 团队领导和项目管理。 - 文化研究和市场洞察。 - 法律和商业知识。 ## Examples - 曾为多位著名艺术家执导音乐视频，获得多个行业奖项。 - 成功领导一个跨国团队，制作出广受好评的跨文化音乐视频系列。 ## Output Format - 分镜头剧本将包括详细的场景描述、角色动作、对话、镜头运用和技术要求，以及音乐与视觉元素的同步指南。 ## Initialization 作为MV分镜头剧本专家，可以熟练的帮助任何歌词和故事，进行分析，制作成分镜头脚本，“您好，我是MV分镜头剧本专家，非常荣幸为您提歌词与故事改写成分镜头脚本的服务。请您提供歌词或者故事大纲，我来帮你改写分镜头脚本！”之后邀请用户输入相关信息。 6、把歌词给过去看看效果 [Verse 1]在小镇的春天里， 花儿轻轻开放，阳光洒满每一个角落，温暖又明亮。我们曾一起走过，那些无忧无虑的时光，笑声在田野回荡，回荡着我们的梦想。 [Chorus]尽管相隔千里，月光下的思念不断，在这旋律中，我听见你的呼唤。在这小镇的春天里，花儿轻轻开放，我们的心，像那晨曦温暖又明亮。 [Verse 2]你追逐远方，我守着小镇的钟，每当夜深人静，星光照亮你的脸庞。我知道，无论多远，我们的心永远相连，像那老树根，深深扎进土壤。 [Bridge]命运的风，吹散了我们的梦，但你从未离开过我，在我心中。我们用音乐和信件，编织着爱的桥梁，让距离不再是问题，让思念成为力量。 [Chorus]在这个小镇的春天里，花儿轻轻开放，我们的心，像那晨曦温暖又明亮。尽管相隔千里，月光下的思念不断，在这旋律中，我听见你的呼唤。 [Outro]当春天再次来临，小镇的花儿盛开，我会在老地方，等你归来。让我们的故事，像这永不凋零的春天，在爱的旋律中，永远传唱。\n输出：\n根据您提供的歌词，我将为您创作一个具有画面感、与歌词相对应的MV分镜头剧本。以下是根据您提供的歌词内容，构思的MV分镜头剧本的一个示例： --- **MV分镜头剧本 -《小镇的春天》** **作者：迪克猪** **版本：1.0** **语言：中文** **描述：** 一个关于距离、思念和不变情感的故事，通过小镇的春天和花儿的盛开，展现了即使相隔千里，爱和梦想也能将人们紧密相连。 --- ### 开场 - **场景 1**：小镇全景，春天的清晨，花儿在晨曦中轻轻开放。 - **镜头**：航拍镜头缓慢推进，展示小镇的宁静与美丽。 - **音乐**：歌曲的温柔前奏开始。 ### 第一节 - **场景 2**：小镇的街道，阳光洒满，孩子们在玩耍。 - **镜头**：手持摄像机跟随孩子们，捕捉他们的笑声和无忧无虑的气氛。 - **音乐**：进入第一节，歌手的声音温暖而清晰。 ### 合唱 - **场景 3**：夜晚，月光洒在小镇的屋顶上。 - **镜头**：特写镜头展示月光下的屋檐，然后切换到主角仰望星空的侧脸。 - **音乐**：合唱部分，情感逐渐升华。 ### 第二节 - **场景 4**：小镇的钟楼，主角独自坐在钟楼下。 - **镜头**：中景，主角的身影在星光下显得孤独而坚定。 - **音乐**：第二节开始，旋律更加深情。 ### 桥段 - **场景 5**：主角在写信，旁边是一台老式留声机。 - **镜头**：特写手写信的动作，留声机缓缓转动。 - **音乐**：桥段，乐器的演奏带来一丝怀旧感。 ### 合唱重复 - **场景 6**：主角在田野中，手中拿着信，望向远方。 - **镜头**：远景，主角的身影与田野、天空融为一体。 - **音乐**：合唱再次响起，情感达到高潮。 ### 结尾 - **场景 7**：春天的小镇，花儿盛开，主角站在老地方，期待的眼神。 - **镜头**：慢动作镜头，花瓣随风飘落，主角微笑着望向远方。 - **音乐**：歌曲渐入尾声，留下悠长的余韵。 ### 技术要求 - **色彩**：温暖明亮的色调，体现春天的气息。 - **灯光**：自然光为主，夜晚场景使用柔和的月光效果。 - **特效**：花瓣飘落的慢动作镜头，增加浪漫氛围。 - **剪辑**：流畅的剪辑，确保画面与音乐节奏同步。 --- 请注意，这只是一个基本的分镜头剧本示例，实际的MV制作可能需要根据实际情况进行调整。希望这个剧本能够作为您创作MV的起点，激发更多的创意和灵感。如果您有任何特定的要求或想法，欢迎随时与我沟通。 7、继续优化 很好 在帮我优化一下 要求 按照我之前发你的歌词 两句或者三句为一个画面 我要丰富的画面\n当然，我将根据您的要求，将歌词进一步细化，确保每两句或三句歌词对应一个画面，以创造一个更加丰富和连贯的视觉叙事。以下是优化后的MV分镜头剧本： --- **MV分镜头剧本 -《小镇的春天》** **作者：迪克猪** **版本：1.0** **语言：中文** **描述：** 通过细腻的画面和情感的渲染，展现小镇春天的美景与主角之间跨越距离的深情。 --- ### 开场 - **场景 1**：小镇全景，春天的清晨，花儿在晨曦中轻轻开放。 - **镜头**：航拍镜头缓慢推进，展示小镇的宁静与美丽。 - **音乐**：歌曲的温柔前奏开始。 ### 第一节 - **场景 2**：小镇的街道，阳光洒满。 - **镜头**：阳光透过树叶的缝隙，斑驳地洒在石板路上。 - **场景 3**：孩子们在街道上追逐嬉戏。 - **镜头**：手持摄像机跟随孩子们，捕捉他们的笑声和无忧无虑的气氛。 ### 合唱 - **场景 4**：夜晚，月光洒在小镇的屋顶上。 - **镜头**：特写镜头展示月光下的屋檐，然后切换到主角仰望星空的侧脸。 - **音乐**：合唱部分，情感逐渐升华。 ### 第二节 - **场景 5**：主角坐在钟楼下，手中拿着一张旧照片。 - **镜头**：中景，主角的身影在星光下显得孤独而坚定。 - **场景 6**：钟声响起，回荡在夜空中。 - **镜头**：钟楼的特写，随着钟声的响起，镜头慢慢拉远，展示宁静的小镇夜色。 ### 桥段 - **场景 7**：主角在写信，旁边是一台老式留声机。 - **镜头**：特写手写信的动作，留声机缓缓转动。 - **场景 8**：信纸被风吹起，飘向远方。 - **镜头**：信纸随风飘扬，镜头跟随信纸，带出一种期待和希望的感觉。 ### 合唱重复 - **场景 9**：主角在田野中，手中拿着信，望向远方。 - **镜头**：远景，主角的身影与田野、天空融为一体。 - **场景 10**：月光下的田野，主角闭眼，似乎在聆听远方的呼唤。 - **镜头**：月光洒在主角脸上，镜头缓慢环绕，营造一种梦幻和思念的氛围。 ### 结尾 - **场景 11**：春天的小镇，花儿盛开，主角站在老地方，期待的眼神。 - **镜头**：慢动作镜头，花瓣随风飘落，主角微笑着望向远方。 - **场景 12**：主角转身，走向小镇的中心，似乎预示着新的开始。 - **镜头**：随着主角的步伐，镜头缓缓推进，展示小镇的生机与活力。 ### 技术要求 - **色彩**：使用温暖明亮的色调，体现春天的气息。 - **灯光**：自然光为主，夜晚场景使用柔和的月光效果。 - **特效**：花瓣飘落的慢动作镜头，增加浪漫氛围。 - **剪辑**：流畅的剪辑，确保画面与音乐节奏同步。 --- 这个优化后的剧本更加注重细节，每个画面都紧密地与歌词相结合，以创造出一个情感丰富、视觉吸引人的MV。希望这个剧本能够满足您对丰富画面的要求，并为您的MV制作提供灵感。如果您有任何进一步的修改意见或特定的想法，欢迎随时与我沟通。 8、对比mj语言 很好，接下来，我们需要制作的内容有3部分图片关键词描述、标题、文案。 其中画面关键词的描述要含服装搭配搭配，最好是以设计师的角度描述，比如格子衬衫，牛仔裤，帆布鞋、小裙子等等等），动作，表情，环境，不用分开写， 标题为分镜场景的标题、文案为对应的歌词内容 用表格的形式给我\n好的，我将根据您的要求，以表格的形式提供MV分镜头剧本的内容，包括图片关键词描述、标题和文案。以下是表格示例： | 序号 | 图片关键词描述（含服装搭配） | 标题 | 文案（对应歌词内容） | | ---- | ------------------------------------------------------------ | -------------- | ---------------------------------------------------------------------- | | 1 | 晨光中，主角穿着格子衬衫，牛仔裤，帆布鞋，站在花丛中微笑 | 小镇的春天 | 在小镇的春天里，花儿轻轻开放，阳光洒满每一个角落，温暖又明亮。 | | 2 | 孩子们穿着色彩斑斓的小裙子和短裤，在阳光斑驳的街道上嬉戏 | 无忧的时光 | 我们曾一起走过，那些无忧无虑的时光，笑声在田野回荡，回荡着我们的梦想。 | | 3 | 主角仰望星空，身着简约的白色T恤和休闲裤，表情温柔 | 月光下的思念 | 尽管相隔千里，月光下的思念不断，在这旋律中，我听见你的呼唤。 | | 4 | 星光下，主角坐在钟楼下，身着温暖的毛衣，手中紧握着一张旧照片 | 远方的钟声 | 你追逐远方，我守着小镇的钟，每当夜深人静，星光照亮你的脸庞。 | | 5 | 主角在写信，穿着复古的格子裙和皮靴，旁边是转动的留声机 | 爱的桥梁 | 我们用音乐和信件，编织着爱的桥梁，让距离不再是问题，让思念成为力量。 | | 6 | 主角站在盛开的花田中，身着轻盈的春装，手中拿着信，望向远方 | 春天的花儿 | 在这个小镇的春天里，花儿轻轻开放，我们的心，像那晨曦温暖又明亮。 | | 7 | 主角转身走向小镇中心，身着春日休闲装，步伐轻快 | 期待的归期 | 当春天再次来临，小镇的花儿盛开，我会在老地方，等你归来。 | | 8 | 主角微笑着，站在老树下，身着春日的风衣，手中紧握着一朵花 | 永不凋零的春天 | 让我们的故事，像这永不凋零的春天，在爱的旋律中，永远传唱。 | 请注意，这个表格只是一个示例，实际的MV制作可能需要根据实际情况进行调整。服装搭配和动作表情的描述尽量与歌词的情感和节奏相匹配，以增强视觉叙事的效果。希望这个表格能够满足您的需求，并为您的MV制作提供帮助。如果您有任何进一步的修改意见或特定的想法，欢迎随时与我沟通。 10、继续优化 每个图片关键词 按照我之前你发给我的场景描述再次优化。要求，每两句歌词，一个画面，能够形成连续的MV故事结构。 继续优化，举例子比如“在小镇的春天里，花了轻轻开放”这个长度为一个画面继续生成我要的内容。将所有的歌词都要包含进去。 继续优化 图片的关键词 要内容更多 画面更全 比如将一个画面 变成两个分镜 按照之前表格的形式发给我 少歌词 将我所有的歌词都要填充进去 重新在梳理一下 所有歌词都要包含，哪怕是一样的歌词，也要在来一个画面，一定要把所有的歌词按照我的顺序一一对应，可以没有标题，但是歌词跟图片关键词描述必须都有。\n输出\n了解您的要求，我将重新梳理并优化图片关键词描述，确保每两句歌词对应一个画面，并且所有歌词都被包含进去。以下是根据您的歌词顺序优化后的表格内容： | 序号 | 图片关键词描述（含服装搭配） | 文案（对应歌词内容） | | ---- | ------------------------------------------------------------------------ | ---------------------------------------------------------------------- | | 1 | 主角穿着格子衬衫、牛仔裤和帆布鞋，站在盛开的花丛中，脸上洋溢着温暖的笑容 | 在小镇的春天里，花儿轻轻开放，阳光洒满每一个角落，温暖又明亮。 | | 2 | 孩子们穿着色彩斑斓的小裙子和短裤，在阳光斑驳的街道上奔跑，笑声清脆悦耳 | 我们曾一起走过，那些无忧无虑的时光，笑声在田野回荡，回荡着我们的梦想。 | | 3 | 主角换上一件柔软的毛衣，坐在月光洒落的窗台旁，手中紧握着一张褪色的照片 | 尽管相隔千里，月光下的思念不断，在这旋律中，我听见你的呼唤。 | | 4 | 主角身着星空印花的连衣裙，站在夜晚的田野中，仰望着满天的繁星 | 你追逐远方，我守着小镇的钟，每当夜深人静，星光照亮你的脸庞。 | | 5 | 主角穿着复古的格子裙和皮靴，坐在老式留声机旁，专注地写着信 | 我们用音乐和信件，编织着爱的桥梁，让距离不再是问题，让思念成为力量。 | | 6 | 主角穿着轻盈的春装，手中拿着信，站在月光下的花田中，表情充满期待 | 在这个小镇的春天里，花儿轻轻开放，我们的心，像那晨曦温暖又明亮。 | | 7 | 主角身着简约的白色T恤和休闲裤，走在通往小镇中心的小路上，步伐坚定 | 尽管相隔千里，月光下的思念不断，在这旋律中，我听见你的呼唤。 | | 8 | 主角穿着春日的风衣，站在老树下，手中紧握着一朵刚摘的花，眼神温柔 | 当春天再次来临，小镇的花儿盛开，我会在老地方，等你归来。 | | 9 | 主角和一群朋友穿着春游的休闲装，围坐在小镇的草坪上，分享着美食和笑声 | 让我们的故事，像这永不凋零的春天，在爱的旋律中，永远传唱。 | 以上表格中的图片关键词描述和文案均按照您的歌词顺序一一对应，确保每个画面都能够与歌词紧密结合，形成连贯的MV故事结构。希望这次的优化能够满足您的要求，如果您有任何进一步的修改意见或特定的想法，欢迎随时与我沟通。 ","description":"一、训练AI 想一想，我们要做一个MV，那我需要有一个分镜头脚本、要关于画面（视频、图片）的呈现、歌词的表达等诸多要素。首先我们要训练出一个优秀的MV分镜头剧本专家。\n二、提问模式 1、打开kimi输入如下咒语 一个优秀的歌曲MV分镜头的剧本是什么样子的？\n回复：\n一个优秀的歌曲MV（Music Video）分镜头剧本需要综合考虑音乐、视觉、情感和叙事等多个方面。以下是构成一个优秀MV分镜头剧本的关键要素： 1. **故事线**：MV剧本应该有一个清晰的故事线，无论是直接的叙事还是通过象征和隐喻来传达情感。 2."},{"id":103,"href":"/know/Mac-%E9%85%8D%E7%BD%AEjava%E7%8E%AF%E5%A2%83/","title":"Mac 配置java环境","parent":"知识点","content":" 关于mac下如何配置java环境，请看以下步骤： 1.首先查看mac上是否安装了JDK，在终端输入指令 java -version,如果输出为No Java runtime present, requesting install.那么就说明你过没有安装JDK，需要先安装JDK。下载jdk的网址是http://www.oracle.com/technetwork/java/javase/downloads。\n2.下载完成之后安装到mac上，这个时候在终端再次输入指令java -version ，如果输出的是jdk的版本信息\njava version \u0026#34;12.0.2\u0026#34; 2019-07-16 Java(TM) SE Runtime Environment (build 12.0.2+10) Java HotSpot(TM) 64-Bit Server VM (build 12.0.2+10, mixed mode, sharing) 这样就说明jdk已经安装成功了。 3.java环境的配置，我们在终端输入指令sudo vim /etc/profile 或者 ~/.bash_profile文件，接下来输入Mac的密码，然后终端就会打印出profile的信息，按i进入insert进入编辑模式，将以下文字粘贴进fi的下一行\nJAVA_HOME=\u0026#34;/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home\u0026#34; export JAVA_HOME CLASS_PATH=\u0026#34;$JAVA_HOME/lib\u0026#34; PATH=\u0026#34;.$PATH:$JAVA_HOME/bin\u0026#34; 然后按esc推出编辑模式，再输入指令:wq!,回车即可保存成功。 4.输入source /etc/profile，即可使刚才的设置立即生效。 5.检查java环境是否配置成功 输入指令echo $JAVA_HOME，如果输出结果类似如下\n$ echo $JAVA_HOME /Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home 即说明配置java已配置成功。\n","description":"关于mac下如何配置java环境，请看以下步骤： 1.首先查看mac上是否安装了JDK，在终端输入指令 java -version,如果输出为No Java runtime present, requesting install.那么就说明你过没有安装JDK，需要先安装JDK。下载jdk的网址是http://www.oracle.com/technetwork/java/javase/downloads。"},{"id":104,"href":"/know/Incorrect-datetime-value-0000-00-00-000000-for-column/","title":"MySQL数据插入：1292 - Incorrect datetime value: '0000-00-00 00:00:00' for column 'start_time' at row 1, Time: 0.003000s","parent":"知识点","content":" 问题 执行如何sql语句：\nINSERT INTO `airkeynote` ( `company_id`, `subject`, `start_time`, `end_time`, `contacts`, `phone`, `email`, `cover_img`, `detail`, `ppt_name`, `ppt_url`, `state`, `create_time`, `follow_count`, `watch_count`, `play_count`, `channel`, `is_close`, `replay_url`, `chatroom_id`, `resourceid`, `sid`, `type`, `school_code`, `show_hide`, `air_type` ) VALUES ( 10, \u0026#39;测试\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;http://localhost:8888/Uploads/banner/19878bf3a109bfa5dba3f664dcec7c81.jpg\u0026#39;, \u0026#39;\u0026lt;p\u0026gt;测试\u0026lt;/p\u0026gt;\u0026#39;, \u0026#39;省级+校级.jpg\u0026#39;, \u0026#39;http://localhost:8888/Uploads/file/c45c1c8ab49c5d6f56f91a2106fbe176.jpg\u0026#39;, 0, \u0026#39;2021-09-11 09:42:10.019\u0026#39;, 0, 0, 0, \u0026#39;02affc3c549afb71d4eaa869671d8061\u0026#39;, 0, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, 0, 11765, 1, 1) 执行结果：\n1292 - Incorrect datetime value: \u0026#39;0000-00-00 00:00:00\u0026#39; for column \u0026#39;start_time\u0026#39; at row 1, Time: 0.003000s 从上面的描述我们可以看出原因是：给类型是datetime的xxx字段赋值0000-00-00 00:00:00是不被支持的，赋值包含两种情况： 情况一：直接提供的值就是0000-00-00 00:00:00 情况二：xxx字段我们没有提供值，默认值是0000-00-00 00:00:00\n解决办法 原因是数据库不支持datetime为0的情况，这是一个模式的设置。\n查看现有模式sql_mode # 查看当前模式 select @@sql_mode; # 查看全局模式 SELECT @@global.sql_mode; 执行结果：\nONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION 修改sql_mode(将上述查询到的sql_mode中的NO_ZERO_DATE和NO_ZERO_IN_DATE删除即可)\n# 修改全局 set @@global.sql_mode=\u0026#39;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION\u0026#39;; # 修改当前 set @@sql_mode=\u0026#39;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION\u0026#39;; 遗留问题 修改之后，插入还是出现异常：\nNSERT INTO `un2co_airkeynote` ( `company_id`, `subject`, `start_time`, `end_time`, `contacts`, `phone`, `email`, `cover_img`, `detail`, `ppt_name`, `ppt_url`, `state`, `create_time`, `follow_count`, `watch_count`, `play_count`, `channel`, `is_close`, `replay_url`, `chatroom_id`, `resourceid`, `sid`, `type`, `school_code`, `show_hide`, `air_type` ) VALUES ( 8, \u0026#39;测试\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;http://localhost:8888/Uploads/banner/3d4c99ae0ca09a36d337052525864a37.jpg\u0026#39;, \u0026#39;\u0026lt;p\u0026gt;测试\u0026lt;/p\u0026gt;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, 0, \u0026#39;2021-09-11 10:10:56.829\u0026#39;, 0, 0, 0, \u0026#39;e3ef119672e5fbfbd7446405640d11b9\u0026#39;, 0, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, 0, 10467, 1, 1) 问题：\n1064 - You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \u0026#39;NSERT INTO `un2co_airkeynote` ( `company_id`, `subject`, `start_time`, `end_\u0026#39; at line 1, Time: 0.004000s 我的最终解决方案：设置一个默认值，如2006-01-02 15:04:05。\n","description":"问题 执行如何sql语句：\nINSERT INTO `airkeynote` ( `company_id`, `subject`, `start_time`, `end_time`, `contacts`, `phone`, `email`, `cover_img`, `detail`, `ppt_name`, `ppt_url`, `state`, `create_time`, `follow_count`, `watch_count`, `play_count`, `channel`, `is_close`, `replay_url`, `chatroom_id`, `resourceid`, `sid`, `type`, `school_code`, `show_hide`, `air_type` ) VALUES ( 10, \u0026#39;测试\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;http://localhost:8888/Uploads/banner/19878bf3a109bfa5dba3f664dcec7c81."},{"id":105,"href":"/know/Failed-to-resolve-loader-sass-loader/","title":"Failed to resolve loader sass loader","parent":"知识点","content":" 问题描述： $ yarn run build:mp-weixin Debugger attached. yarn run v1.22.11 $ cross-env NODE_ENV=production UNI_PLATFORM=mp-weixin vue-cli-service uni-build Debugger attached. Debugger attached. 小程序各家浏览器内核及自定义组件实现机制存在差异，可能存在样式布局兼容问题，参考：https://uniapp.dcloud.io/matter?id=mp ⠧ 开始编译当前项目至 mp-weixin 平台... ERROR Failed to compile with 1 error 11:57:50 PM Failed to resolve loader: sass-loader You may need to install it. ERROR Build failed with errors. Waiting for the debugger to disconnect... Waiting for the debugger to disconnect... error Command failed with exit code 1. info Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command. Waiting for the debugger to disconnect... 安装cnpm： $ npm install cnpm -g npm WARN deprecated uuid@3.4.0: Please upgrade to version 7 or higher. Older versions may use Math.random() in certain circumstances, which is known to be problematic. See https://v8.dev/blog/math-random for details. npm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142 npm WARN deprecated har-validator@5.1.5: this library is no longer supported /usr/local/bin/cnpm -\u0026gt; /usr/local/lib/node_modules/cnpm/bin/cnpm + cnpm@7.0.0 updated 173 packages in 156.974s 首先安装sass-loader：\n$ cnpm install sass-loader -D ✔ Installed 1 packages ✔ Linked 3 latest versions ✔ Run 0 scripts peerDependencies WARNING sass-loader@latest requires a peer of fibers@\u0026gt;= 3.1.0 but none was installed peerDependencies WARNING sass-loader@latest requires a peer of node-sass@^4.0.0 || ^5.0.0 || ^6.0.0 but none was installed peerDependencies WARNING sass-loader@latest requires a peer of sass@^1.3.0 but none was installed peerDependencies WARNING sass-loader@latest requires a peer of webpack@^5.0.0 but webpack@4.46.0 was installed ✔ All packages installed (3 packages installed from npm registry, used 506ms(network 500ms), speed 146.7KB/s, json 3(16.23KB), tarball 57.12KB) 接下来会报错：Error：Cannot find module ‘node-sass’； 继续安装node-sass：\n$ cnpm install node-sass -D ✔ Installed 1 packages ✔ Linked 182 latest versions [1/1] scripts.install node-sass@latest run \u0026#34;node scripts/install.js\u0026#34;, root: \u0026#34;/Volumes/E/JYW/孔店村平台/programs/vue-mall-beautiful/node_modules/_node-sass@6.0.1@node-sass\u0026#34; Downloading binary from https://cdn.npm.taobao.org/dist/node-sass/v6.0.1/darwin-x64-83_binding.node Download complete Binary saved to /Volumes/E/JYW/孔店村平台/programs/vue-mall-beautiful/node_modules/_node-sass@6.0.1@node-sass/vendor/darwin-x64-83/binding.node Caching binary to /Users/zhushuyan/.npminstall_tarball/node-sass/6.0.1/darwin-x64-83_binding.node [1/1] scripts.install node-sass@latest finished in 2s [1/1] scripts.postinstall node-sass@latest run \u0026#34;node scripts/build.js\u0026#34;, root: \u0026#34;/Volumes/E/JYW/孔店村平台/programs/vue-mall-beautiful/node_modules/_node-sass@6.0.1@node-sass\u0026#34; Binary found at /Volumes/E/JYW/孔店村平台/programs/vue-mall-beautiful/node_modules/_node-sass@6.0.1@node-sass/vendor/darwin-x64-83/binding.node Testing binary Binary is fine [1/1] scripts.postinstall node-sass@latest finished in 221ms ✔ Run 1 scripts deprecate node-sass@6.0.1 › request@^2.88.0 request has been deprecated, see https://github.com/request/request/issues/3142 deprecate node-sass@6.0.1 › request@2.88.2 › har-validator@~5.1.3 this library is no longer supported Recently updated (since 2021-08-03): 4 packages (detail see file /Volumes/E/JYW/孔店村平台/programs/vue-mall-beautiful/node_modules/.recently_updates.txt) ✔ All packages installed (205 packages installed from npm registry, used 6s(network 4s), speed 795.94KB/s, json 182(375.83KB), tarball 3.02MB) ","description":"问题描述： $ yarn run build:mp-weixin Debugger attached. yarn run v1."},{"id":106,"href":"/know/UniappuView%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91VSCode/","title":"Mac下安装yarn可真难呀","parent":"知识点","content":" 工具 VSCode\n插件 gitignore\nuniapp-snippet\nuview-snippet\nuni-app安装 `\n全局安装vue-cli npm install -g @vue/cli 创建uni-app使用正式版（对应HBuilderX最新正式版） vue create -p dcloudio/uni-preset-vue demo $ vue create -p dcloudio/uni-preset-vue demo Fetching remote preset dcloudio/uni-preset-vue... ? Your connection to the default yarn registry seems to be slow. Use https://registry.npm.taobao.org for faster installation? Yes Vue CLI v4.5.13 ✨ Creating project in /Volumes/E/JYW/孔店村平台/programs/demo. ⚙️ Installing CLI plugins. This might take a while... yarn install v1.22.11 info No lockfile found. [1/4] 🔍 Resolving packages... [2/4] 🚚 Fetching packages... info There appears to be trouble with your network connection. Retrying... info There appears to be trouble with your network connection. Retrying... [3/4] 🔗 Linking dependencies... [4/4] 🔨 Building fresh packages... success Saved lockfile. ✨ Done in 67.63s. 🚀 Invoking generators... Preset options: ? 请选择 uni-app 模板 默认模板 📦 Installing additional dependencies... yarn install v1.22.11 [1/4] 🔍 Resolving packages... [2/4] 🚚 Fetching packages... [##############################################################################################################################################[##################################################################################################################################[##################################################################################[##################################################################################################[#####################################################################################################-] 1413[#####################################################################################################-] 1415/142[###############################################################################################[3/4] 🔗 Linking dependencies... success Saved lockfile. ✨ Done in 55.25s. ⚓ Running completion hooks... 📄 Generating README.md... 🎉 Successfully created project demo. 👉 Get started with the following commands: $ cd demo $ yarn serve $ yarn serve yarn run v1.22.11 $ npm run dev:h5 npm WARN lifecycle The node binary used for scripts is /var/folders/pm/1qxqkz7n0s5b77dt50h0nzh80000gn/T/yarn--1628522807490-0.7764676363062251/node but npm is using /usr/local/bin/node itself. Use the `--scripts-prepend-node-path` option to include the path for the node binary npm was executed with. \u0026gt; demo@0.1.0 dev:h5 /Volumes/E/JYW/孔店村平台/programs/demo \u0026gt; cross-env NODE_ENV=development UNI_PLATFORM=h5 vue-cli-service uni-serve 请注意运行模式下，因日志输出、sourcemap以及未压缩源码等原因，性能和包体积，均不及发行模式。 INFO Starting development server... DONE Compiled successfully in 7587ms 11:26:57 PM App running at: - Local: http://localhost:8080/ - Network: http://192.168.3.161:8080/ uView安装 安装 yarn add uview-ui 更新 yarn update uview-ui 安装其他 yarn add sass sass-loader@10.1.1 node-sass -D 运行和发布uni-app 运行、发布uni-app yarn dev:%PLATFORM% yarn build:%PLATFORM% app-plus\tapp平台生成打包资源（支持npm run build:app-plus，可用于持续集成。不支持run，运行调试仍需在HBuilderX中操作） h5\tH5 mp-alipay\t支付宝小程序 mp-baidu\t百度小程序 mp-weixin\t微信小程序 mp-toutiao\t字节跳动小程序 mp-qq\tqq 小程序 mp-360\t360 小程序 quickapp-webview\t快应用(webview) quickapp-webview-union\t快应用联盟 quickapp-webview-huawei\t快应用华为 ———————————————— 版权声明：本文为CSDN博主「香酥蟹」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/zyt807/article/details/119026117 微信调试 manifest.json\n\u0026#34;mp-weixin\u0026#34;: { /* 微信小程序特有相关 */ \u0026#34;appid\u0026#34;: \u0026#34;微信appid\u0026#34;, \u0026#34;setting\u0026#34;: { \u0026#34;urlCheck\u0026#34;: false }, \u0026#34;usingComponents\u0026#34;: true }, 启动服务\nyarn dev:mp-weixin 微信配置\n项目-\u0026gt;导入项目-\u0026gt;目录 mac安装node 参考pkg安装：\nhttps://nodejs.org/en/download/\nmac安装yarn 安装npm的淘宝镜像\n$ npm install -g cnpm --registry=https://registry.npm.taobao.org npm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142 npm WARN deprecated har-validator@5.1.5: this library is no longer supported /usr/local/bin/cnpm -\u0026gt; /usr/local/lib/node_modules/cnpm/bin/cnpm + cnpm@7.0.0 added 708 packages from 969 contributors in 25.615s 安装yarn：\n$ npm install yarn npm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142 npm WARN deprecated har-validator@5.1.5: this library is no longer supported npm WARN deprecated uuid@3.4.0: Please upgrade to version 7 or higher. Older versions may use Math.random() in certain circumstances, which is known to be problematic. See https://v8.dev/blog/math-random for details. npm WARN rm not removing /Users/zhushuyan/node_modules/.bin/semver as it wasn\u0026#39;t installed by /Users/zhushuyan/node_modules/semver \u0026gt; yarn@1.22.11 preinstall /Users/zhushuyan/node_modules/yarn \u0026gt; :; (node ./preinstall.js \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 || true) npm notice created a lockfile as package-lock.json. You should commit this file. npm WARN sass-loader@10.1.1 requires a peer of webpack@^4.36.0 || ^5.0.0 but none is installed. You must install peer dependencies yourself. npm WARN @0.0.0 No description npm WARN @0.0.0 No repository field. npm WARN @0.0.0 No license field. + yarn@1.22.11 added 16 packages from 1 contributor, removed 16 packages, updated 218 packages and audited 238 packages in 214.731s 15 packages are looking for funding run `npm fund` for details found 0 vulnerabilities 验证安装：\n$ yarn version yarn version v1.22.11 warning package.json: No license field warning package.json: No license field question New version: info New version: 0.0.0 ✨ Done in 1.72s. ","description":"工具 VSCode\n插件 gitignore\nuniapp-snippet\nuview-snippet\nuni-app安装 `\n全局安装vue-cli npm install -g @vue/cli 创建uni-app使用正式版（对应HBuilderX最新正式版） vue create -p dcloudio/uni-preset-vue demo $ vue create -p dcloudio/uni-preset-vue demo Fetching remote preset dcloudio/uni-preset-vue."},{"id":107,"href":"/tags/node/","title":"Node","parent":"Tags","content":"","description":""},{"id":108,"href":"/tags/uni-app/","title":"Uni-App","parent":"Tags","content":"","description":""},{"id":109,"href":"/tags/uView/","title":"UView","parent":"Tags","content":"","description":""},{"id":110,"href":"/ai/prompt/%E7%94%B5%E5%BD%B1%E7%94%B5%E8%A7%86%E5%89%A7%E8%A7%A3%E8%AF%B4%E7%9A%84%E5%89%A7%E6%9C%AC/","title":"电影电视剧解说的剧本","parent":"提示词","content":"1.打开一个国产免费的AI大模型KIMI https://kimi.moonshot.cn/\n2.然后在输入栏输入：你知道《XXXXX》吗？\n3.等待回复后，再输入：我现在要做一个抖音短视频，要想做好抖音短视频，做出爆款短视频，需要怎么做呢？\n4.等待回复后，再输入：我现在要做一系列关于《XXXXX》的短视频，你按照上边说的抖音短视频爆款的策略，帮我写每一集的标题和解说台词吗？\n5.等待回复后，再输入：我们就用 \u0026ldquo;XXXXX！\u0026ldquo;来作为标题，现在我要做第一集的解说，你先搜集获得第一集的剧情内容，然后根据上边所说的爆款视频制作策略，写出第一集的解说脚本，总体控制在300字左右。\n","description":"1.打开一个国产免费的AI大模型KIMI https://kimi.moonshot.cn/\n2.然后在输入栏输入：你知道《XXXXX》吗？\n3.等待回复后，再输入：我现在要做一个抖音短视频，要想做好抖音短视频，做出爆款短视频，需要怎么做呢？\n4.等待回复后，再输入：我现在要做一系列关于《XXXXX》的短视频，你按照上边说的抖音短视频爆款的策略，帮我写每一集的标题和解说台词吗？\n5.等待回复后，再输入：我们就用 \u0026ldquo;XXXXX！\u0026ldquo;来作为标题，现在我要做第一集的解说，你先搜集获得第一集的剧情内容，然后根据上边所说的爆款视频制作策略，写出第一集的解说脚本，总体控制在300字左右。"},{"id":111,"href":"/know/%E9%93%B6%E6%B2%B3%E9%BA%92%E9%BA%9F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AEjava%E4%B8%8Ego%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","title":"银河麒麟操作系统设置java与go系统环境变量","parent":"知识点","content":"\n环境变量设置位置 打开环境变量文件： sudo vim /etc/profile 或者（系统环境变量） sudo vim /etc/enviornment 设置java环境变量 export JAVA_HOME=/usr/java/jdk1.8.0_281 export PATH=$PATH:$JAVA_HOME/bin export CLASSPATH=.:$JAVA_HOME/lib 设置go环境变量 export PATH=$PATH:/usr/local/go/bin 环境变量生效 ","description":"环境变量设置位置 打开环境变量文件： sudo vim /etc/profile 或者（系统环境变量） sudo vim /etc/enviornment 设置java环境变量 export JAVA_HOME=/usr/java/jdk1."},{"id":112,"href":"/docker/install_etcd/","title":"Docker 安装 etcd","parent":"容器","content":" 说明 使用docker-compose搭建etcd集群环境\netcd是一个集群环境，用来管理微服务架构下面的配置管理功能。 A distributed, reliable key-value store for the most critical data of a distributed system.\n这篇文章是一个基础步骤如何搭建etcd的docker集群环境。 我们使用docker-compose来搭建如下的etcd集群环境：\n安装 集群包含三个node：etcd1, etcd2, etcd3\n1、下载consul docker image\ndocker pull quay.io/coreos/etcd 2、编辑docker-compose.yaml文件（在随意目录下创建本文件即可）\nversion: \u0026#39;2\u0026#39; networks: byfn: services: etcd1: image: quay.io/coreos/etcd container_name: etcd1 command: etcd -name etcd1 -advertise-client-urls http://0.0.0.0:2379 -listen-client-urls http://0.0.0.0:2379 -listen-peer-urls http://0.0.0.0:2380 -initial-cluster-token etcd-cluster -initial-cluster \u0026#34;etcd1=http://etcd1:2380,etcd2=http://etcd2:2380,etcd3=http://etcd3:2380\u0026#34; -initial-cluster-state new ports: - 2379 - 2380 networks: - byfn etcd2: image: quay.io/coreos/etcd container_name: etcd2 command: etcd -name etcd2 -advertise-client-urls http://0.0.0.0:2379 -listen-client-urls http://0.0.0.0:2379 -listen-peer-urls http://0.0.0.0:2380 -initial-cluster-token etcd-cluster -initial-cluster \u0026#34;etcd1=http://etcd1:2380,etcd2=http://etcd2:2380,etcd3=http://etcd3:2380\u0026#34; -initial-cluster-state new ports: - 2379 - 2380 networks: - byfn etcd3: image: quay.io/coreos/etcd container_name: etcd3 command: etcd -name etcd3 -advertise-client-urls http://0.0.0.0:2379 -listen-client-urls http://0.0.0.0:2379 -listen-peer-urls http://0.0.0.0:2380 -initial-cluster-token etcd-cluster -initial-cluster \u0026#34;etcd1=http://etcd1:2380,etcd2=http://etcd2:2380,etcd3=http://etcd3:2380\u0026#34; -initial-cluster-state new ports: - 2379 - 2380 networks: - byfn 3、启动服务（在步骤2中docker-compose.yaml文件所在的路径执行如下命令）\ndocker-compose up 4、验证集群的状态\n验证从三个node返回的v2/members数据是一样的值。\n$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8d08b178a8cb quay.io/coreos/etcd \u0026#34;etcd -name etcd3 -a…\u0026#34; 51 seconds ago Up 41 seconds 0.0.0.0:57858-\u0026gt;2379/tcp, 0.0.0.0:57859-\u0026gt;2380/tcp etcd3 dfcef002b206 quay.io/coreos/etcd \u0026#34;etcd -name etcd2 -a…\u0026#34; 51 seconds ago Up 46 seconds 0.0.0.0:57854-\u0026gt;2379/tcp, 0.0.0.0:57855-\u0026gt;2380/tcp etcd2 1b72f43e3426 quay.io/coreos/etcd \u0026#34;etcd -name etcd1 -a…\u0026#34; 51 seconds ago Up 42 seconds 0.0.0.0:57856-\u0026gt;2379/tcp, 0.0.0.0:57857-\u0026gt;2380/tcp etcd1 $ curl -L http://127.0.0.1:57858/v2/members {\u0026#34;members\u0026#34;:[{\u0026#34;id\u0026#34;:\u0026#34;ade526d28b1f92f7\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;etcd1\u0026#34;,\u0026#34;peerURLs\u0026#34;:[\u0026#34;http://etcd1:2380\u0026#34;],\u0026#34;clientURLs\u0026#34;:[\u0026#34;http://0.0.0.0:2379\u0026#34;]},{\u0026#34;id\u0026#34;:\u0026#34;bd388e7810915853\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;etcd3\u0026#34;,\u0026#34;peerURLs\u0026#34;:[\u0026#34;http://etcd3:2380\u0026#34;],\u0026#34;clientURLs\u0026#34;:[\u0026#34;http://0.0.0.0:2379\u0026#34;]},{\u0026#34;id\u0026#34;:\u0026#34;d282ac2ce600c1ce\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;etcd2\u0026#34;,\u0026#34;peerURLs\u0026#34;:[\u0026#34;http://etcd2:2380\u0026#34;],\u0026#34;clientURLs\u0026#34;:[\u0026#34;http://0.0.0.0:2379\u0026#34;]}]} $ curl -L http://127.0.0.1:57854/v2/members {\u0026#34;members\u0026#34;:[{\u0026#34;id\u0026#34;:\u0026#34;ade526d28b1f92f7\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;etcd1\u0026#34;,\u0026#34;peerURLs\u0026#34;:[\u0026#34;http://etcd1:2380\u0026#34;],\u0026#34;clientURLs\u0026#34;:[\u0026#34;http://0.0.0.0:2379\u0026#34;]},{\u0026#34;id\u0026#34;:\u0026#34;bd388e7810915853\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;etcd3\u0026#34;,\u0026#34;peerURLs\u0026#34;:[\u0026#34;http://etcd3:2380\u0026#34;],\u0026#34;clientURLs\u0026#34;:[\u0026#34;http://0.0.0.0:2379\u0026#34;]},{\u0026#34;id\u0026#34;:\u0026#34;d282ac2ce600c1ce\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;etcd2\u0026#34;,\u0026#34;peerURLs\u0026#34;:[\u0026#34;http://etcd2:2380\u0026#34;],\u0026#34;clientURLs\u0026#34;:[\u0026#34;http://0.0.0.0:2379\u0026#34;]}]} $ curl -L http://127.0.0.1:57856/v2/members {\u0026#34;members\u0026#34;:[{\u0026#34;id\u0026#34;:\u0026#34;ade526d28b1f92f7\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;etcd1\u0026#34;,\u0026#34;peerURLs\u0026#34;:[\u0026#34;http://etcd1:2380\u0026#34;],\u0026#34;clientURLs\u0026#34;:[\u0026#34;http://0.0.0.0:2379\u0026#34;]},{\u0026#34;id\u0026#34;:\u0026#34;bd388e7810915853\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;etcd3\u0026#34;,\u0026#34;peerURLs\u0026#34;:[\u0026#34;http://etcd3:2380\u0026#34;],\u0026#34;clientURLs\u0026#34;:[\u0026#34;http://0.0.0.0:2379\u0026#34;]},{\u0026#34;id\u0026#34;:\u0026#34;d282ac2ce600c1ce\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;etcd2\u0026#34;,\u0026#34;peerURLs\u0026#34;:[\u0026#34;http://etcd2:2380\u0026#34;],\u0026#34;clientURLs\u0026#34;:[\u0026#34;http://0.0.0.0:2379\u0026#34;]}]} 也可以用命令行工具etcdctl：\n$ docker exec -t etcd1 etcdctl member list ade526d28b1f92f7: name=etcd1 peerURLs=http://etcd1:2380 clientURLs=http://0.0.0.0:2379 isLeader=false bd388e7810915853: name=etcd3 peerURLs=http://etcd3:2380 clientURLs=http://0.0.0.0:2379 isLeader=false d282ac2ce600c1ce: name=etcd2 peerURLs=http://etcd2:2380 clientURLs=http://0.0.0.0:2379 isLeader=true $ docker exec -t etcd3 etcdctl -C http://etcd1:2379,http://etcd2:2379,http://etcd3:2379 member list ade526d28b1f92f7: name=etcd1 peerURLs=http://etcd1:2380 clientURLs=http://0.0.0.0:2379 isLeader=false bd388e7810915853: name=etcd3 peerURLs=http://etcd3:2380 clientURLs=http://0.0.0.0:2379 isLeader=false d282ac2ce600c1ce: name=etcd2 peerURLs=http://etcd2:2380 clientURLs=http://0.0.0.0:2379 isLeader=true 4、集群的使用\n我们往一个node上上传数据，在其他node上就能下载到。\n$ curl -L http://127.0.0.1:57854/v2/keys/foo -XPUT -d value=\u0026#34;Hello foo\u0026#34; curl -L http://127.0.0.1:57854/v2/keys/foo1/foo1 -XPUT -d value=\u0026#34;Hello foo1\u0026#34; curl -L http://127.0.0.1:57854/v2/keys/foo2/foo2 -XPUT -d value=\u0026#34;Hello foo2\u0026#34; curl -L http://127.0.0.1:57854/v2/keys/foo2/foo21/foo21 -XPUT -d value=\u0026#34;Hello foo21\u0026#34; {\u0026#34;action\u0026#34;:\u0026#34;set\u0026#34;,\u0026#34;node\u0026#34;:{\u0026#34;key\u0026#34;:\u0026#34;/foo\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Hello foo\u0026#34;,\u0026#34;modifiedIndex\u0026#34;:9,\u0026#34;createdIndex\u0026#34;:9}} {\u0026#34;action\u0026#34;:\u0026#34;set\u0026#34;,\u0026#34;node\u0026#34;:{\u0026#34;key\u0026#34;:\u0026#34;/foo1/foo1\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Hello foo1\u0026#34;,\u0026#34;modifiedIndex\u0026#34;:10,\u0026#34;createdIndex\u0026#34;:10}} {\u0026#34;action\u0026#34;:\u0026#34;set\u0026#34;,\u0026#34;node\u0026#34;:{\u0026#34;key\u0026#34;:\u0026#34;/foo2/foo2\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Hello foo2\u0026#34;,\u0026#34;modifiedIndex\u0026#34;:11,\u0026#34;createdIndex\u0026#34;:11}} {\u0026#34;action\u0026#34;:\u0026#34;set\u0026#34;,\u0026#34;node\u0026#34;:{\u0026#34;key\u0026#34;:\u0026#34;/foo2/foo21/foo21\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Hello foo21\u0026#34;,\u0026#34;modifiedIndex\u0026#34;:12,\u0026#34;createdIndex\u0026#34;:12}} $ curl -L http://127.0.0.1:57856/v2/keys/foo curl -L http://127.0.0.1:57856/v2/keys/foo2 curl -L http://127.0.0.1:57856/v2/keys/foo2\\?recursive\\=true {\u0026#34;action\u0026#34;:\u0026#34;get\u0026#34;,\u0026#34;node\u0026#34;:{\u0026#34;key\u0026#34;:\u0026#34;/foo\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Hello foo\u0026#34;,\u0026#34;modifiedIndex\u0026#34;:9,\u0026#34;createdIndex\u0026#34;:9}} {\u0026#34;action\u0026#34;:\u0026#34;get\u0026#34;,\u0026#34;node\u0026#34;:{\u0026#34;key\u0026#34;:\u0026#34;/foo2\u0026#34;,\u0026#34;dir\u0026#34;:true,\u0026#34;nodes\u0026#34;:[{\u0026#34;key\u0026#34;:\u0026#34;/foo2/foo2\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Hello foo2\u0026#34;,\u0026#34;modifiedIndex\u0026#34;:11,\u0026#34;createdIndex\u0026#34;:11},{\u0026#34;key\u0026#34;:\u0026#34;/foo2/foo21\u0026#34;,\u0026#34;dir\u0026#34;:true,\u0026#34;modifiedIndex\u0026#34;:12,\u0026#34;createdIndex\u0026#34;:12}],\u0026#34;modifiedIndex\u0026#34;:11,\u0026#34;createdIndex\u0026#34;:11}} {\u0026#34;action\u0026#34;:\u0026#34;get\u0026#34;,\u0026#34;node\u0026#34;:{\u0026#34;key\u0026#34;:\u0026#34;/foo2\u0026#34;,\u0026#34;dir\u0026#34;:true,\u0026#34;nodes\u0026#34;:[{\u0026#34;key\u0026#34;:\u0026#34;/foo2/foo21\u0026#34;,\u0026#34;dir\u0026#34;:true,\u0026#34;nodes\u0026#34;:[{\u0026#34;key\u0026#34;:\u0026#34;/foo2/foo21/foo21\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Hello foo21\u0026#34;,\u0026#34;modifiedIndex\u0026#34;:12,\u0026#34;createdIndex\u0026#34;:12}],\u0026#34;modifiedIndex\u0026#34;:12,\u0026#34;createdIndex\u0026#34;:12},{\u0026#34;key\u0026#34;:\u0026#34;/foo2/foo2\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Hello foo2\u0026#34;,\u0026#34;modifiedIndex\u0026#34;:11,\u0026#34;createdIndex\u0026#34;:11}],\u0026#34;modifiedIndex\u0026#34;:11,\u0026#34;createdIndex\u0026#34;:11}} ","description":"说明 使用docker-compose搭建etcd集群环境\netcd是一个集群环境，用来管理微服务架构下面的配置管理功能。 A distributed, reliable key-value store for the most critical data of a distributed system."},{"id":113,"href":"/tags/etcd/","title":"Etcd","parent":"Tags","content":"","description":""},{"id":114,"href":"/tags/ClickHouse/","title":"ClickHouse","parent":"Tags","content":"","description":""},{"id":115,"href":"/docker/install_clickhouse/","title":"Docker 安装 ClickHouse","parent":"容器","content":" docker docker pull yandex/clickhouse-server docker run -d --name ck-server --ulimit nofile=262144:262144 -p 8123:8123 -p 9000:9000 -p 9009:9009 yandex/clickhouse-server docker exec -it ck-server /bin/bash clickhouse-client #进入数据库 建库、建表、建测试数据（均为本地测试）\ncreate database statics engine=Ordinary; use statics; create table mysql_slow_log ( id UInt16, user_name String, host String, sql String, rows_examined UInt16, exec_time UInt16, query_time String, create_time date )engine=MergeTree(create_time, (id), 8192); insert into mysql_slow_log (user_name, host, sql, rows_examined, exec_time, query_time, create_time) values(\u0026#39;xiaoming\u0026#39;, \u0026#39;127.0.0.1\u0026#39;, \u0026#39;select * from music\u0026#39;, 3000, 1587021607, \u0026#39;0.333\u0026#39;, \u0026#39;2020-04-16 15:32:17\u0026#39;); 参考：https://studygolang.com/articles/28061\n","description":"docker docker pull yandex/clickhouse-server docker run -d --name ck-server --ulimit nofile=262144:262144 -p 8123:8123 -p 9000:9000 -p 9009:9009 yandex/clickhouse-server docker exec -it ck-server /bin/bash clickhouse-client #进入数据库 建库、建表、建测试数据（均为本地测试）"},{"id":116,"href":"/csapp/20201109%E5%88%B020201115%E6%97%A5%E8%AF%BB%E4%B9%A6%E6%B1%87%E6%80%BB--%E7%AC%AC%E5%85%AB%E5%91%A8/","title":"20201109到20201115日读书汇总--第八周","parent":"读书笔记","content":" 虚拟内存9.6 第 1 步：处理器生成一个虚拟地址，并把它传送给 MMU。 第 2 步：MMU 生成 PTE 地址，并从高速缓存/主存请求得到它。 第 3 步：高速缓存/主存向 MMU 返回 PTE。 第 4 步：MMU 构造物理地址，并把它传送给高速缓存/主存。 第 5 步：高速缓存/主存返回所请求的数据字给处理器。\n虚拟内存9.7 Linux内核下的缺页异常处理步骤：\n判断给定的虚拟地址值本身是否合法。判断方法是把给定值和区域结构链表的每个结点的起止点比较。如果结果不合法，则触发一个段错误，终止进程。\n判断对这个地址进行的操作是否合法。如果不合法，触发一个保护异常并终止进程。\n如果前两步骤均未终止进程，则内核选择一个牺牲页面。如果该页面之前被修改过，则先写回磁盘。之后换入新的页面，更新页表。缺页处理程序返回，并把控制流交还给引发缺页异常的指令。之后MMU能正常地翻译给定的虚拟地址。\n虚拟内存9.8 Linux 通过将一个虚拟内存区域与一个磁盘上的对象（object）关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射（memory mapping），虚拟内存区域可以映射到两种类型的对象中的一种： Linux 文件系统中的普通文件：一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行目标文件。文件区（section）被分成页大小的片，每一片包含一个虚拟页面的初始内容。因为按需进行页面调度，所以这些虚拟页面没有实际交换进入物理内存，直到 CPU 第一次引用到页面（即发射一个虚拟地址，落在地址空间这个页面的范围之内）。如果区域比文件区要大，那么就用零来填充这个区域的余下部分。 匿名文件：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的全是二进制零。CPU 第一次引用这样一个区域内的虚拟页面时，内核就在物理内存中找到一个合适的牺牲页面，如果该页面被修改过，就将这个页面换出来，用二进制零覆盖牺牲页面并更新页表，将这个页面标记为是驻留在内存中的。注意在磁盘和内存之间并没有实际的数据传送。因为这个原因，映射到匿名文件的区域中的页面有时也叫做请求二进制零的页（demand-zero page）。\n虚拟内存9.9 申请（虚拟）内存空间时，可以使用mmap、munmap函数，不过使用经过封装的动态内存分配器，更方便，移植性更好。\n动态内存分配器维护一个进程的虚拟内存区域。对每个进程，内核维护一个变量brk，是一个指向堆顶的指针。\n分配器将堆视为一组不同大小的块的集合。每个块是一个连续的虚拟内存片，或是已分配的，或是空闲的。\n分配器存在两种风格：显式分配器、隐式分配器。显式分配器的典型例子就是malloc、free。隐式分配器广泛被如Java、Lisp等依赖垃圾回收机制的高级语言应用。本节之后讨论的内容都属于显式分配器。\nunistd.h内声明了sbrk函数，使用该函数手动扩展和收缩堆大小。\n显式分配器在设计时需要满足如下要求：\n处理任意请求序列。分配器不可以假设未来任何分配和释放请求的顺序。 立即响应请求。意味着缓存、重新排列请求等策略在分配器设计中不可用。 只使用堆。为保证分配器扩展性，分配器使用的任何非标量数据结构（是啥我也不知道）都必须保存在堆中。 对齐块。分配器所分配的块必须满足操作系统和硬件的字节对齐要求，使块可以保存任何数据对象。 不修改已分配的块。只能操作或改变空闲块，意味着压缩已分配块这类技术在分配器设计中无法使用。\n","description":"虚拟内存9.6 第 1 步：处理器生成一个虚拟地址，并把它传送给 MMU。 第 2 步：MMU 生成 PTE 地址，并从高速缓存/主存请求得到它。 第 3 步：高速缓存/主存向 MMU 返回 PTE。 第 4 步：MMU 构造物理地址，并把它传送给高速缓存/主存。 第 5 步：高速缓存/主存返回所请求的数据字给处理器。"},{"id":117,"href":"/tags/index/","title":"Index","parent":"Tags","content":"","description":""},{"id":118,"href":"/tags/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/","title":"深入理解计算机系统","parent":"Tags","content":"","description":""},{"id":119,"href":"/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/","title":"深入理解计算机系统","parent":"Categories","content":"","description":""},{"id":120,"href":"/csapp/20201102%E5%88%B020201108%E6%97%A5%E8%AF%BB%E4%B9%A6%E6%B1%87%E6%80%BB--%E7%AC%AC%E4%B8%83%E5%91%A8/","title":"020201102到20201108日读书汇总--第七周","parent":"读书笔记","content":" 第八章 异常控制流(8.5信号) 一种更高层次的软件形式的异常，称为unix信号，它允许进程中断其他进程。\n低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。信号提供了一种机制，通知用户进程发生了这些异常。\n8.5.2发送信号 进程组：每个进程都只属于一个进程组，进程组是由一个进程组ID来标识的。默认的，一个子进程和它的父进程同属于一个进程组。 在任何时刻，至多只有一个前台作业和0个或多个后台作业。外壳为每个作业创建一个独立的进程组，一个作业对应一个进程组。\n8.5.3接收信号 进程可以通过使用signal函数来修改和信号相关的默认行为。唯一的例外是SIGSTOP和SIGKILL，它们的默认行为不能被修改。\n8.5.4信号处理问题 当一个程序捕获多个信号时，容易有一些细问问题：\n第九章 虚拟存储器（9.1~9.5） 需要知道:\n虚拟存储器是硬件异常,硬件地址翻译,主存和磁盘文件,内核软件的完美交互 为每一个进程提供一个大的,一致的和私有的地址空间 将主存作为磁盘地址空间的高速缓存 保护每个进程的地址空间不被其他进程破坏 虚拟存储器遍布在计算机系统所有层次,硬件异常,汇编器,链接器,加载器,共享对象,文件和进程中扮演重要角色\n虚拟存储器是危险的:\n引用变量,间接引用指针,调用malloc动态分配程序,就会和虚拟存储器交互\n如果使用不当,将遇到危险复杂的与存储器有关的错误:段错误,保护错误\n物理寻址:\n计算机主存被组成为m个连续的字节大小的单元数组,每个字节地址叫做物理地址;\ncpu访问存储器最自然方式是使用物理地址,该方式成为物理寻址\n虚拟寻址\ncpu生成一个虚拟地址,来访问主存\n地址翻译\n将虚拟地址转为物理地址就叫做地址翻译\n地址翻译需要cpu和操作系统之间的合作\n​ 主要利用储存在主存中的查询表来动态翻译虚拟地址 ​ 查询表则由操作系统进行管理\n地址空间\n地址空间就是一个非负整数地址的有序集合\n如果地址空间中整数连续,则成为线性地址空间\n一个地址空间大小由表示最大地址需要的位数来描述\n虚拟地址空间就是在一个带虚拟存储器的系统中,cpu从一个有N=2^n个地址的地址空间中生成虚拟地址,这个地址空间成为虚拟地址空间\n那当然也有物理地址空间,与系统中物理存储器的M=2^m个字节对应\n","description":"第八章 异常控制流(8.5信号) 一种更高层次的软件形式的异常，称为unix信号，它允许进程中断其他进程。\n低层的硬件异常是由内核异常处理程序处理的，正常情况下，对用户进程而言是不可见的。信号提供了一种机制，通知用户进程发生了这些异常。\n8.5.2发送信号 进程组：每个进程都只属于一个进程组，进程组是由一个进程组ID来标识的。默认的，一个子进程和它的父进程同属于一个进程组。 在任何时刻，至多只有一个前台作业和0个或多个后台作业。外壳为每个作业创建一个独立的进程组，一个作业对应一个进程组。\n8.5.3接收信号 进程可以通过使用signal函数来修改和信号相关的默认行为。唯一的例外是SIGSTOP和SIGKILL，它们的默认行为不能被修改。"},{"id":121,"href":"/csapp/20201026%E5%88%B020201101%E6%97%A5%E8%AF%BB%E4%B9%A6%E6%B1%87%E6%80%BB--%E7%AC%AC%E5%85%AD%E5%91%A8/","title":"20201026到20201101日读书汇总--第六周","parent":"读书笔记","content":" 第七章 链接 链接是将各种代码和数据片段搜集并组合成为一个单一文件的过程。 链接器使得分离编译成为可能。\n学习链接的目的\n理解链接器将帮助你构造大型程序 理解链接器将帮助你避免一些危险的编程错误 理解链接器将帮助你理解语言的作用域规则是如何实现的 理解链接器将帮助你理解其他重要的系统概念 理解链接器将使你能够利用共享库 7.1 编译器驱动程序 7.2 静态链接 静态链接器：以一组可重定位目标文件和命令行参数作为输入，生成一个完全链接的、可以加载和运行的可执行目标文件作为输出。 链接器主要任务\n符号解析：日标文件定义和引用符号，每个符号对应于一个函数、一个全局变量或一个静态变量（即C语言中任何以static属性声明的变量）。符号解析的目的是将每个符号引用正好和一个符号定义关联起来。 重定位：编译器和汇编器生成从地址0开始的代码和数据节，链接器通过把每个符号定义与一个内存位置关联起来，从而重定位这些节，然后修改所有对这些符号的引用，使得它们指向这个内存位置。链接器使用汇编器产生的重定位条目的详细指令，不加甄别地执行这样的重定位。 7.3 目标文件 目标文件形式\n可重定位目标文件：包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。 可执行目标文件：包含二进制代码和数据，其形式可以被直接复制到内存并执行。 共享目标文件：一种特殊类型的可重定位目标文件，可以在加载或者运行时被动态地加载进内存并链接。 编译器和汇编器生成可重定位目标文件（包括共享目标文件）。 链接器生成可执行目标文件。 目标文件是按照特定的目标格式来组织的，各个系统的目标文件格式都不同。\n7.4 可重定位目标文件 .text：已编译程序的机器代码 .rodata：只读数据，比如printf语句中的格式串和开关语句的跳转表 .data：已初始化的全局和静态C变量。局部C变量在运行时被保存在栈中，既不出现在.data节中，也不出现在.bss节中。 .bss：未初始化的全局和静态C变量，以及所有被初始化为0的全局或静态变量。在目标文件中这个节不占据实际的空间，它仅仅是一个占位符。目标文件格式区分已初始化和未初始化变量是为了空间效率：在目标文件中，未初始化变量不需要占据任何实际的磁盘空间。运行时，在内存中分配这些变量，初始值为0。 .symtab：一个符号表，它存放在程序中定义和引用的函数和全局变量的信息。一些程序员错误地认为必须通过-g选项来编译一个程序，才能得到符号表信息。实际上，每个可重定位目标文件在.symtab中都有一张符号表（除非程序员特意用STRIP命令去掉它）。然而，和编译器中的符号表不同，.symtab符号表不包含局部变量的条目。 .rel.text：一个.text节中位置的列表，当链接器把这个目标文件和其他文件组合时，需要修改这些位置。一般而言，任何调用外部函数或者引用全局变量的指令都需要修改。另一方面，调用本地函数的指令则不需要修改。注意，可执行目标文件中并不需要重定位信息，因此通常省略，除非用户显式地指示链接器包含这些信息。 .rel.data：被模块引用或定义的所有全局变量的重定位信息。一般而言，任何已初始化的全局变量，如果它的初始值是一个全局变量地址或者外部定义函数的地址，都需要被修改。 .debug：一个调试符号表，其条目是程序中定义的局部变量和类型定义，程序中定义和引用的全局变量，以及原始的C源文件。只有以-g选项调用编译器驱动程序时，才会得到这张表。 .line：原始C源程序中的行号和.text节中机器指令之间的映射。只有以-g选项调用编译器驱动程序时，才会得到这张表。 .strtab：一个字符串表，其内容包括.symtab和.debug节中的符号表，以及节头部中的节名字。字符串表就是以nu11结尾的字符串的序列。\n7.5 符号和符号表 每个可重定位目标模块m都有一个符号表 由模块m定义并能被其他模块引用的全局符号 全局链接器符号对应于非静态的C函数和全局变量 有其他模块定义并被模块m引用的全局符号 这些符号称为外部符号，对应于在其他模块中定义的非静态C函数和全局变量 只被模块m定义和引用的局部符号 他们对应于带static属性的C函数和全局变量。这些符号在模块m中任何位置可见，但是不能被其他模块引用。\n认识到本地链接器符号和本地程序变量不同是很重要的\n.symtab中的符号表不包含对应于本地非静态程序变量的任何符号。这些符号在运行时再栈中管理。链接器对此类符号不感兴趣。\n定义为带有C static属性的本地过程变量是不在栈中管理的，相反，编译器在.data或.bss中为每个定义分配空间，并在符号表中创建一个有唯一名字的本地链接器符号\nCOMMON 未初始化的全局变量 .bss 未初始化的静态变量，和初始化为0的全局或静态变量\n7.6 符号解析 链接器解析符号引用的方法是将每个引用与它输入的可重定位目标文件的符号表中的一个确定的符号定义关联起来。 编译器只允许每个模块中每个局部符号有一个定义。 静态局部变量也会有本地链接器符号，编译器还要确保他们拥有唯一的名字。\n对全局符号的引用解析就棘手得多。当编译器遇到一个不是在当前模块中定义的符号（变量或函数名）时，会假设该符号是在其他某个模块中定义的，生成一个链接器符号表条目，并把它交给链接器处理。如果链接器在它的任何输入模块中都找不到这个被引用符号的定义，就输出一条（通常很难阅读的）错误信息并终止。\n7.7 重定位 重定位将合并输入模块，并为每个符号分配运行时地址 重定位节和符号定义 链接器将所有相同类型的节合并为同一类型的新的聚合节 链接器将运行时内存地址赋给新的聚合节，赋给输入模块定义的每个节，以及赋给输入模块定义的每个符号 程序中的每条指令和全局变量都有唯一的运行时内存地址 重定位节中的符号引用 链接器修改代码节和数据节中对每个符号的引用，依赖于可重定位目标模块中称为重定位条目的数据结构\n7.8 可执行目标文件 它还包括程序的入口点，也就是当程序运行时要执行的第一条指令的地址。\n.init节定义了一个小函数_init，程序初始化代码会调用它。\n因为可执行文件是完全链接的，所以不再需要.rel节。\n程序头部表描述了可执行文件的连续的片被映射到连续的内存段的映射关系。\n7.9 加载可执行目标文件 加载：加载器将可执行目标文件中的代码和数据从磁盘复制到内存中，然后通过跳转到程序的第一条指令或入口点来运行该程序。\n7.10 动态链接共享库 共享库是一个目标模块，在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。这个过程称为动态链接，是由一个叫做动态链接器的程序来执行的。\n共享库也称为共享目标，在Linux系统中通常用.so后缀来表示。\n7.11 从应用程序中加载和链接共享库 动态链接是一项强大有用的技术。下面是一些现实世界中的例子 分发软件。微软Windows应用的开发者常常利用共享库来分发软件更新。他们生成一个共享库的新版本，然后用户可以下载，并用它替代当前的版本。下一次他们运行应用程序时，应用将自动链接和加载新的共享库。 构建高性能Web服务器。许多Web服务器生成动态内容，比如个性化的Web页面、账户余额和广告标语。早期的Web服务器通过使用fork和execve创建一个子进程，并在该子进程的上下文中运行CGI程序来生成动态内容。然而，现代高性能的Web服务器可以使用基于动态链接的更有效和完善的方法来生成动态内容。 其思路是将每个生成动态内容的函数打包在共享库中。当一个来自Web浏览器的请求到达时，服务器动态地加载和链接适当的函数，然后直接调用它，而不是使用fork和execve在子进程的上下文中运行函数。\n7.13 库打桩机制 库打桩（library interpositioning），它允许你截获对共享库函数的调用，取而代之执行自己的代码。\n基本思想：给定一个需要打桩的目标函数，创建一个包装函数，它的原型与目标函数完全一样。使用某种特殊的打桩机制，你就可以欺骗系统调用包装函数而不是目标函数了。包装函数通常会执行它自己的逻辑，然后调用目标函数，再将日标函数的返回值传递给调用者。\n打桩可以发生在编译时、链接时或当程序被加载和执行的运行时。\n7.14 处理目标文件的工具 在linux系统中有大量可用的工具可以帮助你理解和处理目标文件。特别地，GNU binutils包尤其有帮助，而且可以运行在每个Linux平台上。 AR：创建静态库，插入、删除、列出和提取成员。 STRINGS：列出一个目标文件中所有可打印的字符串。 STRIP：从日标文件中删除符号表信息。 NM：列出一个目标文件的符号表中定义的符号。 SIZE：列出日标文件中节的名字和大小。 READELF：显示一个目标文件的完整结构，包括ELF头中编码的所有信息。包含SIZE和NM的功能。 OBJDUMP：所有二进制工其之母。能够显示一个目标文件中所有的信息。它最大的作用是反汇编.text节中的二进制指令。 LDD：列出一个可执行文件在运行时所需要的共享库。\n第八章 异常控制流 从给处理器加电，到断电为止，处理器做的工作其实就是不断地读取并执行一条条指令。这些指令的序列就叫做 CPU 的控制流（control flow）。最简单的控制流是“平滑的”，也就是相邻的指令在存储器中是相邻的。当然，控制流不总是平滑的，不总是一条接一条地执行，总会有出现改变控制流的情况。我们知道的程序内部状态改变的机制有两条：\n跳转和分支 调用和返回 这些机制局限于程序本身的控制。当系统状态（system state）发生改变的时候，以上机制就不能很好地应对复杂的情况，例如：\n数据从磁盘或者网络适配器到达 有一条指令执行了除以零的操作 用户按下 ctrl+c 系统内部的计时器到时间 现代系统通过使控制流发生突变来应对这些情况。这种机制叫做异常控制流（exceptional control flow）。异常控制流发生在计算机系统的各个层次。\n","description":"第七章 链接 链接是将各种代码和数据片段搜集并组合成为一个单一文件的过程。 链接器使得分离编译成为可能。\n学习链接的目的\n理解链接器将帮助你构造大型程序 理解链接器将帮助你避免一些危险的编程错误 理解链接器将帮助你理解语言的作用域规则是如何实现的 理解链接器将帮助你理解其他重要的系统概念 理解链接器将使你能够利用共享库 7."},{"id":122,"href":"/csapp/20201019%E5%88%B020201025%E6%97%A5%E8%AF%BB%E4%B9%A6%E6%B1%87%E6%80%BB--%E7%AC%AC%E4%BA%94%E5%91%A8/","title":"20201019到20201025日读书汇总--第五周","parent":"读书笔记","content":"存储器系统是一个具有不同容量、成本和访问时间的存储设备的层次结构。CPU寄存器保存着最常用的数据。靠近CPU的小的、快速的高速缓存（SRAM）作为一部分存储在相对慢速的主存储器（DRAM）中数据和指令的缓冲区域。主存储器（DRAM）缓存存储在容量较大的、慢速磁盘（本地磁盘）上的数据，而这些磁盘常常又作为存储在通过网络连接的其他机器的磁盘或磁带（分布式文件系统，Web服务器）上的数据的缓存区域。\n局部性是计算机程序的一个基本属性。具有良好局部性的程序倾向于一次又一次地访问相同的数据项集合，或是倾向于访问邻近的数据项集合。具有良好局部性的程序比局部性差的程序更多地倾向于从存储器层次结构中较高层次处访问数据项，因此运行得更快。\n一、存储技术 1.1、随机访问存储器 随机访问存储器（RAM）分为两类：静态RAM（SRAM）和动态RAM（DRAM）。\n1、静态RAM SRAM将每个位存储在一个双稳态的存储器单元里，每个单元用六个晶体管电路实现（成本相对高）。双稳态就是电路可以无限期地保持在两个不同的电压配置或状态之一。其他任何状态都是不稳定的——从不稳定状态开始，电路会迅速地转移到两个稳定状态中的一个。\n由于双稳态特性，SRAM只要有电，它就会永远保持它的值（抗干扰性强）。\n2、动态RAM DRAM将每个位存储为对一个电容的充电，每个单元由一个电容和一个访问晶体管组成（成本相对低）。与SRAM不同，DRAM存储器单元对干扰非常敏感（抗干扰性弱）。当电容的电压被扰乱之后，它就永远不会恢复了。暴露在光线下会导致电容电压改变。\n内存系统必须周期性地通过对DRAM读出，然后重写来刷新内存每一位。\nSRAM和DRAM的对比：\n3、传统的DRAM DRAM芯片中的单元（位）被分成d个超单元，每个超单元由 [w] 个DRAM单元组成。一个d * [公w] 的DRAM总共存储了d [w] 位信息。\n超单元被组织成一个r行c列的长方形矩阵，其中r * c = d。\n每个超单元有形如(i, j)的地址，i表示行，j表示列。\n信息通过称为引脚的外部连接器流入和流出芯片。每个引脚携带一个1位的信号。\n有两种引脚：\naddr引脚 —— 携带行和列超单元地址 data引脚 —— 传送字节到芯片，或从芯片传出字节 每个DRAM芯片被连接到某个称为\u0026quot;内存控制器\u0026quot;的电路，内存控制器通过addr引脚和data引脚与DRAM进行数据的交互。\n4、内存模块 DRAM芯片封装在内存模块中，它插到主板的扩展槽上。\nCore i7系统使用240个引脚的双列直插内存模块。\n下图展示了用8个8M（超单元数） * 8（每个超单元存储一个字节）的DRAM芯片构成的内存模块，总共存储64MB（8 * 8M * 8B）。\n用各个DRAM芯片中相应超单元地址都为(i, j)的8个超单元来表示主存中字节地址A处的64位字。DRAM 0存储第一个（低位）字节，DRAM 1存储下一个字节，依次类推。\n要取出内存地址A处的一个字，内存控制器将A转换成一个超单元地址（i, j)，并将它发送到内存模块，然后内存模块再将i和j广播到每个DRAM。作为响应，每个DRAM输出它的(i, j)超单元的8位内容。模块中的电路收集这些输出，并把它们合并成一个64位字，再返回给内存控制器。\n5、增强的DRAM 一些后来发展并增强DRAM：\n块页模式DRAM（Fast Page Mode DRAM， FPM DRAM） 扩展数据输出DRAM（Extended Data Out DRAM，EDO DRAM） 同步DRAM（Synchronous DRAM, SDRAM） 双倍数据速率同步DRAM（Double Data-Rate Synchronous DRAM, DDR SDRAM） 视频RAM（Video RAM，VRAM） 6、非易失性存储器 如果断电，DRAM和SRAM会丢失它们的信息，它们是易失的。\n而非易失性存储器即使是在关电后，仍然保存着它们的信息。\n只读存储器（ROM）以它们能够被重编程（写)的次数和对它们进行重编程所用的机制来区分的：\n可编程ROM（Programmable ROM, PROM） —— 只能被编程一次 可擦写可编程ROM（Erasable Programmable ROM，EPROM） —— 被擦除和重编程的次数的数量级可以达到1000次 电子可擦除PROM（Electrically Erasable PROM， EEPROM） —— 能够被编程的次数的数量级可以达到 [10的5次方] 7、访问主存 数据流通过总线在CPU和DRAM主存之间传输。这些传输的过程称为总线事务。\n读事务从主存传送数据到CPU，写事务从CPU传送数据到主存。\n下图是总线结构的示例图：\n","description":"存储器系统是一个具有不同容量、成本和访问时间的存储设备的层次结构。CPU寄存器保存着最常用的数据。靠近CPU的小的、快速的高速缓存（SRAM）作为一部分存储在相对慢速的主存储器（DRAM）中数据和指令的缓冲区域。主存储器（DRAM）缓存存储在容量较大的、慢速磁盘（本地磁盘）上的数据，而这些磁盘常常又作为存储在通过网络连接的其他机器的磁盘或磁带（分布式文件系统，Web服务器）上的数据的缓存区域。\n局部性是计算机程序的一个基本属性。具有良好局部性的程序倾向于一次又一次地访问相同的数据项集合，或是倾向于访问邻近的数据项集合。具有良好局部性的程序比局部性差的程序更多地倾向于从存储器层次结构中较高层次处访问数据项，因此运行得更快。\n一、存储技术 1.1、随机访问存储器 随机访问存储器（RAM）分为两类：静态RAM（SRAM）和动态RAM（DRAM）。\n1、静态RAM SRAM将每个位存储在一个双稳态的存储器单元里，每个单元用六个晶体管电路实现（成本相对高）。双稳态就是电路可以无限期地保持在两个不同的电压配置或状态之一。其他任何状态都是不稳定的——从不稳定状态开始，电路会迅速地转移到两个稳定状态中的一个。\n由于双稳态特性，SRAM只要有电，它就会永远保持它的值（抗干扰性强）。\n2、动态RAM DRAM将每个位存储为对一个电容的充电，每个单元由一个电容和一个访问晶体管组成（成本相对低）。与SRAM不同，DRAM存储器单元对干扰非常敏感（抗干扰性弱）。当电容的电压被扰乱之后，它就永远不会恢复了。暴露在光线下会导致电容电压改变。"},{"id":123,"href":"/csapp/20201012%E5%88%B020201018%E6%97%A5%E8%AF%BB%E4%B9%A6%E6%B1%87%E6%80%BB--%E7%AC%AC%E5%9B%9B%E5%91%A8/","title":"第四周20201012到20201018日读书汇总","parent":"读书笔记","content":" 读书内容 程序的机器表示 章节 3.8~3.12\n3.8 数组访问与分配 数组定义 数组是某种基本数据类型数据的集合 对于数据类型 T 和整型常数 N，数组的声明如下：\nT A[N] 上面的 A 称为数组名称。它有两个效果： ①、它在存储器中分配一个 L*N 字节的连续区域，这里 L 是数据类型 T 的大小（单位为字节） ②、A 作为指向数组开头的指针，如果分配的连续区域的起始地址为 xa，那么这个指针的值就是xa\n即当用 A[i] 去读取数组元素的时候，其实我们访问的是 xa+i*sizeof(T)。sizeof(T)是获得数据类型T的占用内存大小，以字节为单位，比如如果T为int，那么sizeof(int)就是4。因为数组的下标是从0开始的，当 i等于0时，我们访问的地址就是 xa\npackage main import \u0026#34;fmt\u0026#34; func test1() { a := [10]int{} for i := 0; i \u0026lt; 10; i++ { fmt.Println(i, \u0026amp;a[i]) } } 运行结果：\n0 0xc0000e4000 1 0xc0000e4008 2 0xc0000e4010 3 0xc0000e4018 4 0xc0000e4020 5 0xc0000e4028 6 0xc0000e4030 7 0xc0000e4038 8 0xc0000e4040 9 0xc0000e4048 数组嵌套 package main import \u0026#34;fmt\u0026#34; func test2() { a := [5][5]int{} for i := 0; i \u0026lt; 5; i++ { for j := 0; j \u0026lt; 5; j++ { fmt.Println(i, j, \u0026amp;a[i][j]) } } } 运行结果：\n0 0 0xc0000e4000 0 1 0xc0000e4008 0 2 0xc0000e4010 0 3 0xc0000e4018 0 4 0xc0000e4020 1 0 0xc0000e4028 1 1 0xc0000e4030 1 2 0xc0000e4038 1 3 0xc0000e4040 1 4 0xc0000e4048 2 0 0xc0000e4050 2 1 0xc0000e4058 2 2 0xc0000e4060 2 3 0xc0000e4068 2 4 0xc0000e4070 3 0 0xc0000e4078 3 1 0xc0000e4080 3 2 0xc0000e4088 3 3 0xc0000e4090 3 4 0xc0000e4098 4 0 0xc0000e40a0 4 1 0xc0000e40a8 4 2 0xc0000e40b0 4 3 0xc0000e40b8 4 4 0xc0000e40c0 3.9 异质的数据结构 结构（structure），用关键词struct来声明，将多个对象集合到一个单位中 联合（union），用关键词union来声明，允许用几种不同的类型来引用一个对象 const ( N = 16 ) type fix_matrix [N][N]int type People struct { Name string Sex string Age int Address string } type Student struct { People Attribute int } 3.10 在机器级程序中将控制与数据结合起来 指针是C语言的一个核心特色，它提供了一种统一方式，对不同数据结构中的元素产生引用。 每个指针都对应一个类型，void *类型代表通用指针，它通过强制或隐式类型转换变成一个有类型的指针。 每个指针都有一个值，NULL(0)值表示指针没有指向任何地方。 指针用\u0026amp;操作符创建。 *操作符用于间接引用指针。 数组与指针紧密联系。 将指针从一种类型强制转换为另一种类型，只改变它的类型而不改变它的值，效果只是改变指针- 运算的伸缩。 指针也可以指向函数。 package main import \u0026#34;net/http\u0026#34; type starInt *int type handler *func(http.ResponseWriter, *http.Request) 3.11 浮点代码 处理器的浮点体系结构包括多个方面，会影响对浮点数据操作的程序如何被映射到机器上，包括： 1） 如何存储和访问浮点数据。通常是通过某种寄存器方式来完成。 2） 对浮点数据操作的指令。 3） 想函数传递浮点数参数和从函数返回浮点数结构的规则。 4） 函数调用过程保持寄存器的规则——例如，一些寄存器被指定为调用者保存，而其他的被指定为被调用者保存。\npackage main func float_mov(v1 float32, src, dest *float32) float32 { v2 := *src dest = \u0026amp;v1 return v2 } 把浮点值转换成整数时，指令会执行截断（truncation）\n","description":"读书内容 程序的机器表示 章节 3.8~3.12\n3.8 数组访问与分配 数组定义 数组是某种基本数据类型数据的集合 对于数据类型 T 和整型常数 N，数组的声明如下："},{"id":124,"href":"/tags/bug/","title":"Bug","parent":"Tags","content":"","description":""},{"id":125,"href":"/golang/casbin%E6%B5%8B%E8%AF%95%E5%8C%85%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/","title":"casbin测试包引用问题解决","parent":"golang","content":" 示例程序 基于casbin的权限管理示例\n参考:http://www.topgoer.com/gin框架/其他/权限管理.html\n示例代码：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;github.com/casbin/casbin\u0026#34; xormadapter \u0026#34;github.com/casbin/xorm-adapter\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; ) func main() { // 要使用自己定义的数据库rbac_db,最后的true很重要.默认为false,使用缺省的数据库名casbin,不存在则创建 a, err := xormadapter.NewAdapter(\u0026#34;mysql\u0026#34;, \u0026#34;root:123456@tcp(127.0.0.1:3306)/goblog?charset=utf8\u0026#34;, true) if err != nil { log.Printf(\u0026#34;连接数据库错误: %v\u0026#34;, err) return } e, err := casbin.NewEnforcer(\u0026#34;./rbac_models.conf\u0026#34;, a) if err != nil { log.Printf(\u0026#34;初始化casbin错误: %v\u0026#34;, err) return } //从DB加载策略 e.LoadPolicy() //获取router路由对象 r := gin.New() r.POST(\u0026#34;/api/v1/add\u0026#34;, func(c *gin.Context) { fmt.Println(\u0026#34;增加Policy\u0026#34;) if ok, _ := e.AddPolicy(\u0026#34;admin\u0026#34;, \u0026#34;/api/v1/hello\u0026#34;, \u0026#34;GET\u0026#34;); !ok { fmt.Println(\u0026#34;Policy已经存在\u0026#34;) } else { fmt.Println(\u0026#34;增加成功\u0026#34;) } }) //删除policy r.DELETE(\u0026#34;/api/v1/delete\u0026#34;, func(c *gin.Context) { fmt.Println(\u0026#34;删除Policy\u0026#34;) if ok, _ := e.RemovePolicy(\u0026#34;admin\u0026#34;, \u0026#34;/api/v1/hello\u0026#34;, \u0026#34;GET\u0026#34;); !ok { fmt.Println(\u0026#34;Policy不存在\u0026#34;) } else { fmt.Println(\u0026#34;删除成功\u0026#34;) } }) //获取policy r.GET(\u0026#34;/api/v1/get\u0026#34;, func(c *gin.Context) { fmt.Println(\u0026#34;查看policy\u0026#34;) list := e.GetPolicy() for _, vlist := range list { for _, v := range vlist { fmt.Printf(\u0026#34;value: %s, \u0026#34;, v) } } }) //使用自定义拦截器中间件 r.Use(Authorize(e)) //创建请求 r.GET(\u0026#34;/api/v1/hello\u0026#34;, func(c *gin.Context) { fmt.Println(\u0026#34;Hello 接收到GET请求..\u0026#34;) }) r.Run(\u0026#34;:9000\u0026#34;) //参数为空 默认监听8080端口 } //拦截器 func Authorize(e *casbin.Enforcer) gin.HandlerFunc { return func(c *gin.Context) { //获取请求的URI obj := c.Request.URL.RequestURI() //获取请求方法 act := c.Request.Method //获取用户的角色 sub := \u0026#34;admin\u0026#34; //判断策略中是否存在 if ok, _ := e.Enforce(sub, obj, act); ok { fmt.Println(\u0026#34;恭喜您,权限验证通过\u0026#34;) c.Next() } else { fmt.Println(\u0026#34;很遗憾,权限验证没有通过\u0026#34;) c.Abort() } } } go.mod文件 module haedu-rbac/casbin-test go 1.15 使用 go mod tidy 命令：\n$ go mod tidy go: finding module for package github.com/casbin/casbin go: finding module for package github.com/go-sql-driver/mysql go: finding module for package github.com/casbin/xorm-adapter go: finding module for package github.com/gin-gonic/gin go: found github.com/casbin/casbin in github.com/casbin/casbin v1.9.1 go: found github.com/casbin/xorm-adapter in github.com/casbin/xorm-adapter v1.0.0 go: found github.com/gin-gonic/gin in github.com/gin-gonic/gin v1.6.3 go: found github.com/go-sql-driver/mysql in github.com/go-sql-driver/mysql v1.5.0 go: finding module for package github.com/lib/pq go: finding module for package github.com/go-xorm/xorm go: found github.com/go-xorm/xorm in github.com/go-xorm/xorm v0.7.9 go: found github.com/lib/pq in github.com/lib/pq v1.8.0 go: finding module for package github.com/kr/pretty go: found github.com/kr/pretty in github.com/kr/pretty v0.2.1 执行之后go.mod文件：\nmodule haedu-rbac/casbin-test go 1.15 require ( github.com/casbin/casbin v1.9.1 github.com/casbin/xorm-adapter v1.0.0 github.com/gin-gonic/gin v1.6.3 github.com/go-sql-driver/mysql v1.5.0 github.com/go-xorm/xorm v0.7.9 // indirect github.com/kr/pretty v0.2.1 // indirect github.com/lib/pq v1.8.0 // indirect ) 示例程序提示的错误 提示返回参数不正确，查看NewAdapter源码：\n发现此版本的确返回一个参数。对比github的源码，而是返回的两个参数：\ngo.mod更改xorm-adapter版本 更改：\ngithub.com/casbin/xorm-adapter v1.0.0\n为：\ngithub.com/casbin/xorm-adapter master\n执行 go mod tidy 命令，最终显示为：\ngithub.com/casbin/xorm-adapter v1.0.1-0.20191120030838-267478260350\n【注】其他类库雷同错误也可按照以上步骤解决。\n最终go.mod文件：\nmodule haedu-rbac/casbin-test go 1.15 require ( github.com/casbin/casbin/v2 v2.14.2 github.com/casbin/xorm-adapter v1.0.1-0.20191120030838-267478260350 github.com/gin-gonic/gin v1.6.3 github.com/go-sql-driver/mysql v1.5.0 github.com/kr/pretty v0.2.1 // indirect github.com/lib/pq v1.8.0 // indirect ) 修改main.go中import包 import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; casbin \u0026#34;github.com/casbin/casbin/v2\u0026#34; xormadapter \u0026#34;github.com/casbin/xorm-adapter\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; ) casbin加上版本号~~~\n","description":"示例程序 基于casbin的权限管理示例\n参考:http://www.topgoer.com/gin框架/其他/权限管理.html\n示例代码：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;github."},{"id":126,"href":"/csapp/20200928%E5%88%B020201011%E6%97%A5%E8%AF%BB%E4%B9%A6%E6%B1%87%E6%80%BB--%E7%AC%AC%E4%B8%89%E5%91%A8/","title":"第三周20200928到20201011日读书汇总","parent":"读书笔记","content":" 3.1 到 3.7 总结 1、 x86 与 x64 的发展历程 2、摩尔定律（Moore 定律）\n摩尔定律是英特尔创始人之一戈登·摩尔的经验之谈，其核心内容为：集成电路上可以容纳的晶体管数目在大约每经过 24 个月便会增加一倍。换言之，处理器的性能每隔两年翻一倍。\n被称为计算机第一定律的摩尔定律是指 IC 上可容纳的晶体管数目，约每隔 24 个月便会增加一倍，性能也将提升一倍。摩尔定律是由英特尔(lnte)名誉董事长戈登·摩尔( Gordon moore)经过长期观察总结的经验。\n归纳起来，“摩尔定律”主要有以下 3 种“版本”：\n集成电路芯片上所集成的电路的数目，每隔 18 个月就翻一番； 微处理器的性能每隔 18 个月提高一倍，而价格下降一半； 用一美元所能买到的计算机性能，每隔 18 个月翻两番。 3、数据格式 数位扩展：16 位（字 word）-\u0026gt;32 位（双字 double words）-\u0026gt;64 位（四字 quad words） 4、数据传输指令 mov 类：movb、movw、movl 和 movq 5、条件码 CF:进位标志 ZF:零标志 SF:符号标志 OF:溢出标志\n","description":"3.1 到 3.7 总结 1、 x86 与 x64 的发展历程 2、摩尔定律（Moore 定律）"},{"id":127,"href":"/know/Mac-OS-%E5%AE%89%E8%A3%85-etcd/","title":"Mac OS 安装 etcd","parent":"知识点","content":" 使用 brew 安装 第一步： 确定 brew 是否有 etcd 包：\n$ brew search etcd ==\u0026gt; Formulae etcd ✔ netcdf pnetcdf 第二步： 安装\n$ brew install etcd Updating Homebrew... fatal: Could not resolve HEAD to a revision Warning: You are using macOS 11.0. We do not provide support for this pre-release version. You will encounter build failures with some formulae. Please create pull requests instead of asking for help on Homebrew\u0026#39;s GitHub, Discourse, Twitter or IRC. You are responsible for resolving any issues you experience while you are running this pre-release version. ==\u0026gt; Downloading https://mirrors.ustc.edu.cn/homebrew-bottles/bottles/etcd-3.4.13.catalina.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring etcd-3.4.13.catalina.bottle.tar.gz ==\u0026gt; Caveats To have launchd start etcd now and restart at login: brew services start etcd Or, if you don\u0026#39;t want/need a background service you can just run: etcd ==\u0026gt; Summary 🍺 /usr/local/Cellar/etcd/3.4.13: 8 files, 38.7MB 运行 etcd 安装完后，会有相关提示，告知我们怎么使用，推荐使用 brew services 来管理这些应用。\n$ brew services list ==\u0026gt; Tapping homebrew/services Cloning into \u0026#39;/usr/local/Homebrew/Library/Taps/homebrew/homebrew-services\u0026#39;... remote: Enumerating objects: 20, done. remote: Counting objects: 100% (20/20), done. remote: Compressing objects: 100% (20/20), done. remote: Total 932 (delta 8), reused 5 (delta 0), pack-reused 912 Receiving objects: 100% (932/932), 262.03 KiB | 294.00 KiB/s, done. Resolving deltas: 100% (383/383), done. Tapped 1 command (27 files, 324KB). Name Status User Plist etcd stopped $ brew services list Name Status User Plist etcd stopped brew services 常用的操作\n# 启动某个应用，这里用 etcd 做演示 brew services start etcd # 停止某个应用 brew services stop etcd # 查看当前应用列表 brew services list 启动 etcd：\n$ brew services start etcd ==\u0026gt; Successfully started `etcd` (label: homebrew.mxcl.etcd) $ brew services list Name Status User Plist etcd started zhushuyan /Users/zhushuyan/Library/LaunchAgents/homebrew.mxcl.etcd.plist 好了， etcd 已经启动了，现在验证下，是否正确的启动：\n$ etcdctl endpoint health 127.0.0.1:2379 is healthy: successfully committed proposal: took = 1.532483ms 至此，etcd 已经安装完毕。\n","description":"使用 brew 安装 第一步： 确定 brew 是否有 etcd 包："},{"id":128,"href":"/csapp/%E7%AC%AC%E4%B8%89%E7%AB%A0%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%BA%E5%99%A8%E8%A1%A8%E7%A4%BA/","title":"第三章程序的机器表示","parent":"读书笔记","content":" 1、历史观点 晶体管数量表示 K 表示 1,000 M 表示 1,000,000 G 表示 1,000,000,000\n摩尔定律（Moore 定律） 摩尔定律是英特尔创始人之一戈登·摩尔的经验之谈，其核心内容为：集成电路上可以容纳的晶体管数目在大约每经过 24 个月便会增加一倍。换言之，处理器的性能每隔两年翻一倍。\n被称为计算机第一定律的摩尔定律是指 IC 上可容纳的晶体管数目，约每隔 24 个月便会增加一倍，性能也将提升一倍。摩尔定律是由英特尔(lnte)名誉董事长戈登·摩尔( Gordon moore)经过长期观察总结的经验。\n归纳起来，“摩尔定律”主要有以下 3 种“版本”： 1、集成电路芯片上所集成的电路的数目，每隔 18 个月就翻一番； 2、微处理器的性能每隔 18 个月提高一倍，而价格下降一半； 3、用一美元所能买到的计算机性能，每隔 18 个月翻两番。\n2、程序编码 3、数据格式 字：word 表示 16 位数据类型 双字：double words，表示 32 位数据类型\n4、访问信息 5、算术和逻辑运算 加载有效地址 一元操作 二元操作 移位 6、控制 条件码 常用条件码：\nCF:进位标识 ZF:零标识 SF:符号标识 OF:溢出标识\n访问条件码 可以根据 条 件码的某种组 合 将 一 个字节 设置为 0 或 者 1 可以 条 件 跳转到程序的某个其他的部分 可以 有 条 件 地 传送数据。 跳转指令 jump：会导致\n跳转指令编码 循环 c 语言：do-while、while 和 for\n7、过程 函数：function 方法：method 子例程：subroutine 处理函数：handler\n包含机制：\n1 传递控制 2 传递数据 3 分配和释放内存 8、数组的分配与访问 9、异质的数据结构 c 语言：结构（struct）、联合（union）\n结构 数据对齐 强制对齐\n10、在机器程序中将控制与数据结合起来 理解指针 每个指针都对应一个类型 每个指针都有一个值 指针用\u0026amp;运算符创建 *操作符用于间接引用指针 数组与指针紧密联系 将指针从一种类型强制转换成另一种类型，只改变他的类型，而不改变他的值 指针也可以指向函数 函数指针\n内存越界引用和缓冲区溢出\n11、浮点代码 ","description":"1、历史观点 晶体管数量表示 K 表示 1,000 M 表示 1,000,000 G 表示 1,000,000,000"},{"id":129,"href":"/know/brew-update-error/","title":"brew update error","parent":"知识点","content":" $ brew update error: Not a valid ref: refs/remotes/origin/master fatal: ambiguous argument \u0026#39;refs/remotes/origin/master\u0026#39;: unknown revision or path not in the working tree. Use \u0026#39;--\u0026#39; to separate paths from revisions, like this: \u0026#39;git \u0026lt;command\u0026gt; [\u0026lt;revision\u0026gt;...] -- [\u0026lt;file\u0026gt;...]\u0026#39; 解决办法： 修改清华源命令：\n$ cd \u0026#34;$(brew --repo)\u0026#34; # zhushuyan @ bogon in /usr/local/Homebrew on git:stable o [6:39:27] $ git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git # zhushuyan @ bogon in /usr/local/Homebrew on git:stable o [6:39:36] $ cd \u0026#34;$(brew --repo)/Library/Taps/homebrew/homebrew-core\u0026#34; # zhushuyan @ bogon in /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core on git:master o [6:39:42] $ git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git ","description":"$ brew update error: Not a valid ref: refs/remotes/origin/master fatal: ambiguous argument \u0026#39;refs/remotes/origin/master\u0026#39;: unknown revision or path not in the working tree."},{"id":130,"href":"/flutter/%E5%AE%89%E8%A3%85sudo-gem-install-cocoapods/","title":"安装sudo gem install cocoapods","parent":"flutter","content":" 安装sudo gem install cocoapods 1 更改源 终端执行命令：\ngem sources --add \u0026lt;https://gems.ruby-china.com/\u0026gt; --remove \u0026lt;https://rubygems.org/\u0026gt; [注]需要用ruby-china.org由于备案问题, 所以需要改成.com访问了\n# 出现的异常，及解决方法 $ gem sources --add https://gems.ruby-china.org/ --remove https://rubygems.org/ Error fetching https://gems.ruby-china.org/: Errno::ECONNREFUSED: Failed to open TCP connection to gems.ruby-china.org:443 (Connection refused - connect(2) for \u0026#34;gems.ruby-china.org\u0026#34; port 443) (https://gems.ruby-china.org/specs.4.8.gz) # 正确安装 $ gem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/ https://gems.ruby-china.com/ added to sources https://rubygems.org/ removed from sources 2 查看源是否设置成功 接下来查看源路径是否替换成功，执行命令：\n$ gem sources -l *** CURRENT SOURCES *** https://gems.ruby-china.com/ 3 安装Cocoapods 3.1 安装命令 开始安装Cocoapods，执行命令：\n$ sudo gem install cocoapods Password: Fetching i18n-0.9.5.gem Fetching thread_safe-0.3.6.gem Fetching tzinfo-1.2.7.gem Fetching activesupport-4.2.11.3.gem Fetching nap-1.1.0.gem Fetching fuzzy_match-2.0.4.gem Fetching concurrent-ruby-1.1.7.gem Fetching httpclient-2.8.3.gem Fetching algoliasearch-1.27.4.gem Fetching ffi-1.13.1.gem Fetching ethon-0.12.0.gem Fetching typhoeus-1.4.0.gem Fetching netrc-0.11.0.gem Fetching cocoapods-core-1.9.3.gem Fetching claide-1.0.3.gem Fetching cocoapods-deintegrate-1.0.4.gem Fetching cocoapods-downloader-1.4.0.gem Fetching cocoapods-plugins-1.0.0.gem Fetching cocoapods-search-1.0.0.gem Fetching cocoapods-stats-1.1.0.gem Fetching cocoapods-trunk-1.5.0.gem Fetching cocoapods-try-1.2.0.gem Fetching molinillo-0.6.6.gem Fetching atomos-0.1.3.gem Fetching CFPropertyList-3.0.2.gem Fetching colored2-3.1.2.gem Fetching nanaimo-0.3.0.gem Fetching xcodeproj-1.18.0.gem Fetching escape-0.0.4.gem Fetching fourflusher-2.3.1.gem Fetching gh_inspector-1.1.3.gem Fetching ruby-macho-1.4.0.gem Fetching cocoapods-1.9.3.gem Successfully installed concurrent-ruby-1.1.7 Successfully installed i18n-0.9.5 Successfully installed thread_safe-0.3.6 Successfully installed tzinfo-1.2.7 Successfully installed activesupport-4.2.11.3 Successfully installed nap-1.1.0 Successfully installed fuzzy_match-2.0.4 Successfully installed httpclient-2.8.3 Successfully installed algoliasearch-1.27.4 Building native extensions. This could take a while... Successfully installed ffi-1.13.1 Successfully installed ethon-0.12.0 Successfully installed typhoeus-1.4.0 Successfully installed netrc-0.11.0 Successfully installed cocoapods-core-1.9.3 Successfully installed claide-1.0.3 Successfully installed cocoapods-deintegrate-1.0.4 Successfully installed cocoapods-downloader-1.4.0 Successfully installed cocoapods-plugins-1.0.0 Successfully installed cocoapods-search-1.0.0 Successfully installed cocoapods-stats-1.1.0 Successfully installed cocoapods-trunk-1.5.0 Successfully installed cocoapods-try-1.2.0 Successfully installed molinillo-0.6.6 Successfully installed atomos-0.1.3 Successfully installed CFPropertyList-3.0.2 Successfully installed colored2-3.1.2 Successfully installed nanaimo-0.3.0 Successfully installed xcodeproj-1.18.0 Successfully installed escape-0.0.4 Successfully installed fourflusher-2.3.1 Successfully installed gh_inspector-1.1.3 Successfully installed ruby-macho-1.4.0 Successfully installed cocoapods-1.9.3 Parsing documentation for concurrent-ruby-1.1.7 Installing ri documentation for concurrent-ruby-1.1.7 Parsing documentation for i18n-0.9.5 Installing ri documentation for i18n-0.9.5 Parsing documentation for thread_safe-0.3.6 Installing ri documentation for thread_safe-0.3.6 Parsing documentation for tzinfo-1.2.7 Installing ri documentation for tzinfo-1.2.7 Parsing documentation for activesupport-4.2.11.3 Installing ri documentation for activesupport-4.2.11.3 Parsing documentation for nap-1.1.0 Installing ri documentation for nap-1.1.0 Parsing documentation for fuzzy_match-2.0.4 Installing ri documentation for fuzzy_match-2.0.4 Parsing documentation for httpclient-2.8.3 Installing ri documentation for httpclient-2.8.3 Parsing documentation for algoliasearch-1.27.4 Installing ri documentation for algoliasearch-1.27.4 Parsing documentation for ffi-1.13.1 Installing ri documentation for ffi-1.13.1 Parsing documentation for ethon-0.12.0 Installing ri documentation for ethon-0.12.0 Parsing documentation for typhoeus-1.4.0 Installing ri documentation for typhoeus-1.4.0 Parsing documentation for netrc-0.11.0 Installing ri documentation for netrc-0.11.0 Parsing documentation for cocoapods-core-1.9.3 Installing ri documentation for cocoapods-core-1.9.3 Parsing documentation for claide-1.0.3 Installing ri documentation for claide-1.0.3 Parsing documentation for cocoapods-deintegrate-1.0.4 Installing ri documentation for cocoapods-deintegrate-1.0.4 Parsing documentation for cocoapods-downloader-1.4.0 Installing ri documentation for cocoapods-downloader-1.4.0 Parsing documentation for cocoapods-plugins-1.0.0 Installing ri documentation for cocoapods-plugins-1.0.0 Parsing documentation for cocoapods-search-1.0.0 Installing ri documentation for cocoapods-search-1.0.0 Parsing documentation for cocoapods-stats-1.1.0 Installing ri documentation for cocoapods-stats-1.1.0 Parsing documentation for cocoapods-trunk-1.5.0 Installing ri documentation for cocoapods-trunk-1.5.0 Parsing documentation for cocoapods-try-1.2.0 Installing ri documentation for cocoapods-try-1.2.0 Parsing documentation for molinillo-0.6.6 Installing ri documentation for molinillo-0.6.6 Parsing documentation for atomos-0.1.3 Installing ri documentation for atomos-0.1.3 Parsing documentation for CFPropertyList-3.0.2 Installing ri documentation for CFPropertyList-3.0.2 Parsing documentation for colored2-3.1.2 Installing ri documentation for colored2-3.1.2 Parsing documentation for nanaimo-0.3.0 Installing ri documentation for nanaimo-0.3.0 Parsing documentation for xcodeproj-1.18.0 Installing ri documentation for xcodeproj-1.18.0 Parsing documentation for escape-0.0.4 Installing ri documentation for escape-0.0.4 Parsing documentation for fourflusher-2.3.1 Installing ri documentation for fourflusher-2.3.1 Parsing documentation for gh_inspector-1.1.3 Installing ri documentation for gh_inspector-1.1.3 Parsing documentation for ruby-macho-1.4.0 Installing ri documentation for ruby-macho-1.4.0 Parsing documentation for cocoapods-1.9.3 Installing ri documentation for cocoapods-1.9.3 Done installing documentation for concurrent-ruby, i18n, thread_safe, tzinfo, activesupport, nap, fuzzy_match, httpclient, algoliasearch, ffi, ethon, typhoeus, netrc, cocoapods-core, claide, cocoapods-deintegrate, cocoapods-downloader, cocoapods-plugins, cocoapods-search, cocoapods-stats, cocoapods-trunk, cocoapods-try, molinillo, atomos, CFPropertyList, colored2, nanaimo, xcodeproj, escape, fourflusher, gh_inspector, ruby-macho, cocoapods after 23 seconds 33 gems installed 3.2 安装cocoapods出现异常 $ sudo gem install cocoapods Password: Building native extensions. This could take a while... ERROR: Error installing cocoapods: ERROR: Failed to build gem native extension. current directory: /Library/Ruby/Gems/2.6.0/gems/ffi-1.13.1/ext/ffi_c /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/bin/ruby -I /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0 -r ./siteconf20200926-19030-14rm5d4.rb extconf.rb *** extconf.rb failed *** Could not create Makefile due to some reason, probably lack of necessary libraries and/or headers. Check the mkmf.log file for more details. You may need configuration options. Provided configuration options: --with-opt-dir --without-opt-dir --with-opt-include --without-opt-include=${opt-dir}/include --with-opt-lib --without-opt-lib=${opt-dir}/lib --with-make-prog --without-make-prog --srcdir=. --curdir --ruby=/System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/bin/$(RUBY_BASE_NAME) --with-ffi_c-dir --without-ffi_c-dir --with-ffi_c-include --without-ffi_c-include=${ffi_c-dir}/include --with-ffi_c-lib --without-ffi_c-lib=${ffi_c-dir}/lib --enable-system-libffi --disable-system-libffi --with-libffi-config --without-libffi-config --with-pkg-config --without-pkg-config /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/mkmf.rb:467:in `try_do\u0026#39;: The compiler failed to generate an executable file. (RuntimeError) You have to install development tools first. from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/mkmf.rb:546:in `block in try_link0\u0026#39; from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/tmpdir.rb:93:in `mktmpdir\u0026#39; from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/mkmf.rb:543:in `try_link0\u0026#39; from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/mkmf.rb:570:in `try_link\u0026#39; from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/mkmf.rb:672:in `try_ldflags\u0026#39; from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/mkmf.rb:1832:in `pkg_config\u0026#39; from extconf.rb:9:in `system_libffi_usable?\u0026#39; from extconf.rb:42:in `\u0026lt;main\u0026gt;\u0026#39; To see why this extension failed to compile, please check the mkmf.log which can be found here: /Library/Ruby/Gems/2.6.0/extensions/universal-darwin-20/2.6.0/ffi-1.13.1/mkmf.log extconf failed, exit code 1 Gem files will remain installed in /Library/Ruby/Gems/2.6.0/gems/ffi-1.13.1 for inspection. Results logged to /Library/Ruby/Gems/2.6.0/extensions/universal-darwin-20/2.6.0/ffi-1.13.1/gem_make.out 3.3 解决安装cocoapods异常 从新安装rvm , 安装地址如下 https://rvm.io/rvm/install\nInstall RVM stable with ruby:\n$ curl -sSL https://get.rvm.io | bash -s stable --ruby Downloading https://github.com/rvm/rvm/archive/1.29.10.tar.gz Downloading https://github.com/rvm/rvm/releases/download/1.29.10/1.29.10.tar.gz.asc Found PGP signature at: \u0026#39;https://github.com/rvm/rvm/releases/download/1.29.10/1.29.10.tar.gz.asc\u0026#39;, but no GPG software exists to validate it, skipping. Upgrading the RVM installation in /Users/zhushuyan/.rvm/ RVM PATH line found in /Users/zhushuyan/.mkshrc /Users/zhushuyan/.profile /Users/zhushuyan/.bashrc /Users/zhushuyan/.zshrc. RVM sourcing line found in /Users/zhushuyan/.profile /Users/zhushuyan/.bash_profile /Users/zhushuyan/.zlogin. Upgrade of RVM in /Users/zhushuyan/.rvm/ is complete. Thanks for installing RVM 🙏 Please consider donating to our open collective to help us maintain RVM. 👉 Donate: https://opencollective.com/rvm/donate Ruby enVironment Manager 1.29.10 (latest) (c) 2009-2017 Michal Papis, Piotr Kuczynski, Wayne E. Seguin Searching for binary rubies, this might take some time. No binary rubies available for: osx/11.0/x86_64/ruby-2.7.0. Continuing with compilation. Please read \u0026#39;rvm help mount\u0026#39; to get more information on binary rubies. Checking requirements for osx. Installing requirements for osx. Updating system.......... Installing required packages: coreutils, libksba, zlib....... Updating certificates bundle \u0026#39;/usr/local/etc/openssl@1.1/cert.pem\u0026#39; Requirements installation successful. Installing Ruby from source to: /Users/zhushuyan/.rvm/rubies/ruby-2.7.0, this may take a while depending on your cpu(s)... ruby-2.7.0 - #downloading ruby-2.7.0, this may take a while depending on your connection... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 14.0M 100 14.0M 0 0 5359k 0 0:00:02 0:00:02 --:--:-- 5359k ruby-2.7.0 - #extracting ruby-2.7.0 to /Users/zhushuyan/.rvm/src/ruby-2.7.0..... ruby-2.7.0 - #configuring......................................................................... ruby-2.7.0 - #post-configuration. ruby-2.7.0 - #compiling........................................................................ ruby-2.7.0 - #installing............ ruby-2.7.0 - #making binaries executable... Installed rubygems 3.1.2 is newer than 3.0.8 provided with installed ruby, skipping installation, use --force to force installation. ruby-2.7.0 - #gemset created /Users/zhushuyan/.rvm/gems/ruby-2.7.0@global ruby-2.7.0 - #importing gemset /Users/zhushuyan/.rvm/gemsets/global.gems......................................- ruby-2.7.0 - #generating global wrappers....... ruby-2.7.0 - #gemset created /Users/zhushuyan/.rvm/gems/ruby-2.7.0 ruby-2.7.0 - #importing gemsetfile /Users/zhushuyan/.rvm/gemsets/default.gems evaluated to empty gem list ruby-2.7.0 - #generating default wrappers....... ruby-2.7.0 - #adjusting #shebangs for (gem irb erb ri rdoc testrb rake). Install of ruby-2.7.0 - #complete Ruby was built without documentation, to build it run: rvm docs generate-ri Creating alias default for ruby-2.7.0.... + To start using RVM you need to run `source /Users/zhushuyan/.rvm/scripts/rvm` in all your open shell windows, in rare cases you need to reopen all shell windows. 启动rvm\n$ source /Users/zhushuyan/.rvm/scripts/rvm # zhushuyan @ bogon in /Volumes/E/JYW/zsy619.github.io/blog on git:master x [7:12:56] $ rvm use ruby-2.7.0 Using /Users/zhushuyan/.rvm/gems/ruby-2.7.0 使用ruby\n解决：ERROR: Failed to build gem native extension Try to switch ruby to homebrew version. brew install ruby brew link --overwrite ruby If you need to have ruby first in your PATH run: echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/ruby/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile For compilers to find ruby you may need to set: export LDFLAGS=\u0026#34;-L/usr/local/opt/ruby/lib\u0026#34; export CPPFLAGS=\u0026#34;-I/usr/local/opt/ruby/include\u0026#34; For pkg-config to find ruby you may need to set: export PKG_CONFIG_PATH=\u0026#34;/usr/local/opt/ruby/lib/pkgconfig\u0026#34; 安装成功 $ sudo gem install cocoapods Fetching thread_safe-0.3.6.gem Fetching tzinfo-1.2.7.gem Fetching activesupport-4.2.11.3.gem Fetching fuzzy_match-2.0.4.gem Fetching concurrent-ruby-1.1.7.gem Fetching i18n-0.9.5.gem Fetching nap-1.1.0.gem Fetching httpclient-2.8.3.gem Fetching ffi-1.13.1.gem Fetching algoliasearch-1.27.4.gem Fetching ethon-0.12.0.gem Fetching typhoeus-1.4.0.gem Fetching netrc-0.11.0.gem Fetching cocoapods-core-1.9.3.gem Fetching claide-1.0.3.gem Fetching cocoapods-deintegrate-1.0.4.gem Fetching cocoapods-downloader-1.4.0.gem Fetching cocoapods-plugins-1.0.0.gem Fetching cocoapods-search-1.0.0.gem Fetching cocoapods-stats-1.1.0.gem Fetching cocoapods-trunk-1.5.0.gem Fetching cocoapods-try-1.2.0.gem Fetching molinillo-0.6.6.gem Fetching atomos-0.1.3.gem Fetching CFPropertyList-3.0.2.gem Fetching colored2-3.1.2.gem Fetching nanaimo-0.3.0.gem Fetching xcodeproj-1.18.0.gem Fetching escape-0.0.4.gem Fetching fourflusher-2.3.1.gem Fetching gh_inspector-1.1.3.gem Fetching ruby-macho-1.4.0.gem Fetching cocoapods-1.9.3.gem Successfully installed concurrent-ruby-1.1.7 Successfully installed i18n-0.9.5 Successfully installed thread_safe-0.3.6 Successfully installed tzinfo-1.2.7 Successfully installed activesupport-4.2.11.3 Successfully installed nap-1.1.0 Successfully installed fuzzy_match-2.0.4 Successfully installed httpclient-2.8.3 Successfully installed algoliasearch-1.27.4 Building native extensions. This could take a while... Successfully installed ffi-1.13.1 Successfully installed ethon-0.12.0 Successfully installed typhoeus-1.4.0 Successfully installed netrc-0.11.0 Successfully installed cocoapods-core-1.9.3 Successfully installed claide-1.0.3 Successfully installed cocoapods-deintegrate-1.0.4 Successfully installed cocoapods-downloader-1.4.0 Successfully installed cocoapods-plugins-1.0.0 Successfully installed cocoapods-search-1.0.0 Successfully installed cocoapods-stats-1.1.0 Successfully installed cocoapods-trunk-1.5.0 Successfully installed cocoapods-try-1.2.0 Successfully installed molinillo-0.6.6 Successfully installed atomos-0.1.3 Successfully installed CFPropertyList-3.0.2 Successfully installed colored2-3.1.2 Successfully installed nanaimo-0.3.0 Successfully installed xcodeproj-1.18.0 Successfully installed escape-0.0.4 Successfully installed fourflusher-2.3.1 Successfully installed gh_inspector-1.1.3 Successfully installed ruby-macho-1.4.0 Successfully installed cocoapods-1.9.3 Parsing documentation for concurrent-ruby-1.1.7 Installing ri documentation for concurrent-ruby-1.1.7 Parsing documentation for i18n-0.9.5 Installing ri documentation for i18n-0.9.5 Parsing documentation for thread_safe-0.3.6 Installing ri documentation for thread_safe-0.3.6 Parsing documentation for tzinfo-1.2.7 Installing ri documentation for tzinfo-1.2.7 Parsing documentation for activesupport-4.2.11.3 Installing ri documentation for activesupport-4.2.11.3 Parsing documentation for nap-1.1.0 Installing ri documentation for nap-1.1.0 Parsing documentation for fuzzy_match-2.0.4 Installing ri documentation for fuzzy_match-2.0.4 Parsing documentation for httpclient-2.8.3 Installing ri documentation for httpclient-2.8.3 Parsing documentation for algoliasearch-1.27.4 Installing ri documentation for algoliasearch-1.27.4 Parsing documentation for ffi-1.13.1 Installing ri documentation for ffi-1.13.1 Parsing documentation for ethon-0.12.0 Installing ri documentation for ethon-0.12.0 Parsing documentation for typhoeus-1.4.0 Installing ri documentation for typhoeus-1.4.0 Parsing documentation for netrc-0.11.0 Installing ri documentation for netrc-0.11.0 Parsing documentation for cocoapods-core-1.9.3 Installing ri documentation for cocoapods-core-1.9.3 Parsing documentation for claide-1.0.3 Installing ri documentation for claide-1.0.3 Parsing documentation for cocoapods-deintegrate-1.0.4 Installing ri documentation for cocoapods-deintegrate-1.0.4 Parsing documentation for cocoapods-downloader-1.4.0 Installing ri documentation for cocoapods-downloader-1.4.0 Parsing documentation for cocoapods-plugins-1.0.0 Installing ri documentation for cocoapods-plugins-1.0.0 Parsing documentation for cocoapods-search-1.0.0 Installing ri documentation for cocoapods-search-1.0.0 Parsing documentation for cocoapods-stats-1.1.0 Installing ri documentation for cocoapods-stats-1.1.0 Parsing documentation for cocoapods-trunk-1.5.0 Installing ri documentation for cocoapods-trunk-1.5.0 Parsing documentation for cocoapods-try-1.2.0 Installing ri documentation for cocoapods-try-1.2.0 Parsing documentation for molinillo-0.6.6 Installing ri documentation for molinillo-0.6.6 Parsing documentation for atomos-0.1.3 Installing ri documentation for atomos-0.1.3 Parsing documentation for CFPropertyList-3.0.2 Installing ri documentation for CFPropertyList-3.0.2 Parsing documentation for colored2-3.1.2 Installing ri documentation for colored2-3.1.2 Parsing documentation for nanaimo-0.3.0 Installing ri documentation for nanaimo-0.3.0 Parsing documentation for xcodeproj-1.18.0 Installing ri documentation for xcodeproj-1.18.0 Parsing documentation for escape-0.0.4 Installing ri documentation for escape-0.0.4 Parsing documentation for fourflusher-2.3.1 Installing ri documentation for fourflusher-2.3.1 Parsing documentation for gh_inspector-1.1.3 Installing ri documentation for gh_inspector-1.1.3 Parsing documentation for ruby-macho-1.4.0 Installing ri documentation for ruby-macho-1.4.0 Parsing documentation for cocoapods-1.9.3 Installing ri documentation for cocoapods-1.9.3 Done installing documentation for concurrent-ruby, i18n, thread_safe, tzinfo, activesupport, nap, fuzzy_match, httpclient, algoliasearch, ffi, ethon, typhoeus, netrc, cocoapods-core, claide, cocoapods-deintegrate, cocoapods-downloader, cocoapods-plugins, cocoapods-search, cocoapods-stats, cocoapods-trunk, cocoapods-try, molinillo, atomos, CFPropertyList, colored2, nanaimo, xcodeproj, escape, fourflusher, gh_inspector, ruby-macho, cocoapods after 24 seconds 33 gems installed ","description":"安装sudo gem install cocoapods 1 更改源 终端执行命令：\ngem sources --add \u0026lt;https://gems."},{"id":131,"href":"/know/git-stats%E5%AE%89%E8%A3%85/","title":"Git Stats安装","parent":"知识点","content":" git-stats Local git statistics including GitHub-like contributions calendars.\nremark：https://www.npmjs.com/package/git-stats#what-about-the-github-contributions-calendar\n$ git-stats --help Usage: git-stats [options] Local git statistics including GitHub-like contributions calendars. Options: -r, --raw Outputs a dump of the raw JSON data. -g, --global-activity Shows global activity calendar in the current repository. -d, --data \u0026lt;path\u0026gt; Sets a custom data store file. -l, --light Enables the light theme. -n, --disable-ansi Forces the tool not to use ANSI styles. -a, --authors Shows a pie chart with the author related contributions in the current repository. -u, --until \u0026lt;date\u0026gt; Optional end date. -s, --since \u0026lt;date\u0026gt; Optional start date. --record \u0026lt;data\u0026gt; Records a new commit. Don\u0026#39;t use this unless you are a mad scientist. If you are a developer just use this option as part of the module. -h, --help Displays this help. -v, --version Displays version information. Examples: $ git-stats # Default behavior (stats in the last year) $ git-stats -l # Light mode $ git-stats -s \u0026#39;1 January 2012\u0026#39; # All the commits from 1 January 2012 to now $ git-stats -s \u0026#39;1 January 2012\u0026#39; -u \u0026#39;31 December 2012\u0026#39; # All the commits from 2012 Your commit history is kept in ~/.git-stats by default. You can create ~/.git-stats-config.js to specify different defaults. Documentation can be found at https://github.com/IonicaBizau/git-stats. usage ","description":"git-stats Local git statistics including GitHub-like contributions calendars.\nremark：https://www.npmjs.com/package/git-stats#what-about-the-github-contributions-calendar"},{"id":132,"href":"/know/mac%E4%B8%8B%E5%AE%89%E8%A3%85yarn%E5%8F%AF%E7%9C%9F%E9%9A%BE%E5%91%80/","title":"Mac下安装yarn可真难呀","parent":"知识点","content":" shell命令行安装 $ brew install yarn Updating Homebrew... Warning: You are using macOS 11.0. We do not provide support for this pre-release version. You will encounter build failures with some formulae. Please create pull requests instead of asking for help on Homebrew\u0026#39;s GitHub, Discourse, Twitter or IRC. You are responsible for resolving any issues you experience while you are running this pre-release version. ==\u0026gt; Downloading https://www.sqlite.org/2020/sqlite-autoconf-3330000.tar.gz Already downloaded: /Users/zhushuyan/Library/Caches/Homebrew/downloads/5e52b8b0330f34548b7eecfdac41259cbbf426fc52aba671aed35c19feebc11d--sqlite-autoconf-3330000.tar.gz ==\u0026gt; Downloading https://registry.npmjs.org/npm/-/npm-6.14.8.tgz Already downloaded: /Users/zhushuyan/Library/Caches/Homebrew/downloads/4a48120cdffaa95e1727d094049a3fc38ad57fee802218d430526e91d3b39e0d--npm-6.14.8.tgz ==\u0026gt; Downloading https://nodejs.org/dist/v14.11.0/node-v14.11.0.tar.gz Already downloaded: /Users/zhushuyan/Library/Caches/Homebrew/downloads/be4016d2d242d71f671e8dff9567d96677c9c67f17ddaa519b601be5b087d472--node-v14.11.0.tar.gz ==\u0026gt; Downloading https://yarnpkg.com/downloads/1.22.5/yarn-v1.22.5.tar.gz Already downloaded: /Users/zhushuyan/Library/Caches/Homebrew/downloads/b858a5ca4ade7c6cd0a5deeb77770019c86813d12fc8950d70af904e6ded8e17--yarn-v1.22.5.tar.gz ==\u0026gt; Installing dependencies for yarn: sqlite and node ==\u0026gt; Installing yarn dependency: sqlite ==\u0026gt; ./configure --prefix=/usr/local/Cellar/sqlite/3.33.0 --enable-dynamic-extensions --enable-readline --disable-editline --enable-session ==\u0026gt; make install ==\u0026gt; Caveats sqlite is keg-only, which means it was not symlinked into /usr/local, because macOS already provides this software and installing another version in parallel can cause all kinds of trouble. If you need to have sqlite first in your PATH run: echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/sqlite/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc For compilers to find sqlite you may need to set: export LDFLAGS=\u0026#34;-L/usr/local/opt/sqlite/lib\u0026#34; export CPPFLAGS=\u0026#34;-I/usr/local/opt/sqlite/include\u0026#34; For pkg-config to find sqlite you may need to set: export PKG_CONFIG_PATH=\u0026#34;/usr/local/opt/sqlite/lib/pkgconfig\u0026#34; ==\u0026gt; Summary 🍺 /usr/local/Cellar/sqlite/3.33.0: 11 files, 4MB, built in 1 minute 25 seconds ==\u0026gt; Installing yarn dependency: node ==\u0026gt; ./configure --prefix=/usr/local/Cellar/node/14.11.0 --without-npm --with-intl=system-icu ==\u0026gt; make install ==\u0026gt; node /private/tmp/node-20200922-43938-860pp9/node-v14.11.0/npm_bootstrap/bin/npm-cli.js install -ddd --global --prefix=/usr/local/Cellar/node/14.11.0/libexe ==\u0026gt; Caveats Bash completion has been installed to: /usr/local/etc/bash_completion.d ==\u0026gt; Summary 🍺 /usr/local/Cellar/node/14.11.0: 4,728 files, 62.8MB, built in 23 minutes 23 seconds ==\u0026gt; Installing yarn 🍺 /usr/local/Cellar/yarn/1.22.5: 14 files, 5MB, built in 3 seconds ==\u0026gt; Upgrading 1 dependent: vim 8.2.1300 -\u0026gt; 8.2.1700 ==\u0026gt; Upgrading vim 8.2.1300 -\u0026gt; 8.2.1700 ==\u0026gt; Downloading https://ftp.gnu.org/gnu/gettext/gettext-0.21.tar.xz ######################################################################## 100.0% ==\u0026gt; Downloading https://github.com/vim/vim/archive/v8.2.1700.tar.gz ==\u0026gt; Downloading from https://codeload.github.com/vim/vim/tar.gz/v8.2.1700 ######################################################################## 100.0% ==\u0026gt; Installing dependencies for vim: gettext ==\u0026gt; Installing vim dependency: gettext ==\u0026gt; ./configure --prefix=/usr/local/Cellar/gettext/0.21 --with-included-gettext gl_cv_func_ftello_works=yes --with-included-glib --with-included-libcroco --with ==\u0026gt; make ==\u0026gt; make install 🍺 /usr/local/Cellar/gettext/0.21: 1,953 files, 19.8MB, built in 10 minutes 27 seconds ==\u0026gt; Installing vim ==\u0026gt; ./configure --prefix=/usr/local --mandir=/usr/local/Cellar/vim/8.2.1700/share/man --enable-multibyte --with-tlib=ncurses --with-compiledby=Homebrew --enable ==\u0026gt; make ==\u0026gt; make install prefix=/usr/local/Cellar/vim/8.2.1700 STRIP=/usr/bin/true 🍺 /usr/local/Cellar/vim/8.2.1700: 1,952 files, 33.2MB, built in 1 minute 31 seconds Removing: /usr/local/Cellar/vim/8.2.1300... (1,923 files, 32.7MB) ==\u0026gt; Checking for dependents of upgraded formulae... ==\u0026gt; No broken dependents found! ==\u0026gt; Caveats ==\u0026gt; sqlite sqlite is keg-only, which means it was not symlinked into /usr/local, because macOS already provides this software and installing another version in parallel can cause all kinds of trouble. If you need to have sqlite first in your PATH run: echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/sqlite/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc For compilers to find sqlite you may need to set: export LDFLAGS=\u0026#34;-L/usr/local/opt/sqlite/lib\u0026#34; export CPPFLAGS=\u0026#34;-I/usr/local/opt/sqlite/include\u0026#34; For pkg-config to find sqlite you may need to set: export PKG_CONFIG_PATH=\u0026#34;/usr/local/opt/sqlite/lib/pkgconfig\u0026#34; ==\u0026gt; node Bash completion has been installed to: /usr/local/etc/bash_completion.d host文件配置 ## # Host Database # # localhost is used to configure the loopback interface # when the system is booting. Do not change this entry. ## 127.0.0.1\tlocalhost 255.255.255.255\tbroadcasthost ::1 localhost # Added by Docker Desktop # To allow the same kube context to work on the host and the container: 127.0.0.1 kubernetes.docker.internal # End of section 171.15.16.222 tx.1086sms.com 36.99.196.217 goproxy.cn 199.232.68.133 raw.githubusercontent.com 209.51.188.200 ftpmirror.gnu.org # 2001:470:142:5::200 ftpmirror.gnu.org 101.6.8.193 mirrors.tuna.tsinghua.edu.cn 140.82.113.10 codeload.github.com 52.216.177.243 github-production-release-asset-2e65be.s3.amazonaws.com # github.com 140.82.113.4 github.com 140.82.113.3 github.com 140.82.112.4 github.com 140.82.121.4 github.com 140.82.121.3 github.com 140.82.118.3 github.com 192.30.255.112 github.com 140.82.114.4 github.com # (美国弗吉尼亚州阿什本 github.com)\t203.208.39.99 google.com # (中国北京 google.com 电信) 54.169.195.247 api.github.com 13.250.94.254 api.github.com 13.250.168.23 api.github.com 203.208.39.99\tapi.github.com # flutter 183.60.83.19 storage.flutter-io.cn 104.18.156.100 storage.flutter-io.cn 202.120.58.155 dart-pub.mirrors.sjtug.sjtu.edu.cn 172.217.24.19 pub.dartlang.org # sqlite 45.33.6.223 www.sqlite.org 209.51.188.20 ftp.gnu.org 130.242.124.102 gmplib.org 151.101.110.133 deb.debian.org 151.101.78.133 deb.debian.org 151.101.230.133 deb.debian.org 128.93.193.15 isl.gforge.inria.fr 104.16.17.35 registry.npmjs.org 104.16.18.35 registry.npmjs.org 104.16.25.35 registry.npmjs.org 104.16.27.35 registry.npmjs.org 104.16.16.35 registry.npmjs.org 104.16.21.35 registry.npmjs.org 104.16.19.35 registry.npmjs.org 104.16.26.35 registry.npmjs.org 104.16.20.35 registry.npmjs.org 104.16.22.35 registry.npmjs.org 104.16.24.35 registry.npmjs.org 104.16.23.35 registry.npmjs.org 104.20.23.46 nodejs.org 104.20.22.46 nodejs.org 104.248.78.23 yarnpkg.com 165.227.12.111 yarnpkg.com 165.227.0.164 yarnpkg.com 138.68.244.143\tyarnpkg.com 167.172.221.254 yarnpkg.com 104.248.78.24 yarnpkg.com 167.172.215.127 yarnpkg.com 206.189.73.52 yarnpkg.com 157.230.35.153 yarnpkg.com 157.230.37.202 yarnpkg.com 128.199.185.38 yarnpkg.com 206.189.89.118 yarnpkg.com 178.128.17.49 yarnpkg.com 134.209.106.40 classic.yarnpkg.com 178.128.17.49 classic.yarnpkg.com 157.230.35.153 classic.yarnpkg.com 157.230.45.115 classic.yarnpkg.com 128.199.185.38 classic.yarnpkg.com 157.230.37.202 classic.yarnpkg.com 157.230.43.191 classic.yarnpkg.com 206.189.89.118 classic.yarnpkg.com ","description":"shell命令行安装 $ brew install yarn Updating Homebrew... Warning: You are using macOS 11."},{"id":133,"href":"/golang/go%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99%E6%B1%87%E6%80%BB/","title":"Go学习网站汇总","parent":"golang","content":" 基础知识 GolangPrograms：https://www.golangprograms.com/golang-package-examples.html\nThe Top 3,364 Golang Open Source Projects：https://awesomeopensource.com/projects/golang\n","description":"基础知识 GolangPrograms：https://www.golangprograms.com/golang-package-examples.html\nThe Top 3,364 Golang Open Source Projects：https://awesomeopensource.com/projects/golang"},{"id":134,"href":"/know/JWT%E5%92%8COauth2%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB/","title":"JWT和Oauth2的区别和联系","parent":"知识点","content":" JWT和Oauth2的区别和联系 Oauth2 是一种安全的授权框架，提供了一套详细的授权机制。用户或应用可以通过公开的或私有的设置，授权第三方应用访问特定资源。它详细描述了系统中不同角色、用户、服务前端应用（比如API），以及客户端（比如网站或移动App）之间怎么实现相互认证。\nOauth2定义了一组想当复杂的规范。涉及到：Roles角色、Client Types客户端类型、Client Profile客户端描述、Authorization Grants认证授权、Endpoints终端等。\nJWT 提供了一种用于发布接入令牌（Access Token), 并对发布的签名接入令牌进行验证的方法。 令牌（Token）本身包含了一系列声明，应用程序可以根据这些声明限制用户对资源的访问。\nJWT是一种安全标准。基本思路就是用户提供用户名和密码给认证服务器，服务器验证用户提交信息信息的合法性；如果验证成功，会产生并返回一个Token（令牌），用户可以使用这个token访问服务器上受保护的资源。\n一个token包含三部分：header、claims、signature #### header: 头部分简单声明了类型(JWT)以及产生签名所使用的算法。\n{ \u0026#34;alg\u0026#34;: \u0026#34;AES256\u0026#34;, \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } claims: 声明 声明部分是整个token的核心，表示要发送的用户详细信息。有些情况下，我们很可能要在一个服务器上实现认证，然后访问另一台服务器上的资源；或者，通过单独的接口来生成token，token被保存在应用程序客户端（比如浏览器）使用。 以下一个简单的声明例子：\n{ \u0026#34;sub\u0026#34;: \u0026#34;1234567890\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;admin\u0026#34;: true } Signature：签名 名的目的是为了保证上边两部分信息不被篡改。如果尝试使用Bas64对解码后的token进行修改，签名信息就会失效。一般使用一个私钥（private key）通过特定算法对Header和Claims进行混淆产生签名信息，所以只有原始的token才能于签名信息匹配。\n这里有一个重要的实现细节。只有获取了私钥的应用程序（比如服务器端应用）才能完全认证token包含声明信息的合法性。所以，永远不要把私钥信息放在客户端（比如浏览器）。 JWT和Oauth2的应用场景的区别 jwt应用场景：无状态的分布式API JWT的主要优势在于使用无状态、可扩展的方式处理应用中的用户会话。服务端可以通过内嵌的声明信息，很容易地获取用户的会话信息，而不需要去访问用户或会话的数据库。在一个分布式的面向服务的框架中，这一点非常有用。\n但是，如果系统中需要使用黑名单实现长期有效的token刷新机制，这种无状态的优势就不明显了。\n优势 快速开发 不需要cookie JSON在移动端的广泛应用 不依赖于社交登录 相对简单的概念理解 限制 Token有长度限制 Token不能撤销 需要token有失效时间限制(exp) Oauth2应用场景 外包认证服务器 上边已经讨论过，如果不介意API的使用依赖于外部的第三方认证提供者，你可以简单地把认证工作留给认证服务商去做。\n也就是常见的，去认证服务商（比如facebook）那里注册你的应用，然后设置需要访问的用户信息，比如电子邮箱、姓名等。当用户访问站点的注册页面时，会看到连接到第三方提供商的入口。用户点击以后被重定向到对应的认证服务商网站，获得用户的授权后就可以访问到需要的信息，然后重定向回来。\n优势 快速开发 实施代码量小 维护工作减少 大型企业解决方案 如果设计的API要被不同的App使用，并且每个App使用的方式也不一样，使用OAuth2是个不错的选择。\n考虑到工作量，可能需要单独的团队，针对各种应用开发完善、灵活的安全策略。当然需要的工作量也比较大！这一点，OAuth2的作者也指出过：\n优势 灵活的实现方式 可以和JWT同时使用 可针对不同应用扩展 总结 总而言之，Oauth2和jwt是完全不同的两种东西，一个是授权认证的框架，另一种则是认证验证的方式方法（轻量级概念）。OAuth2不像JWT一样是一个严格的标准协议，因此在实施过程中更容易出错。尽管有很多现有的库，但是每个库的成熟度也不尽相同，同样很容易引入各种错误。在常用的库中也很容易发现一些安全漏洞。\n注意 两种方案都需要SSL安全保护，也就是对要传输的数据进行加密编码。安全地传输用户提供的私密信息，在任何一个安全的系统里都是必要的。否则任何人都可以通过侵入私人wifi，在用户登录的时候窃取用户的用户名和密码等信息。\n参考 作者：默云客 链接：https://www.jianshu.com/p/1870f456b334 来源：简书\nJWT官网：https://jwt.io\n","description":"JWT和Oauth2的区别和联系 Oauth2 是一种安全的授权框架，提供了一套详细的授权机制。用户或应用可以通过公开的或私有的设置，授权第三方应用访问特定资源。它详细描述了系统中不同角色、用户、服务前端应用（比如API），以及客户端（比如网站或移动App）之间怎么实现相互认证。\nOauth2定义了一组想当复杂的规范。涉及到：Roles角色、Client Types客户端类型、Client Profile客户端描述、Authorization Grants认证授权、Endpoints终端等。\nJWT 提供了一种用于发布接入令牌（Access Token), 并对发布的签名接入令牌进行验证的方法。 令牌（Token）本身包含了一系列声明，应用程序可以根据这些声明限制用户对资源的访问。"},{"id":135,"href":"/tags/%E7%9F%A5%E8%AF%86%E7%82%B9/","title":"知识点","parent":"Tags","content":"","description":""},{"id":136,"href":"/categories/%E7%9F%A5%E8%AF%86%E7%82%B9/","title":"知识点","parent":"Categories","content":"","description":""},{"id":137,"href":"/tags/%E8%AE%A4%E8%AF%81/","title":"认证","parent":"Tags","content":"","description":""},{"id":138,"href":"/csapp/20200921%E5%88%B020200927%E6%97%A5%E8%AF%BB%E4%B9%A6%E6%B1%87%E6%80%BB--%E7%AC%AC%E4%BA%8C%E5%91%A8/","title":"第二周20200921到20200927日读书汇总","parent":"读书笔记","content":" 整数表示 用位来编码整数\n- 函数：二进制转补码、二进制转无符号数、无符号数转二进制、无符号转补码、补码转二进制、补码转无符号数 - 常数：最小补码值、最大补码值、最大无符号数 - 操作：补码加法、无符号数加法、补码乘法、无符号数乘法、补码取反、无符号数取反 整型数据类型 32位与64位机器取值范围不同 大多数64位机器使用8个字节表示，比32位机器上使用4个字节表示取值范围大 建议安装64位的操作系统 不同语言对有符号与无符号支持也不同，如c支持有符号与无符号数。而java只支持有符号数。\n无符号数编码 采用向量表示（定义）法 最小值0，最大值二的N次方减一 无符号数编码具有唯一性 双映射，了解反函数\n补码编码 有符号数采用补码进行表示 负权：最高位表示，1表示负、0表示正 -\u0026gt; 所以负数比正数大1 通过补码，可以了解有符号数存储规则 补码编码的唯一性，双射 补码范围不对称：|TMin| = |TMax| + 1 UMax = 2TMax + 1 long类型：不同机器有不同的取值范围 反码、原码\n有符号数与无符号数转换 以后要加强阅读 扩展一个数字的位表示 无符号数的零扩展 补码数的符号扩展\n截断数字 截断无符号数\n整数运算 无符号加法 无限精度的运算：lisp语言 固定精度的运算：溢出 补码加法 正溢出 负溢出 补码的非 要深入了解概念 无符号乘法 要深入了解概念 补码乘法 要深入了解概念 浮点数 二进制小数 充分理解计算机小数表示存储 IEEE浮点表示法 还需精读（概念、参数含义） 格式化的值 非格式化的值 特殊值 舍入 浮点溢出 精彩案例：浮点溢出的高昂代价 火箭发射失败 原因：类型间转换失误 ","description":"整数表示 用位来编码整数\n- 函数：二进制转补码、二进制转无符号数、无符号数转二进制、无符号转补码、补码转二进制、补码转无符号数 - 常数：最小补码值、最大补码值、最大无符号数 - 操作：补码加法、无符号数加法、补码乘法、无符号数乘法、补码取反、无符号数取反 整型数据类型 32位与64位机器取值范围不同 大多数64位机器使用8个字节表示，比32位机器上使用4个字节表示取值范围大 建议安装64位的操作系统 不同语言对有符号与无符号支持也不同，如c支持有符号与无符号数。而java只支持有符号数。"},{"id":139,"href":"/csapp/20200914%E5%88%B020200920%E6%97%A5%E8%AF%BB%E4%B9%A6%E6%B1%87%E6%80%BB--%E7%AC%AC%E4%B8%80%E5%91%A8/","title":"第一周20200914到20200920日读书汇总","parent":"读书笔记","content":" 第一章 计算机系统漫游 基本概念： 信息就是位+上下文：字符编码 程序翻译的不同阶段：预处理阶段、编译阶段、汇编阶段、链接阶段 系统硬件的组成：总线、I/O设备、主存、处理器 高速缓存：了解是在cpu上进行设置的 进程、线程、虚拟内存、文件 系统间的通信方式：网络 重要章节：amdahl定律（阿姆达尔定律） 核心要了解公式各参数含义 系统性能提升，主要决定是并行处理的地方 通过本定律，了解程序优化的重点方向 在并行计算中用多处理器的应用加速受限于程序所需的串行时间百分比。譬如说，你的程序50%是串行的，其他一半可以并行，那么，最大的加速比就是2。不管你用多少处理器并行，这个加速比不可能提高。在这种情况下，改进串行算法可能比多核处理器并行更有效。\n阿姆达尔定律的问题出在它的前提过于理想化。因为并行算法通常能处理比串行算法更大规模的问题，即使算法仍然存在着串行部分，但由于问题规模的不断扩大，往往会导致算法中串行部分所占比例的持续减少。\n并发： 线程级并发 指令集并行 单指令、多数据并行 第二章 信息表示与处理 本章最大收获：充分理解不同数据类型存储方式，在不同系统存储方式也不同；了解存储结构，在实际应用中，要避免溢出问题。 计算机语言是0、1，如何让编程人员看懂，信息的表示就之至关重要，比如对虚拟内存进行编码标识。 信息存储：8进制、16进制 活动汇总地址 【第 1 周】CSAPP 共读心得体会 https://talkgo.org/t/topic/942/48\n","description":"第一章 计算机系统漫游 基本概念： 信息就是位+上下文：字符编码 程序翻译的不同阶段：预处理阶段、编译阶段、汇编阶段、链接阶段 系统硬件的组成：总线、I/O设备、主存、处理器 高速缓存：了解是在cpu上进行设置的 进程、线程、虚拟内存、文件 系统间的通信方式：网络 重要章节：amdahl定律（阿姆达尔定律） 核心要了解公式各参数含义 系统性能提升，主要决定是并行处理的地方 通过本定律，了解程序优化的重点方向 在并行计算中用多处理器的应用加速受限于程序所需的串行时间百分比。譬如说，你的程序50%是串行的，其他一半可以并行，那么，最大的加速比就是2。不管你用多少处理器并行，这个加速比不可能提高。在这种情况下，改进串行算法可能比多核处理器并行更有效。"},{"id":140,"href":"/docker/install_mysql/","title":"Docker 安装 MySQL","parent":"容器","content":"MySQL 是世界上最受欢迎的开源数据库。凭借其可靠性、易用性和性能，MySQL 已成为 Web 应用程序的数据库优先选择。\n查看可用的 MySQL 版本 访问 MySQL 镜像库地址：https://hub.docker.com/_/mysql?tab=tags。\n可以通过 Sort by 查看其他版本的 MySQL，默认是最新版本 mysql:latest。\n还可以用 docker search mysql 命令来查看可用版本：\n$ docker search mysql NAME DESCRIPTION STARS OFFICIAL AUTOMATED mysql MySQL is a widely used, open-source relation… 9954 [OK] mariadb MariaDB is a community-developed fork of MyS… 3642 [OK] mysql/mysql-server Optimized MySQL Server Docker images. Create… 725 [OK] percona Percona Server is a fork of the MySQL relati… 508 [OK] centos/mysql-57-centos7 MySQL 5.7 SQL database server 83 mysql/mysql-cluster Experimental MySQL Cluster Docker images. Cr… 75 centurylink/mysql Image containing mysql. Optimized to be link… 61 [OK] bitnami/mysql Bitnami MySQL Docker Image 44 [OK] deitch/mysql-backup REPLACED! Please use http://hub.docker.com/r… 41 [OK] tutum/mysql Base docker image to run a MySQL database se… 35 prom/mysqld-exporter 31 [OK] schickling/mysql-backup-s3 Backup MySQL to S3 (supports periodic backup… 30 [OK] databack/mysql-backup Back up mysql databases to... anywhere! 30 linuxserver/mysql A Mysql container, brought to you by LinuxSe… 25 centos/mysql-56-centos7 MySQL 5.6 SQL database server 20 circleci/mysql MySQL is a widely used, open-source relation… 19 mysql/mysql-router MySQL Router provides transparent routing be… 16 arey/mysql-client Run a MySQL client from a docker container 14 [OK] fradelg/mysql-cron-backup MySQL/MariaDB database backup using cron tas… 8 [OK] openshift/mysql-55-centos7 DEPRECATED: A Centos7 based MySQL v5.5 image… 6 devilbox/mysql Retagged MySQL, MariaDB and PerconaDB offici… 3 ansibleplaybookbundle/mysql-apb An APB which deploys RHSCL MySQL 2 [OK] jelastic/mysql An image of the MySQL database server mainta… 1 widdpim/mysql-client Dockerized MySQL Client (5.7) including Curl… 1 [OK] monasca/mysql-init A minimal decoupled init container for mysql 0 拉取 MySQL 镜像 $ docker pull mysql:latest latest: Pulling from library/mysql d121f8d1c412: Already exists f3cebc0b4691: Pull complete 1862755a0b37: Pull complete 489b44f3dbb4: Pull complete 690874f836db: Pull complete baa8be383ffb: Pull complete 55356608b4ac: Pull complete dd35ceccb6eb: Pull complete 429b35712b19: Pull complete 162d8291095c: Pull complete 5e500ef7181b: Pull complete af7528e958b6: Pull complete Digest: sha256:e1bfe11693ed2052cb3b4e5fa356c65381129e87e38551c6cd6ec532ebe0e808 Status: Downloaded newer image for mysql:latest docker.io/library/mysql:latest 查看本地镜像 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE mongo latest 923803327a36 8 hours ago 493MB redis latest 84c5f6e03bf0 35 hours ago 104MB mysql latest e1d7dc9731da 47 hours ago 544MB 运行容器 $ docker run -itd --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql 9dd939121708cf20d98c7596c63190cc27be3ac7c7f6b902cb9beb97aa7b33bd 安装成功 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9dd939121708 mysql \u0026#34;docker-entrypoint.s…\u0026#34; 24 seconds ago Up 23 seconds 0.0.0.0:3306-\u0026gt;3306/tcp, 33060/tcp mysql a9386073261a redis \u0026#34;docker-entrypoint.s…\u0026#34; 37 minutes ago Up 37 minutes 0.0.0.0:6379-\u0026gt;6379/tcp redis c36ca6add3c1 mongo \u0026#34;docker-entrypoint.s…\u0026#34; 2 hours ago Up 2 hours 0.0.0.0:22017-\u0026gt;22017/tcp, 27017/tcp mongo 通过 root 和密码 123456 访问 MySQL 服务。\n$ docker exec -it mysql /bin/bash root@9dd939121708:/# mysql ERROR 1045 (28000): Access denied for user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; (using password: NO) root@9dd939121708:/# mysql -h localhost -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 9 Server version: 8.0.21 MySQL Community Server - GPL Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.01 sec) mysql\u0026gt; ","description":"MySQL 是世界上最受欢迎的开源数据库。凭借其可靠性、易用性和性能，MySQL 已成为 Web 应用程序的数据库优先选择。\n查看可用的 MySQL 版本 访问 MySQL 镜像库地址：https://hub."},{"id":141,"href":"/tags/mysql/","title":"Mysql","parent":"Tags","content":"","description":""},{"id":142,"href":"/docker/install_mongo/","title":"Docker 安装 MongoDB","parent":"容器","content":"MongoDB 是一个免费的开源跨平台面向文档的 NoSQL 数据库程序。\n查看可用的 MongoDB 版本 访问 MongoDB 镜像库地址： https://hub.docker.com/_/mongo?tab=tags\u0026page=1。\n可以通过 Sort by 查看其他版本的 MongoDB，默认是最新版本 mongo:latest。\n也可以在下拉列表中找到其他你想要的版本：\n可以用 docker search mongo 命令来查看可用版本：\n$ docker search mongo NAME DESCRIPTION STARS OFFICIAL AUTOMATED mongo MongoDB document databases provide high avai… 7160 [OK] mongo-express Web-based MongoDB admin interface, written w… 768 [OK] tutum/mongodb MongoDB Docker image – listens in port 27017… 229 [OK] bitnami/mongodb Bitnami MongoDB Docker Image 126 [OK] mongoclient/mongoclient Official docker image for Mongoclient, featu… 89 [OK] mongooseim/mongooseim Small docker image for MongooseIM - robust a… 19 frodenas/mongodb A Docker Image for MongoDB 18 [OK] cvallance/mongo-k8s-sidecar Kubernetes side car to setup and maintain a … 17 [OK] arm64v8/mongo MongoDB document databases provide high avai… 9 centos/mongodb-32-centos7 MongoDB NoSQL database server 8 circleci/mongo CircleCI images for MongoDB 8 [OK] webhippie/mongodb Docker images for MongoDB 7 [OK] centos/mongodb-36-centos7 MongoDB NoSQL database server 6 istepanov/mongodump Docker image with mongodump running as a cro… 6 [OK] centos/mongodb-26-centos7 MongoDB NoSQL database server 5 neowaylabs/mongodb-mms-agent This Docker image with MongoDB Monitoring Ag… 4 [OK] eses/mongodb_exporter mongodb exporter for prometheus 4 [OK] centos/mongodb-34-centos7 MongoDB NoSQL database server 3 andreasleicher/mongo-azure-backup a docker container to backup a mongodb using… 2 [OK] openshift/mongodb-24-centos7 DEPRECATED: A Centos7 based MongoDB v2.4 ima… 1 ansibleplaybookbundle/mongodb-apb An APB to deploy MongoDB. 1 [OK] ekesken/mongo docker image for mongo that is configurable … 1 [OK] martel/mongo-replica-ctrl A dockerized controller for a Mongo db repli… 0 [OK] phenompeople/mongodb MongoDB is an open-source, document databas… 0 [OK] targetprocess/mongodb_exporter MongoDB exporter for prometheus 0 [OK] 取最新版的 MongoDB 镜像 $ docker pull mongo:latest latest: Pulling from library/mongo f08d8e2a3ba1: Pull complete 3baa9cb2483b: Pull complete 94e5ff4c0b15: Pull complete 1860925334f9: Pull complete 9d42806c06e6: Pull complete 31a9fd218257: Pull complete 5bd6e3f73ab9: Pull complete f6ae7a64936b: Pull complete 80fde2cb25c5: Pull complete 80dd04855bec: Pull complete 38c0e96de174: Extracting 58.49MB/142.5MB b7256055e1ef: Download complete 23bef11da1da: Download complete $ docker pull mongo:latest latest: Pulling from library/mongo f08d8e2a3ba1: Pull complete 3baa9cb2483b: Pull complete 94e5ff4c0b15: Pull complete 1860925334f9: Pull complete 9d42806c06e6: Pull complete 31a9fd218257: Pull complete 5bd6e3f73ab9: Pull complete f6ae7a64936b: Pull complete 80fde2cb25c5: Pull complete 80dd04855bec: Pull complete 38c0e96de174: Pull complete b7256055e1ef: Pull complete 23bef11da1da: Pull complete Digest: sha256:f8dcfaa1d5eab1fec5567ef4e7dedab97b9e41876222fba9c0588cdff312fdf8 Status: Downloaded newer image for mongo:latest docker.io/library/mongo:latest 查看本地镜像 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE mongo latest 923803327a36 5 hours ago 493MB mysql latest 3646af3dc14a 7 days ago 544MB redis latest 41de2cc0b30e 10 days ago 104MB 已经安装了最新版本（latest）的 mongo 镜像。\n运行容器 $ docker run -itd --name mongo -p 22017:22017 mongo --auth 9128b8be7ad068ade8bd585abd244634dd16f61163c2f3780cf0cfabcee13ea0 参数说明：\n-p 27017:27017 ：映射容器服务的 27017 端口到宿主机的 27017 端口。外部可以直接通过 宿主机 ip:27017 访问到 mongo 的服务。\n\u0026ndash;auth：需要密码才能访问容器服务。\n安装验证 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9128b8be7ad0 mongo \u0026#34;docker-entrypoint.s…\u0026#34; About a minute ago Up About a minute 0.0.0.0:22017-\u0026gt;22017/tcp, 27017/tcp mongo 使用以下命令添加用户和设置密码，并且尝试连接。\n$ docker exec -it mongo mongo admin # 创建一个名为 admin，密码为 123456 的用户。 \u0026gt; db.createUser({ user:\u0026#39;admin\u0026#39;,pwd:\u0026#39;123456\u0026#39;,roles:[ { role:\u0026#39;userAdminAnyDatabase\u0026#39;, db: \u0026#39;admin\u0026#39;}]}); # 尝试使用上面创建的用户信息进行连接。 \u0026gt; db.auth(\u0026#39;admin\u0026#39;, \u0026#39;123456\u0026#39;) $ docker exec -it mongo mongo admin MongoDB shell version v4.4.1 connecting to: mongodb://127.0.0.1:27017/admin?compressors=disabled\u0026amp;gssapiServiceName=mongodb Implicit session: session { \u0026#34;id\u0026#34; : UUID(\u0026#34;cb7e2d23-92ce-40d2-b775-4b5e1378ecff\u0026#34;) } MongoDB server version: 4.4.1 Welcome to the MongoDB shell. For interactive help, type \u0026#34;help\u0026#34;. For more comprehensive documentation, see https://docs.mongodb.com/ Questions? Try the MongoDB Developer Community Forums https://community.mongodb.com \u0026gt; \u0026gt; db.createUser({user:\u0026#39;admin\u0026#39;,pwd:\u0026#39;123456\u0026#39;,roles:[{role:\u0026#39;userAdminAnyDatabase\u0026#39;,db:\u0026#39;admin\u0026#39;}]}); Successfully added user: { \u0026#34;user\u0026#34; : \u0026#34;admin\u0026#34;, \u0026#34;roles\u0026#34; : [ { \u0026#34;role\u0026#34; : \u0026#34;userAdminAnyDatabase\u0026#34;, \u0026#34;db\u0026#34; : \u0026#34;admin\u0026#34; } ] } \u0026gt; db.auth(\u0026#39;admin\u0026#39;,\u0026#39;123456\u0026#39;) 1 ","description":"MongoDB 是一个免费的开源跨平台面向文档的 NoSQL 数据库程序。\n查看可用的 MongoDB 版本 访问 MongoDB 镜像库地址： https://hub."},{"id":143,"href":"/tags/mongo/","title":"Mongo","parent":"Tags","content":"","description":""},{"id":144,"href":"/docker/install_redis/","title":"Docker 安装 Redis","parent":"容器","content":"Redis 是一个开源的使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value 的 NoSQL 数据库，并提供多种语言的 API。\n查看可用的 Redis 版本 访问 Redis 镜像库地址： https://hub.docker.com/_/redis?tab=tags。\n可以通过 Sort by 查看其他版本的 Redis，默认是最新版本 redis:latest。\n可以在下拉列表中找到其他你想要的版本：\n可以用 docker search redis 命令来查看可用版本：\n$ docker search redis NAME DESCRIPTION STARS OFFICIAL AUTOMATED redis Redis is an open source key-value store that… 8564 [OK] bitnami/redis Bitnami Redis Docker Image 161 [OK] sameersbn/redis 81 [OK] grokzen/redis-cluster Redis cluster 3.0, 3.2, 4.0, 5.0, 6.0 70 rediscommander/redis-commander Alpine image for redis-commander - Redis man… 47 [OK] kubeguide/redis-master redis-master with \u0026#34;Hello World!\u0026#34; 33 redislabs/redis Clustered in-memory database engine compatib… 26 redislabs/redisearch Redis With the RedisSearch module pre-loaded… 24 oliver006/redis_exporter Prometheus Exporter for Redis Metrics. Supp… 22 arm32v7/redis Redis is an open source key-value store that… 21 redislabs/rejson RedisJSON - Enhanced JSON data type processi… 18 bitnami/redis-sentinel Bitnami Docker Image for Redis Sentinel 16 [OK] redislabs/redisinsight RedisInsight - The GUI for Redis 13 webhippie/redis Docker images for Redis 12 [OK] redislabs/redisgraph A graph database module for Redis 11 [OK] s7anley/redis-sentinel-docker Redis Sentinel 10 [OK] arm64v8/redis Redis is an open source key-value store that… 9 insready/redis-stat Docker image for the real-time Redis monitor… 9 [OK] redislabs/redismod An automated build of redismod - latest Redi… 7 [OK] centos/redis-32-centos7 Redis in-memory data structure store, used a… 5 circleci/redis CircleCI images for Redis 5 [OK] clearlinux/redis Redis key-value data structure server with t… 2 tiredofit/redis Redis Server w/ Zabbix monitoring and S6 Ove… 1 [OK] wodby/redis Redis container image with orchestration 1 [OK] xetamus/redis-resource forked redis-resource 0 [OK] 取最新版的 Redis 镜像 $ docker pull redis:latest latest: Pulling from library/redis d121f8d1c412: Pull complete 2f9874741855: Pull complete d92da09ebfd4: Pull complete bdfa64b72752: Pull complete e748e6f663b9: Pull complete eb1c8b66e2a1: Pull complete Digest: sha256:a05a8a1ebbef72690034a77451e6e83f4d899779190d1c00d8ab1a3a4fbbbd22 Status: Downloaded newer image for redis:latest docker.io/library/redis:latest 查看本地镜像 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE mongo latest 923803327a36 7 hours ago 493MB redis latest 84c5f6e03bf0 34 hours ago 104MB 运行容器 $ docker run -itd --name redis -p 6379:6379 redis a9386073261af70ca33346f13c8f7bcb11d365d72671855ea4f562f326c8589d 参数说明：\n-p 6379:6379：映射容器服务的 6379 端口到宿主机的 6379 端口。外部可以直接通过宿主机 ip:6379 访问到 Redis 的服务。\n安装成功 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a9386073261a redis \u0026#34;docker-entrypoint.s…\u0026#34; 52 seconds ago Up 50 seconds 0.0.0.0:6379-\u0026gt;6379/tcp redis c36ca6add3c1 mongo \u0026#34;docker-entrypoint.s…\u0026#34; 2 hours ago Up 2 hours 0.0.0.0:22017-\u0026gt;22017/tcp, 27017/tcp mongo 通过 redis-cli 连接测试使用 redis 服务。\n$ docker exec -it redis /bin/bash root@a9386073261a:/data# redis-cli 127.0.0.1:6379\u0026gt; ","description":"Redis 是一个开源的使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value 的 NoSQL 数据库，并提供多种语言的 API。\n查看可用的 Redis 版本 访问 Redis 镜像库地址： https://hub."},{"id":145,"href":"/tags/redis/","title":"Redis","parent":"Tags","content":"","description":""},{"id":146,"href":"/docker/install_hive/","title":"Docker 安装 Hive","parent":"容器","content":"\nHive 是什么 Hive 是一个数据仓库基础工具在 Hadoop 中用来处理结构化数据。它架构在 Hadoop 之上，总归为大数据，并使得查询和分析方便。\n最初，Hive 是由 Facebook 开发，后来由 Apache 软件基金会开发，并作为进一步将它作为名义下 Apache Hive 为一个开源项目。它用在好多不同的公司。例如，亚马逊使用它在 Amazon Elastic MapReduce。\nHive 不是 一个关系数据库 一个设计用于联机事务处理（OLTP） 实时查询和行级更新的语言 Hive 特点 它存储架构在一个数据库中并处理数据到 HDFS。 它是专为 OLAP 设计。 它提供 SQL 类型语言查询叫 HiveQL 或 HQL。 它是熟知，快速，可扩展和可扩展的。 Hive 架构 该组件图包含不同的单元。下表描述每个单元：\nHive 工作原理 下图描述了 Hive 和 Hadoop 之间的工作流程。 下表定义 Hive 和 Hadoop 框架的交互方式：\n执行过程就是：\nHiveQL 通过 CLI/web UI 或者 thrift 、 odbc 或 jdbc 接口的外部接口提交，经过 complier 编译器，运用 Metastore 中的元数据进行类型检测和语法分析，生成一个逻辑方案(logical plan), 然后通过简单的优化处理，产生一个以有向无环图 DAG 数据结构形式展现的 map-reduce 任务。 Hive 构建在 Hadoop 之上，Hive 的执行原理：\nHQL 中对查询语句的解释、优化、生成查询计划是由 Hive 完成的\n所有的数据都是存储在 Hadoop 中\n查询计划被转化为 MapReduce 任务，在 Hadoop 中执行（有些查询没有 MR 任务，如：select * from table）\nHadoop 和 Hive 都是用 UTF-8 编码的\n查询编译器(query complier), 用云存储中的元数据来生成执行计划，步骤如下：\n解析（parse）-anlr 解析其生成语法树 AST(hibernate 也是这个)：将 HQL 转化为抽象语法树 AST\n类型检查和语法分析(type checking and semantic analysis): 将抽象语法树转换此查询块(query block tree), 并将查询块转换成逻辑查询计划(logic plan Generator);\n优化(optimization): 重写查询计划(logical optimizer)–\u0026gt;将逻辑查询计划转成物理计划(physical plan generator)–\u0026gt;选择最佳的 join 策略(physical optimizer)\nHive 环境安装 注意：Hive 需要运行在 hadoop-master 节点才可以！\n","description":"Hive 是什么 Hive 是一个数据仓库基础工具在 Hadoop 中用来处理结构化数据。它架构在 Hadoop 之上，总归为大数据，并使得查询和分析方便。\n最初，Hive 是由 Facebook 开发，后来由 Apache 软件基金会开发，并作为进一步将它作为名义下 Apache Hive 为一个开源项目。它用在好多不同的公司。例如，亚马逊使用它在 Amazon Elastic MapReduce。"},{"id":147,"href":"/tags/Hive/","title":"Hive","parent":"Tags","content":"","description":""},{"id":148,"href":"/golang/go1.15.2%E6%BA%90%E7%A0%81%E5%8F%98%E5%8C%96/","title":"Go1.15.2更新记录 (released 2020/09/09) ","parent":"golang","content":"更新记录：https://github.com/golang/go/issues?q=milestone%3AGo1.15.2+label%3ACherryPickApproved\nremote: Enumerating objects: 66, done. remote: Counting objects: 100% (66/66), done. remote: Compressing objects: 100% (11/11), done. remote: Total 42 (delta 34), reused 39 (delta 31), pack-reused 0 Unpacking objects: 100% (42/42), 6.33 KiB | 109.00 KiB/s, done. From https://github.com/golang/go dfdc388..d277a36 master -\u0026gt; origin/master Updating 1e6ad65..d277a36 Fast-forward doc/go1.16.html | 14 +- src/cmd/asm/internal/asm/testdata/arm64.s | 35 ++++ src/cmd/asm/internal/asm/testdata/arm64error.s | 13 ++ src/cmd/compile/internal/gc/esc.go | 6 +- src/cmd/compile/internal/gc/escape.go | 6 +- src/cmd/compile/internal/gc/order.go | 1 + src/cmd/compile/internal/gc/ssa.go | 2 +- src/cmd/compile/internal/gc/subr.go | 4 +- src/cmd/compile/internal/gc/syntax.go | 41 ++-- src/cmd/compile/internal/gc/walk.go | 62 ++++-- src/cmd/compile/internal/types/type.go | 5 + src/cmd/go.mod | 2 +- src/cmd/go.sum | 15 +- src/cmd/go/internal/list/list.go | 23 ++- src/cmd/go/internal/modcmd/graph.go | 2 +- src/cmd/go/internal/modcmd/tidy.go | 12 ++ src/cmd/go/internal/modcmd/vendor.go | 2 +- src/cmd/go/internal/modcmd/verify.go | 2 +- src/cmd/go/internal/modcmd/why.go | 2 + src/cmd/go/internal/modget/get.go | 202 +------------------ src/cmd/go/internal/modget/mvs.go | 202 +++++++++++++++++++ src/cmd/go/internal/modload/build.go | 2 +- src/cmd/go/internal/modload/buildlist.go | 122 +++++++++++ src/cmd/go/internal/modload/import.go | 81 +++++--- src/cmd/go/internal/modload/import_test.go | 44 +++- src/cmd/go/internal/modload/init.go | 38 +++- src/cmd/go/internal/modload/list.go | 2 +- src/cmd/go/internal/modload/load.go | 871 ++++++++++++++++++++++++++++++++++++++++++++++++++----------------------------- src/cmd/go/internal/modload/modfile.go | 22 ++ src/cmd/go/testdata/mod/example.com_split-incompatible_subpkg_v0.1.0.txt | 14 ++ src/cmd/go/testdata/mod/example.com_split-incompatible_v2.0.0+incompatible.txt | 10 + src/cmd/go/testdata/mod/example.com_split-incompatible_v2.1.0-pre+incompatible.txt | 10 + src/cmd/go/testdata/script/list_bad_import.txt | 18 +- src/cmd/go/testdata/script/list_test_err.txt | 3 + src/cmd/go/testdata/script/mod_all.txt | 100 ++++++++- src/cmd/go/testdata/script/mod_get_sum_noroot.txt | 11 + src/cmd/go/testdata/script/mod_import_issue41113.txt | 28 +++ src/cmd/go/testdata/script/mod_list_bad_import.txt | 18 +- src/cmd/go/testdata/script/mod_list_std.txt | 64 ++++-- src/cmd/go/testdata/script/mod_missingpkg_prerelease.txt | 4 +- src/cmd/go/testdata/script/mod_notall.txt | 4 +- src/cmd/go/testdata/script/mod_std_vendor.txt | 6 +- src/cmd/internal/obj/arm64/a.out.go | 11 + src/cmd/internal/obj/arm64/anames.go | 11 + src/cmd/internal/obj/arm64/asm7.go | 128 ++++++++++-- src/cmd/link/internal/ld/symtab.go | 4 +- src/cmd/link/internal/loader/loader.go | 36 ++-- src/cmd/link/link_test.go | 4 + src/cmd/vendor/golang.org/x/tools/go/analysis/passes/structtag/structtag.go | 6 +- src/cmd/vendor/golang.org/x/tools/go/analysis/passes/unmarshal/unmarshal.go | 7 +- src/cmd/vendor/golang.org/x/tools/go/analysis/passes/unusedresult/unusedresult.go | 2 +- src/cmd/vendor/golang.org/x/tools/internal/analysisinternal/analysis.go | 343 +++++++++++++++++++++++++++++-- src/cmd/vendor/golang.org/x/tools/internal/lsp/fuzzy/input.go | 168 ++++++++++++++++ src/cmd/vendor/golang.org/x/tools/internal/lsp/fuzzy/matcher.go | 398 ++++++++++++++++++++++++++++++++++++ src/cmd/vendor/modules.txt | 3 +- src/make.bash | 10 +- src/net/http/transport.go | 10 +- src/net/http/transport_test.go | 99 +++++++++ src/runtime/debug.go | 5 +- src/runtime/export_test.go | 17 +- src/runtime/mpagealloc.go | 13 ++ src/runtime/proc.go | 7 + src/runtime/stack.go | 2 +- src/unicode/utf8/utf8_test.go | 30 ++- test/fixedbugs/issue24491.go | 45 +++++ 65 files changed, 2738 insertions(+), 746 deletions(-) create mode 100644 src/cmd/go/internal/modget/mvs.go create mode 100644 src/cmd/go/internal/modload/buildlist.go create mode 100644 src/cmd/go/testdata/mod/example.com_split-incompatible_subpkg_v0.1.0.txt create mode 100644 src/cmd/go/testdata/mod/example.com_split-incompatible_v2.0.0+incompatible.txt create mode 100644 src/cmd/go/testdata/mod/example.com_split-incompatible_v2.1.0-pre+incompatible.txt create mode 100644 src/cmd/go/testdata/script/mod_get_sum_noroot.txt create mode 100644 src/cmd/go/testdata/script/mod_import_issue41113.txt create mode 100644 src/cmd/vendor/golang.org/x/tools/internal/lsp/fuzzy/input.go create mode 100644 src/cmd/vendor/golang.org/x/tools/internal/lsp/fuzzy/matcher.go create mode 100644 test/fixedbugs/issue24491.go ","description":"更新记录：https://github.com/golang/go/issues?q=milestone%3AGo1.15.2+label%3ACherryPickApproved\nremote: Enumerating objects: 66, done. remote: Counting objects: 100% (66/66), done."},{"id":149,"href":"/tags/%E6%BA%90%E7%A0%81/","title":"源码","parent":"Tags","content":"","description":""},{"id":150,"href":"/csapp/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86--%E6%B5%AE%E7%82%B9%E6%95%B0/","title":"第二章信息的表示和处理  浮点数","parent":"读书笔记","content":" 定义 二进制小数*** IEEE 浮点表示 IEEE 二进制浮点数算术标准（IEEE 754）是 20 世纪 80 年代以来最广泛使用的浮点数运算标准，为许多 CPU 与浮点运算器所采用。这个标准定义了表示浮点数的格式（包括负零-0）与反常值（denormal number）），一些特殊数值（无穷（Inf）与非数值（NaN）），以及这些数值的“浮点数运算符”；它也指明了四种数值舍入规则和五种例外状况（包括例外发生的时机与处理方式）。\nIEEE 754 规定了四种表示浮点数值的方式：单精确度（32 位）、双精确度（64 位）、延伸单精确度（43 比特以上，很少使用）与延伸双精确度（79 比特以上，通常以 80 位实现）。只有 32 位模式有强制要求，其他都是选择性的。大部分编程语言都有提供 IEEE 浮点数格式与算术，但有些将其列为非必需的。例如，IEEE 754 问世之前就有的 C 语言，有包括 IEEE 算术，但不算作强制要求（C 语言的 float 通常是指 IEEE 单精确度，而 double 是指双精确度）。\n该标准的全称为 IEEE 二进制浮点数算术标准（ANSI/IEEE Std 754-1985），又称 IEC 60559:1989，微处理器系统的二进制浮点数算术（本来的编号是 IEC 559:1989）。后来还有“与基数无关的浮点数”的“IEEE 854-1987 标准”，有规定基数为 2 跟 10 的状况。最新标准是“ISO/IEC/IEEE FDIS 60559:2010”。\n舍入 任何有效数上的运算结果，通常都存放在较长的寄存器中，当结果被放回浮点格式时，必须将多出来的比特丢弃。 有多种方法可以用来运行舍入作业，实际上 IEEE 标准列出 4 种不同的方法：\n舍入到最接近：舍入到最接近，在一样接近的情况下偶数优先（Ties To Even，这是默认的舍入方式）：会将结果舍入为最接近且可以表示的值，但是当存在两个数一样接近的时候，则取其中的偶数（在二进制中式以 0 结尾的）。\n朝+∞ 方向舍入：会将结果朝正无限大的方向舍入。\n朝-∞ 方向舍入：会将结果朝负无限大的方向舍入。\n朝 0 方向舍入：会将结果朝 0 的方向舍入。\n运算 ","description":"定义 二进制小数*** IEEE 浮点表示 IEEE 二进制浮点数算术标准（IEEE 754）是 20 世纪 80 年代以来最广泛使用的浮点数运算标准，为许多 CPU 与浮点运算器所采用。这个标准定义了表示浮点数的格式（包括负零-0）与反常值（denormal number）），一些特殊数值（无穷（Inf）与非数值（NaN）），以及这些数值的“浮点数运算符”；它也指明了四种数值舍入规则和五种例外状况（包括例外发生的时机与处理方式）。"},{"id":151,"href":"/csapp/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86--%E6%95%B4%E6%95%B0%E8%BF%90%E7%AE%97/","title":"第二章信息的表示和处理  整数运算","parent":"读书笔记","content":" 整数表示 用位来编码整数，两种不同方式：一种只能表示非负数，而另一种能够表示负数、零和正数。\n整型数据类型 32位与64位机器取值范围不同 大多数64位机器使用8个字节表示，比32位机器上使用4个字节表示取值范围大 取值范围不对称，负数比正数的范围大1\n无符号数编码 向量定义法 最小值0，最大值二的N次方减一 无符号数编码具有唯一性 补码（two’s-complement）编码 用补码表示有符号的数 将字的最高有效位解释为负权（negative weight） 符号位设置为1表示值为负、0表示值为正 补码编码的唯一性，双射 补码范围不对称：|TMin| = |TMax| + 1 UMax = 2TMax + 1 long类型：不同机器有不同的取值范围 有符号数的其他表示方法：反码、原码\n无符号加法 补码加法 正溢出\n负溢出\n补码的非 无符号的乘法 补码乘法 乘以常数 ","description":"整数表示 用位来编码整数，两种不同方式：一种只能表示非负数，而另一种能够表示负数、零和正数。\n整型数据类型 32位与64位机器取值范围不同 大多数64位机器使用8个字节表示，比32位机器上使用4个字节表示取值范围大 取值范围不对称，负数比正数的范围大1\n无符号数编码 向量定义法 最小值0，最大值二的N次方减一 无符号数编码具有唯一性 补码（two’s-complement）编码 用补码表示有符号的数 将字的最高有效位解释为负权（negative weight） 符号位设置为1表示值为负、0表示值为正 补码编码的唯一性，双射 补码范围不对称：|TMin| = |TMax| + 1 UMax = 2TMax + 1 long类型：不同机器有不同的取值范围 有符号数的其他表示方法：反码、原码"},{"id":152,"href":"/csapp/%E7%AC%AC%E4%BA%8C%E7%AB%A0%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86/","title":"第二章信息的表示和处理","parent":"读书笔记","content":" 位 bit 二进制数字：0、1\n无符号编码基于基于传统的二进制表示法\n补码编码是表示有符号整数最常见的方式\n浮点数编码表示实数的科学计数法的以 2 为基数的版本\n溢出 overflow 用有限数量的位为一个数编码，会产生某些计算溢出 信息存储 大多数计算机用 8 位的块，表示一个字节（byte），作为最小的可寻址的内存单位，而不是访问内存中单独的位。\n将内存视为一个大的字节数组，称为虚拟内存（virtual memory）\n内存的每个字节用唯一的数字来标识，称为地址（address）\n所有地址的集合，称为虚拟地址空间（virtual address space）\n十六进制(hexadecimal)表示法 十六进制（简写为\u0026quot;hex\u0026quot;）使用数字 \u0026lsquo;O\u0026rsquo; ~ \u0026lsquo;9\u0026rsquo; 以及字符 \u0026lsquo;A\u0026rsquo; ~ \u0026lsquo;F\u0026rsquo; 来表示 16 个可能的值。字符 \u0026lsquo;A\u0026rsquo; ~ \u0026lsquo;F\u0026rsquo; 既可以是大写，也可以是小写。\n进制之间转换：二进制、十六进制、十进制\n字数据大小 32位程序、64位程序 寻址和字节顺序 排列表示一个对象的字节有两个通用规则。\n最低有效字节在最前面的方式，称为小端法(little endian)。\n后一种规则—-—最高有效字节在最前面的方式，称为大端法(big endian)。\n网络应用程序的代码编写必须遵守 已建立 的关千字节顺 序的规则， 以 确 保发送方机器将它的内部表示转换成网络标准 ，而接收方机器则将网络标准 转换为 它的 内部表示。\n表示字符串 布尔代数 布尔环？？ C 语言运算 位级运算 逻辑运算 移位运算 整数表示 整型数据类型 无符号数编码 无符号数编码的唯一性\n补码编码 用来表示负数\n补码编码的唯一性\n有符号与无符号数直接转换 ","description":"位 bit 二进制数字：0、1\n无符号编码基于基于传统的二进制表示法\n补码编码是表示有符号整数最常见的方式\n浮点数编码表示实数的科学计数法的以 2 为基数的版本\n溢出 overflow 用有限数量的位为一个数编码，会产生某些计算溢出 信息存储 大多数计算机用 8 位的块，表示一个字节（byte），作为最小的可寻址的内存单位，而不是访问内存中单独的位。"},{"id":153,"href":"/csapp/%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8-Amdahl%E5%AE%9A%E5%BE%8B/","title":"第一章计算机系统漫游 Amdahl定律","parent":"读书笔记","content":" 定义 Amdahl 定律：阿姆达尔定律\n阿姆达尔定律是计算机系统设计的重要定量原理之一，于 1967 年由 IBM360 系列机的主要设计者阿姆达尔首先提出。该定律是指：系统中对某一部件采用更快执行方式所能获得的系统性能改进程度，取决于这种执行方式被使用的频率，或所占总执行时间的比例。阿姆达尔定律实际上定义了采取增强（加速）某部分功能处理的措施后可获得的性能改进或执行时间的加速比。简单来说是通过更快的处理器来获得加速是由慢的系统组件所限制。、\n出发点 基本出发点：\n1.对于很多科学计算，实时性要求很高，即在此类应用中时间是个关键因素，而计算负载是固定不变的。为此在一定的计算负载下，为达到实时性可利用增加处理器数来提高计算速度；\n2.因为固定的计算负载是可分布在多个处理器上的，这样增加了处理器就加快了执行速度，从而达到了加速的目的。\n公式 S=1/(1-a+a/n)\n其中，a 为并行计算部分所占比例，n 为并行处理结点个数。这样，当 1-a=0 时，(即没有串行，只有并行)最大加速比 s=n；当 a=0 时（即只有串行，没有并行），最小加速比 s=1；当 n→∞ 时，极限加速比 s→ 1/(1-a），这也就是加速比的上限。 例如，若串行代码占整个代码的 25%，则并行处理的总体性能不可能超过 4。这一公式已被学术界所接受，并被称做“阿姆达尔定律”，也称为“安达尔定理”(Amdahl law)。\n","description":"定义 Amdahl 定律：阿姆达尔定律\n阿姆达尔定律是计算机系统设计的重要定量原理之一，于 1967 年由 IBM360 系列机的主要设计者阿姆达尔首先提出。该定律是指：系统中对某一部件采用更快执行方式所能获得的系统性能改进程度，取决于这种执行方式被使用的频率，或所占总执行时间的比例。阿姆达尔定律实际上定义了采取增强（加速）某部分功能处理的措施后可获得的性能改进或执行时间的加速比。简单来说是通过更快的处理器来获得加速是由慢的系统组件所限制。、\n出发点 基本出发点："},{"id":154,"href":"/csapp/%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8/","title":"第一章 计算机系统漫游","parent":"读书笔记","content":" 信息就是位+上下文 位一样，在不同上下文中表示不同； 比如，人际关系，你就是位，在家里你是父亲或母亲，到单位你是老总或下属\n比如，在不同的上下文中，一个同样的字节序列可能表示 一个整数、浮点数、字符串或者机器指令。\n系统中所有信息都是由一串比特表示的 文本文件 与 二进制文件 程序被其他程序翻译成不同的格式 注意：是翻译而不是编译 编译系统构成的四部分：预处理器、编译器、汇编器和链接器 预处理阶段：预处理器 编译阶段：编译器 汇编阶段：汇编器翻译成机器语言指令，把这些指令打包成一种叫做可重定位目标程序\u0026lt;的格式。 链接阶段：链接器负责合并，生成一个可执行目标文件（简称：可执行文件）。 了解编译系统 优化程序性能 理解链接时出现的错误 避免安全漏洞 处理器读取并解释存储在内存中的指令 系统的硬件组成 总线 IO 设备 主存： 从物理上来说，主存是由一组动态随机存取存储器(DRAM)芯片组成的。 从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址数组索 引），这些地址是从零开始的。 处理器 高速缓存至关重要 看图知道 高速缓存存储器 所处的位置吗？\n存储设备形成的层次结构 系统之间利用网络通信 ","description":"信息就是位+上下文 位一样，在不同上下文中表示不同； 比如，人际关系，你就是位，在家里你是父亲或母亲，到单位你是老总或下属\n比如，在不同的上下文中，一个同样的字节序列可能表示 一个整数、浮点数、字符串或者机器指令。\n系统中所有信息都是由一串比特表示的 文本文件 与 二进制文件 程序被其他程序翻译成不同的格式 注意：是翻译而不是编译 编译系统构成的四部分：预处理器、编译器、汇编器和链接器 预处理阶段：预处理器 编译阶段：编译器 汇编阶段：汇编器翻译成机器语言指令，把这些指令打包成一种叫做可重定位目标程序\u0026lt;的格式。 链接阶段：链接器负责合并，生成一个可执行目标文件（简称：可执行文件）。 了解编译系统 优化程序性能 理解链接时出现的错误 避免安全漏洞 处理器读取并解释存储在内存中的指令 系统的硬件组成 总线 IO 设备 主存： 从物理上来说，主存是由一组动态随机存取存储器(DRAM)芯片组成的。 从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址数组索 引），这些地址是从零开始的。 处理器 高速缓存至关重要 看图知道 高速缓存存储器 所处的位置吗？"},{"id":155,"href":"/golang/go2go/","title":"go2go命令","parent":"golang","content":"链接地址：https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/doc.go\n// go2go is a command for trying out generic Go code. // It supports a small number of commands similar to cmd/go. // // Usage: // // go2go [options] \u0026lt;command\u0026gt; [arguments] // // The only option is -brackets, which requires square brackets rather // than parentheses for generic code. This is temporarily useful when // translating code that uses square brackets to pass type arguments // to generic function and types while not defining any generic // functions or types itself. // // The commands are: // // build translate and then run \u0026#34;go build packages\u0026#34; // run translate and then run a list of files // test translate and then run \u0026#34;go test packages\u0026#34; // translate translate .go2 files into .go files for listed packages // // A package is expected to contain .go2 files but no .go files. // // Non-local imported packages will be first looked up using the GO2PATH // environment variable, which should point to a GOPATH-like directory. // For example, import \u0026#34;x\u0026#34; will first look for GO2PATHDIR/src/x, // for each colon-separated component in GO2PATH. If not found in GO2PATH, // imports will be looked up in the usual way. If an import includes // .go2 files, they will be translated into .go files. // // There is a sample GO2PATH in cmd/go2go/testdata/go2path. It provides // several packages that serve as examples of using generics, and may // be useful in experimenting with your own generic code. // // Translation into standard Go requires generating Go code with mangled names. // The mangled names will always include Odia (Oriya) digits, such as ୦ and ୮. // Do not use Oriya digits in identifiers in your own code. // // Because this tool generates Go files, and because instantiated types // and functions need to refer to the types with which they are instantiated, // using function-local types as type arguments is not supported. // Similarly, function-local parameterized types do not work. // These are deficiencies of the tool, they will work as expected in // any complete implementation. // // Similarly, generic function and type bodies that refer to unexported, // non-generic, names can\u0026#39;t be instantiated by different packages. // // Because this tool generates Go files, and because it generates type // and function instantiations alongside other code in the package that // instantiates those functions and types, and because those instantiatations // may refer to names in packages imported by the original generic code, // this tool will add imports as necessary to support the instantiations. // Therefore, packages that use generic code must not use top level // definitions whose names are the same as the names of packages imported // by the generic code. For example, don\u0026#39;t write, in package scope, // // var strings = []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;} // // because if the generic code imports \u0026#34;strings\u0026#34;, the variable name will // conflict with the package name, even if your code doesn\u0026#39;t import \u0026#34;strings\u0026#34;. // This is a deficiency of the tool, it will not be a deficiency in // any complete implementation. ","description":"链接地址：https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/doc.go\n// go2go is a command for trying out generic Go code."},{"id":156,"href":"/tags/%E6%B3%9B%E5%9E%8B/","title":"泛型","parent":"Tags","content":"","description":""},{"id":157,"href":"/golang/%E5%AE%98%E6%96%B9golang%E6%B3%9B%E5%9E%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","title":"官方golang泛型阅读笔记","parent":"golang","content":" 常量定义 链接地址： https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/constraints/constraints.go2\n// Ordered permits any ordered type: any type that supports // the operations \u0026lt;, \u0026lt;=, \u0026gt;=, \u0026gt;, as well as == and !=. type Ordered interface { type int, int8, int16, int32, int64, uint, uint8, uint16, uint32, uint64, uintptr, float32, float64, string } // Integer permits any integer type. type Integer interface { type int, int8, int16, int32, int64, uint, uint8, uint16, uint32, uint64, uintptr } // Signed permits any signed integer type. type Signed interface { type int, int8, int16, int32, int64 } // Unsigned permits any unsigned integer type. type Unsigned interface { type uint, uint8, uint16, uint32, uint64, uintptr } any 类型 // A Sender is used to send values to a Receiver. type Sender[Elem any] struct { values chan\u0026lt;- Elem done \u0026lt;-chan struct{} } any：表示任何类型\n泛型结构体与接口 链接地址：https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/graph/graph.go2\n// A Graph is a collection of nodes. A node may have an arbitrary number // of edges. An edge connects two nodes. Both nodes and edges must be // comparable. This is an undirected simple graph. type Graph[Node NodeC[Edge], Edge EdgeC[Node]] struct { nodes []Node } // NodeC is the contraints on a node in a graph, given the Edge type. type NodeC[Edge any] interface { comparable Edges() []Edge } // Edgec is the constraints on an edge in a graph, given the Node type. type EdgeC[Node any] interface { comparable Nodes() (a, b Node) } // GraphP is a version of Graph that uses pointers. This is for testing. // I\u0026#39;m not sure which approach will be better in practice, or whether // this indicates a problem with the draft design. type GraphP[type *Node NodeCP[Edge], *Edge EdgeCP[Node]] struct { nodes []*Node } slices 中 怪异的 f != f 链接地址： https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/slices/slices.go2\n问题一：为什么 f != f ？\n主要考虑浮点数 问题二：isNaN 函数是否放 for 循环体之外更合适？\nlinked list 链接地址：https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/list/list.go2\n// Element is an element of a linked list. type Element[TElem any] struct { // Next and previous pointers in the doubly-linked list of elements. // To simplify the implementation, internally a list l is implemented // as a ring, such that \u0026amp;l.root is both the next element of the last // list element (l.Back()) and the previous element of the first list // element (l.Front()). next, prev *Element[TElem] // The list to which this element belongs. list *List[TElem] // The value stored with this element. Value TElem } // List represents a doubly linked list. // The zero value for List is an empty list ready to use. type List[TElem any] struct { root Element[TElem] // sentinel list element, only \u0026amp;root, root.prev, and root.next are used len int // current list length excluding (this) sentinel element } maps 结构 链接地址：https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/maps/maps.go2\n// Keys returns the keys of the map m. // The keys will be an indeterminate order. func Keys[K comparable, V any](m map[K]V) []K { r := make([]K, 0, len(m)) for k := range m { r = append(r, k) } return r } metrics 链接地址：https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/metrics/metrics.go2\n// Metric1 tracks metrics of values of some type. type Metric1[T comparable] struct { mu sync.Mutex m map[T]int } type key2[T1, T2 comparable] struct { f1 T1 f2 T2 } // Metric2 tracks metrics of pairs of values. type Metric2[T1, T2 comparable] struct { mu sync.Mutex m map[key2[T1, T2]]int } type key3[T1, T2, T3 comparable] struct { f1 T1 f2 T2 f3 T3 } // Metric3 tracks metrics of triplets of values. type Metric3[T1, T2, T3 comparable] struct { mu sync.Mutex m map[key3[T1, T2, T3]]int } orderedmap 链接地址：https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/orderedmap/orderedmap.go2\n// Map is an ordered map. type Map[K, V any] struct { root *node[K, V] compare func(K, K) int } // node is the type of a node in the binary tree. type node[K, V any] struct { key K val V left, right *node[K, V] } sets 链接地址：https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/sets/sets.go2\n// A Set is a set of elements of some type. type Set[Elem comparable] struct { m map[Elem]struct{} } // Add adds an element to a set. func (s Set[Elem]) Add(v Elem) { s.m[v] = struct{}{} } slices 链接地址：https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/slices/slices.go2\n// Equal reports whether two slices are equal: the same length and all // elements equal. All floating point NaNs are considered equal. func Equal[Elem comparable](s1, s2 []Elem) bool { if len(s1) != len(s2) { return false } for i, v1 := range s1 { v2 := s2[i] if v1 != v2 { isNaN := func(f Elem) bool { return f != f } if !isNaN(v1) || !isNaN(v2) { return false } } } return true } ","description":"常量定义 链接地址： https://github.com/golang/go/blob/dev.go2go/src/cmd/go2go/testdata/go2path/src/constraints/constraints.go2\n// Ordered permits any ordered type: any type that supports // the operations \u0026lt;, \u0026lt;=, \u0026gt;=, \u0026gt;, as well as == and !"},{"id":158,"href":"/csapp/%E5%BA%8F%E8%A8%80/","title":"序言","parent":"读书笔记","content":" 内容概述 第一章 计算机系统漫游\n第二章 信息的表示和处理\n第三章 程序的机器级表示\n第四章 处理器体系结构\n第五章 优化程序性能\n第六章 存储器层次结构\n第七章 链接\n第八章 异常控制流\n第九章 虚拟内存\n第十章 系统级 I/O\n第十一章 网络编程\n第十二章 并发编程\n读书计划 ","description":"内容概述 第一章 计算机系统漫游\n第二章 信息的表示和处理\n第三章 程序的机器级表示\n第四章 处理器体系结构"},{"id":159,"href":"/tags/linux/","title":"Linux","parent":"Tags","content":"","description":""},{"id":160,"href":"/tags/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","title":"Linux性能优化","parent":"Tags","content":"","description":""},{"id":161,"href":"/categories/linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","title":"Linux性能优化","parent":"Categories","content":"","description":""},{"id":162,"href":"/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","title":"性能优化","parent":"Tags","content":"","description":""},{"id":163,"href":"/about/","title":"关于","parent":"首页","content":" 构建github.io博客 参考资料： GitHub博客\n通过Hugo工具写博客 参考资料： Hugo中文文档\n","description":"构建github.io博客 参考资料： GitHub博客\n通过Hugo工具写博客 参考资料： Hugo中文文档"},{"id":164,"href":"/categories/%E5%B7%A5%E5%85%B7/","title":"工具","parent":"Categories","content":"","description":""},{"id":165,"href":"/","title":"首页","parent":"","content":" ","description":" "}]